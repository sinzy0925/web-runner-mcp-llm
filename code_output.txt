


---


- フォルダ名: .
- ファイル名: config.py
- 内容:
# --- ファイル: config.py ---
"""
スクリプト全体で使用する設定値と定数を定義します。
"""

# --- Playwright 関連設定 ---
DEFAULT_ACTION_TIMEOUT = 10000  # 10000 デフォルトのアクションタイムアウト (ミリ秒)
IFRAME_LOCATOR_TIMEOUT = 5000   #  5000 iframe存在確認のタイムアウト (ミリ秒)
PDF_DOWNLOAD_TIMEOUT   = 60000  # 60000 PDFダウンロードのタイムアウト (ミリ秒)
NEW_PAGE_EVENT_TIMEOUT = 4000   #  4000 新しいページが開くのを待つタイムアウト (ミリ秒)(クリック後常に待つので長くすると常にクリック後遅い)

# --- 動的探索関連設定 ---
DYNAMIC_SEARCH_MAX_DEPTH = 2    # iframe探索の最大深度

# --- ファイルパス・ディレクトリ名 ---
LOG_FILE               = 'output_web_runner.log'
DEFAULT_INPUT_FILE     = 'input.json'
DEFAULT_SCREENSHOT_DIR = 'screenshots'
RESULTS_OUTPUT_FILE    = 'output_results.txt'

# --- その他 ---
# 必要に応じて他の設定値を追加
MCP_SERVER_LOG_FILE    = 'output/web_runner_mcp.log' # MCPサーバー用ログファイル名 (例)
MCP_CLIENT_OUTPUT_FILE = 'output/web_runner_mcp.txt' # MCPクライアントのデフォルト出力ファイル名


---


- フォルダ名: .
- ファイル名: crawl_results.txt
- 内容:
--- Web Runner 実行結果 ---

--- Step 1: input (success) ---
Selector: #APjFqb
Other Details:
  value: 東京都　昭島市　朝日町　会社概要

--- Step 2: click (success) ---
Selector: body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b
New page did not open within timeout.

--- Step 3: sleep (success) ---
Other Details:
  duration_sec: 2.0

--- Step 4: get_all_attributes (success) ---
Selector: #rso div.kb0PBd.A9Y9g.jGGQ5e span a
Requested Attribute/Content: mail
Results (10 items processed):
  Extracted Emails (Unique Domains for this step):
  - info@dilemma.co.jp
  - info@realty-akishima.com
  - info@tatsuki-k.com

--- Step 5: click (success) ---
Selector: #pnnext > span.oeN89d
New page did not open within timeout.

--- Step 6: sleep (success) ---
Other Details:
  duration_sec: 2.0

--- Step 7: get_all_attributes (success) ---
Selector: #rso div.kb0PBd.A9Y9g.jGGQ5e span a
Requested Attribute/Content: mail
Results (10 items processed):
  Extracted Emails (Unique Domains for this step):
  - info@artplancorp.jp
  - asbestos@pandecon.net

--- Step 8: click (success) ---
Selector: #pnnext > span.oeN89d
New page did not open within timeout.

--- Step 9: sleep (success) ---
Other Details:
  duration_sec: 2.0

--- Step 10: get_all_attributes (success) ---
Selector: #rso div.kb0PBd.A9Y9g.jGGQ5e span a
Requested Attribute/Content: mail
Results (10 items processed):
  Extracted Emails (Unique Domains for this step):
    (No unique domain emails found for this step)

--- Step 11: click (success) ---
Selector: #pnnext > span.oeN89d
New page did not open within timeout.

--- Step 12: sleep (success) ---
Other Details:
  duration_sec: 2.0

--- Step 13: get_all_attributes (success) ---
Selector: #rso div.kb0PBd.A9Y9g.jGGQ5e span a
Requested Attribute/Content: mail
Results (10 items processed):
  Extracted Emails (Unique Domains for this step):
    (No unique domain emails found for this step)

--- Step 14: click (success) ---
Selector: #pnnext > span.oeN89d
New page did not open within timeout.

--- Step 15: sleep (success) ---
Other Details:
  duration_sec: 2.0

--- Step 16: get_all_attributes (success) ---
Selector: #rso div.kb0PBd.A9Y9g.jGGQ5e span a
Requested Attribute/Content: mail
Results (10 items processed):
  Extracted Emails (Unique Domains for this step):
  - contact@jrd.jp
  - info-b@ouchi.co.jp

--- Final Aggregated Summary ---

Final Unique Domain Emails:
[
  "asbestos@pandecon.net",
  "contact@jrd.jp",
  "info-b@ouchi.co.jp",
  "info@artplancorp.jp",
  "info@dilemma.co.jp",
  "info@realty-akishima.com",
  "info@tatsuki-k.com"
]




---


- フォルダ名: .
- ファイル名: generated_crawl_proven.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "memo": "検索ボックスに入力",
      "action": "input",
      "selector": "#APjFqb",
      "value": "東京都　昭島市　朝日町　会社概要"
    },
    {
      "memo": "検索ボタンをクリック",
      "action": "click",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 5000
    },
    {
      "memo": "検索結果表示待機 (2秒)",
      "action": "sleep",
      "value": 2
    },
    {
      "memo": "ページ 1 メール抽出",
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "attribute_name": "mail",
      "wait_time_ms": 7000
    },
    {
      "memo": "ページ 2 へ移動",
      "action": "click",
      "selector": "#pnnext > span.oeN89d",
      "wait_time_ms": 5000
    },
    {
      "memo": "ページ遷移待機 (2秒)",
      "action": "sleep",
      "value": 2
    },
    {
      "memo": "ページ 2 メール抽出",
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "attribute_name": "mail",
      "wait_time_ms": 7000
    },
    {
      "memo": "ページ 3 へ移動",
      "action": "click",
      "selector": "#pnnext > span.oeN89d",
      "wait_time_ms": 5000
    },
    {
      "memo": "ページ遷移待機 (2秒)",
      "action": "sleep",
      "value": 2
    },
    {
      "memo": "ページ 3 メール抽出",
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "attribute_name": "mail",
      "wait_time_ms": 7000
    },
    {
      "memo": "ページ 4 へ移動",
      "action": "click",
      "selector": "#pnnext > span.oeN89d",
      "wait_time_ms": 5000
    },
    {
      "memo": "ページ遷移待機 (2秒)",
      "action": "sleep",
      "value": 2
    },
    {
      "memo": "ページ 4 メール抽出",
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "attribute_name": "mail",
      "wait_time_ms": 7000
    },
    {
      "memo": "ページ 5 へ移動",
      "action": "click",
      "selector": "#pnnext > span.oeN89d",
      "wait_time_ms": 5000
    },
    {
      "memo": "ページ遷移待機 (2秒)",
      "action": "sleep",
      "value": 2
    },
    {
      "memo": "ページ 5 メール抽出",
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "attribute_name": "mail",
      "wait_time_ms": 7000
    }
  ]
}


---


- フォルダ名: .
- ファイル名: info_extractor_tester.py
- 内容:
# info_extractor_tester.py:

import os
import google.generativeai as genai
import pathlib
from dotenv import load_dotenv
import logging
import traceback
import time
import json # JSONを扱うためにインポート

# --- 初期設定 ---
load_dotenv()
api_key = os.getenv('API_KEY')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

if not api_key:
    logging.error("API_KEYが環境変数に見つかりません。.envファイルを確認してください。")
    exit()

try:
    genai.configure(api_key=api_key, transport='rest')
except Exception as e:
    logging.error(f"Geminiの設定中にエラーが発生しました: {e}")
    exit()

# --- Geminiモデル設定 ---
# ★★★ 必要に応じてモデル名を変更 ★★★
MODEL_NAME = "gemini-2.0-flash" # または "gemini-1.5-flash-latest" など
try:
    model = genai.GenerativeModel(model_name=MODEL_NAME)
    logging.info(f"Geminiモデル '{MODEL_NAME}' を初期化しました。")
except Exception as e:
    logging.error(f"指定されたGeminiモデル '{MODEL_NAME}' の初期化に失敗しました: {e}")
    exit()


def extract_element_info(html_content: str, instruction: str, max_retries=3, retry_delay=5) -> dict | None:
    """
    与えられたHTMLコンテンツと自然言語指示に基づき、Gemini APIを使用して
    要素特定情報をJSON形式で抽出します。

    Args:
        html_content (str): 解析対象のHTMLコンテンツ。
        instruction (str): 抽出したい要素を示す自然言語の指示。
        max_retries (int): APIエラー時の最大リトライ回数。
        retry_delay (int): リトライ間の待機時間（秒）。

    Returns:
        dict | None: 抽出された要素情報の辞書、または失敗時にNone。
    """
    logging.info("-" * 30)
    logging.info(f"指示に基づいて要素情報を抽出中: '{instruction}'")
    logging.info(f"HTMLコンテンツ長: {len(html_content)} 文字")

    # --- プロンプト設計 (要素情報抽出用) ---
    prompt = f"""
あなたはHTMLコンテンツとユーザーの指示を理解するエキスパートです。
以下のHTMLコンテンツとユーザーの指示を読み、指示された要素を特定するために最も役立つ情報をJSON形式で抽出してください。

# HTMLコンテンツ
```html
{html_content}

ユーザーの指示

「{instruction}」

あなたのタスク

ユーザーの指示に合致する要素を特定するための情報を以下のJSONフォーマットに従って抽出してください。
可能な限り多くのフィールドを埋めてください。特にtext, role, test_idがあれば重要です。
もし要素がリストの一部（例：検索結果リストのN番目）だと判断でき、順序が重要そうな場合は common_selector と index (0始まり) を設定してください。
該当する要素が見つからない、または指示が不明瞭な場合は、 "error": "Element not found or instruction unclear" というキーを持つJSONオブジェクトを返してください。

出力JSONフォーマット (この形式のJSONオブジェクトのみを出力すること)
{{
  "text": "要素に含まれる完全なテキスト or 部分テキスト (もしあれば、String)",
  "role": "要素のARIAロール (例: 'button', 'link', 'textbox', もしあれば、String)",
  "test_id": "data-testidなどのテスト用ID (もしあれば、String)",
  "placeholder": "プレースホルダー属性の値 (もしあれば、String)",
  "aria_label": "aria-label属性の値 (もしあれば、String)",
  "common_selector": "もし要素がリストの一部なら、そのリスト要素全体に共通するCSSセレクター (例: '#rso .g', なければnull)",
  "index": "リスト内の順序 (0始まりの整数、common_selectorとセットで使う、なければnull)",
  "tag_name": "要素のHTMLタグ名 (例: 'a', 'button', 'input', String)",
  "other_attributes": {{ "属性名": "属性値", ... }} // 上記以外で特定に役立ちそうな属性 (Object, なければ空の{{}})
}}
出力JSON:""" # 出力を促す接尾辞 (マークダウンは不要)
    extracted_info = None
    for attempt in range(max_retries):
        try:
            logging.info(f"Gemini APIへのリクエスト送信 (試行 {attempt + 1}/{max_retries})...")
            start_time = time.monotonic()

            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
            # ★★★ JSONモードを試す (利用可能なモデルか確認が必要) ★★★
            # モデルが対応していれば、より安定してJSONを出力する可能性がある
            # 対応していない場合は通常の generate_content を使う
            if hasattr(genai.GenerationConfig, 'response_mime_type') and MODEL_NAME in ["gemini-1.5-pro-latest", "gemini-1.5-flash-latest"]: # 例
                generation_config = genai.GenerationConfig(
                    response_mime_type="application/json",
                    # temperature=0.1 # 必要なら設定
                )
                response = model.generate_content(
                    prompt,
                    generation_config=generation_config,
                    safety_settings=safety_settings
                )
                logging.info("Gemini APIをJSONモードで呼び出しました。")
            else:
                # JSONモード非対応または不明なモデルの場合は通常モード
                logging.info("Gemini APIを通常モードで呼び出します (JSONモード非対応の可能性)。")
                response = model.generate_content(
                    prompt,
                    safety_settings=safety_settings
                )


            end_time = time.monotonic()
            logging.info(f"Gemini API応答受信。処理時間: {end_time - start_time:.2f} 秒")

            # --- 応答の解析 ---
            if response.candidates and response.text:
                raw_response_text = response.text.strip()
                logging.debug(f"生の応答テキスト: {raw_response_text}")
                # 応答がマークダウンのコードブロックで囲まれている場合、中身を抽出
                if raw_response_text.startswith("```json") and raw_response_text.endswith("```"):
                    json_text = raw_response_text[len("```json"): -len("```")].strip()
                elif raw_response_text.startswith("```") and raw_response_text.endswith("```"):
                    json_text = raw_response_text[len("```"): -len("```")].strip()
                else:
                    json_text = raw_response_text # マークダウンがない場合はそのまま

                try:
                    extracted_info = json.loads(json_text)
                    # 簡単なバリデーション (辞書型かどうか)
                    if isinstance(extracted_info, dict):
                        logging.info("JSON形式の情報を正常に抽出・解析しました。")
                        break # 成功したのでリトライループを抜ける
                    else:
                        logging.warning(f"GeminiがJSON形式でない応答を返しました: {type(extracted_info)}")
                        extracted_info = {"error": "Invalid format from LLM", "raw_response": json_text}
                        # 成功ではないのでリトライを続ける可能性がある

                except json.JSONDecodeError as e:
                    logging.warning(f"Geminiの応答JSONの解析に失敗しました: {e}")
                    logging.warning(f"解析しようとしたテキスト: {json_text}")
                    extracted_info = {"error": "JSONDecodeError from LLM response", "raw_response": json_text}
                    # 失敗したのでリトライする
            else:
                logging.warning("Gemini APIからの応答が空か、候補がありませんでした。")
                logging.debug(f"詳細な応答: {response}")
                error_details = "Unknown error or empty response"
                # ... (エラー詳細取得の試み - selector_tester.py と同様) ...
                extracted_info = {"error": error_details}
                # 失敗したのでリトライする

        except Exception as e:
            logging.error(f"Gemini API呼び出し中にエラーが発生しました (試行 {attempt + 1}): {e}")
            logging.debug(traceback.format_exc())
            extracted_info = {"error": f"API call failed: {e}"}
            if attempt == max_retries - 1:
                logging.error("最大リトライ回数に達しました。")
                return extracted_info # 最後のエラー情報を返す

        # リトライが必要な場合 (ループの最後で判定)
        if attempt < max_retries - 1 and (extracted_info is None or extracted_info.get("error")):
            logging.warning(f"{retry_delay}秒待機してリトライします...")
            time.sleep(retry_delay)
        elif extracted_info is not None and not extracted_info.get("error"):
            break # 成功したので抜ける

    # --- 最終的な結果を返す ---
    if extracted_info and not extracted_info.get("error"):
        # 不要なキーやnull値を除去するなどの後処理をここで行っても良い
        logging.info(f"抽出された情報: {json.dumps(extracted_info, ensure_ascii=False, indent=2)}")
        return extracted_info
    else:
        logging.error("要素情報の抽出に失敗しました。")
        # 失敗した場合も、最後のエラー情報を含む辞書を返す
        return extracted_info if extracted_info else {"error": "Extraction failed after retries"}
#--- テストケース定義 (期待値をJSON形式に変更) ---

TEST_CASES = [
{
"name": "Google Search Box",
"html_file": "test_html/google_search.html",
"instruction": "検索キーワードを入力するテキストエリア",
"expected_info": { # ★期待する情報
"role": "textbox", # textarea は textbox ロールを持つことが多い
"tag_name": "textarea",
"aria_label": "検索",
"other_attributes": {"title": "検索", "id": "APjFqb", "class": "gLFyf"} # idもotherに含めるか要検討
}
},
{
"name": "Google Search Button",
"html_file": "test_html/google_search.html",
"instruction": "「Google 検索」ボタン",
"expected_info": {
"text": "Google 検索", # value属性が表示テキストになっている
"role": "button",
"tag_name": "input",
"aria_label": "Google 検索",
"other_attributes": {"name": "btnK", "class": "gNO89b", "type": "submit"}
}
},
{
"name": "Google Result 1 Link",
"html_file": "test_html/google_results.html",
"instruction": "最初の検索結果のタイトルへのリンク",
"expected_info": {
"text": "検索結果タイトル 1", # リンク内のテキスト
"role": "link",
"tag_name": "a",
"common_selector": "#rso .g", # または "#rso > div.g" など、結果ブロックの共通セレクター
"index": 0,
"other_attributes": {"href": "https://example-result1.com/"}
}
},
{
"name": "Google Result 2 Link", # ★2番目のテストケースを追加
"html_file": "test_html/google_results.html",
"instruction": "2番目の検索結果のリンク",
"expected_info": {
"text": "Example Result 2",
"role": "link",
"tag_name": "a",
"common_selector": "#rso .g", # 1番目と同じ共通セレクター
"index": 1, # ★index が 1 になる
"other_attributes": {"href": "https://example-result2.net/"}
}
},
{
"name": "Google Next Page Link",
"html_file": "test_html/google_results.html",
"instruction": "「次へ」のページネーションリンク",
"expected_info": {
"text": "次へ",
"role": "link",
"tag_name": "a",
"other_attributes": {"id": "pnnext"}
}
},
{
"name": "News Article Title",
"html_file": "test_html/news_article.html",
"instruction": "記事の見出し (タイトル)",
"expected_info": {
"text": "今日のビッグニュース",
"role": "heading", # h1 は heading ロール
"tag_name": "h1",
"other_attributes": {"class": "article-title main", "itemprop": "headline"}
}
},
{
"name": "News Share Button",
"html_file": "test_html/news_article.html",
"instruction": "共有ボタン",
"expected_info": {
"text": "共有",
"role": "button",
"tag_name": "button",
"test_id": "share-button", # data-testid を抽出してほしい
"other_attributes": {"class": "share-button"}
}
},
{
"name": "News Non-existent Element",
"html_file": "test_html/news_article.html",
"instruction": "記事へのコメント投稿フォーム",
"expected_info": { # ★期待値としてエラーを示す
"error": "Element not found or instruction unclear"
}
},
]

#--- テスト用HTMLファイルを作成するヘルパー関数 (変更なし) ---
#selector_tester.py からコピー

def create_test_html_files():
    """テスト用のHTMLファイルを test_html ディレクトリに作成"""
    html_dir = pathlib.Path("test_html")
    html_dir.mkdir(exist_ok=True)
    # --- Google検索トップページ ---
    google_html = """
    <!DOCTYPE html><html><head><title>Google</title></head><body>
    <form action="/search">
    <textarea class="gLFyf" id="APjFqb" title="検索" aria-label="検索" role="textbox"></textarea>
    <div><center>
    <input class="gNO89b" value="Google 検索" aria-label="Google 検索" name="btnK" role="button" type="submit" data-ved="0ahUKEwi...">
    <input class="RNmpXc" value="I'm Feeling Lucky" aria-label="I'm Feeling Lucky" name="btnI" role="button" type="submit" data-ved="0ahUKEwi...">
    </center></div>
    </form></body></html>
    """
    with open(html_dir / "google_search.html", "w", encoding="utf-8") as f: f.write(google_html)
    # --- 一般的なニュース記事ページ ---
    news_html = """
    <!DOCTYPE html><html><head><title>ニュース記事</title></head><body>
    <header>サイトヘッダー</header><main><article>
    <h1 class="article-title main" itemprop="headline" role="heading" aria-level="1">今日のビッグニュース</h1>
    <div class="content body" role="article">
    <p>記事の本文がここに続きます...</p><p>さらなる段落。</p>
    <a href="/login" id="login-link" style="color: blue;" role="link">続きを読むにはログイン</a>
    </div><footer>
    <button class="share-button" data-testid="share-button" role="button">共有</button>
    <button role="button">コメント</button>
    </footer></article></main>
    <footer>サイトフッター</footer></body></html>
    """
    with open(html_dir / "news_article.html", "w", encoding="utf-8") as f: f.write(news_html)
    # --- Google検索結果ページ風HTML ---
    google_results_html = """
    <!DOCTYPE html><html><head><title>検索結果 - Google Search</title></head><body><div id="main"><div id="cnt"><div id="rcnt"><div id="center_col"><div id="res"><div id="search"><div id="rso">
    <!-- 検索結果 1 -->
    <div class="g Ww4FFb vt6azd tF2Cxc asEBEc"><div><div class="kb0PBd cvP2Ce jGGQ5e"><div class="yuRUbf"><div><span>
    <a href="https://example-result1.com/" role="link"><br><h3 class="LC20lb MBeuO DKV0Md" role="heading" aria-level="3">検索結果タイトル 1</h3><div><cite>example-result1.com</cite></div></a>
    </span></div></div></div><div class="VwiC3b"><span>検索結果の説明文1がここに入ります。</span></div></div></div>
    <!-- 検索結果 2 -->
    <div class="g Ww4FFb vt6azd tF2Cxc asEBEc"><div><div class="kb0PBd cvP2Ce jGGQ5e"><div class="yuRUbf">
    <a href="https://example-result2.net/" role="link"><h3 class="LC20lb MBeuO DKV0Md" role="heading" aria-level="3">Example Result 2</h3><cite>example-result2.net</cite></a>
    </div></div><div class="VwiC3b"><span>Description for the second result goes here.</span></div></div></div>
    </div><div id="botstuff"><div class="navigation">
    <a id="pnnext" href="/search?q=..." role="link"><span style="display:block;margin-left:53px">次へ</span></a>
    </div></div></div></div></div></div></div></div></body></html>
    """
    with open(html_dir / "google_results.html", "w", encoding="utf-8") as f: f.write(google_results_html)
    logging.info(f"テスト用HTMLファイルを '{html_dir}' に作成/更新しました。")

    #--- テスト実行関数 (評価ロジックを修正) ---

def run_all_tests():
    """定義されたすべてのテストケースを実行"""
    logging.info(">>> 要素情報抽出テストを開始します <<<")
    create_test_html_files()

    results = {"passed": 0, "failed": 0, "total": len(TEST_CASES)}
    failed_cases = []

    for case in TEST_CASES:
        print("=" * 50)
        logging.info(f"テストケース実行: {case['name']}")
        logging.info(f"指示: {case['instruction']}")
        logging.info(f"期待値:\n{json.dumps(case['expected_info'], ensure_ascii=False, indent=2)}")

        html_path = pathlib.Path(case['html_file'])
        if not html_path.exists():
            logging.error(f"  エラー: HTMLファイルが見つかりません: {html_path}")
            results["failed"] += 1
            failed_cases.append({"name": case['name'], "reason": "HTML file not found"})
            continue

        try:
            with open(html_path, 'r', encoding='utf-8') as f:
                html_content = f.read()
        except Exception as e:
            logging.error(f"  エラー: HTMLファイルの読み込みに失敗しました: {e}")
            results["failed"] += 1
            failed_cases.append({"name": case['name'], "reason": f"HTML read error: {e}"})
            continue

        # 要素情報抽出関数を呼び出し
        generated_info = extract_element_info(html_content, case['instruction'])

        # --- 結果の評価 ---
        expected = case['expected_info']
        passed = False
        reason = "Mismatch" # デフォルトの失敗理由

        if generated_info is None:
            reason = "LLM call failed or returned None"
            logging.error(f"  結果: 情報抽出に失敗しました ❌")
        elif isinstance(generated_info, dict) and "error" in generated_info:
            if "error" in expected and generated_info["error"] == expected["error"]:
                passed = True
                reason = "Expected error matched"
                logging.info(f"  結果: 期待通りエラーが返されました ✅ ({generated_info['error']})")
            else:
                reason = f"Unexpected error from LLM: {generated_info.get('error')}"
                logging.warning(f"  結果: LLMが予期しないエラーを返しました ❌ ({generated_info.get('error')})")
                logging.warning(f"    期待値: {expected}")
        elif isinstance(generated_info, dict):
            # ★★★ 期待値と生成値の比較 ★★★
            # ここでは単純に完全一致を見るが、より柔軟な比較も可能
            # 例えば、期待値に含まれるキーが生成値にも存在し、値が一致するかどうかなど
            if generated_info == expected:
                passed = True
                reason = "Exact match"
                logging.info(f"  結果: 完全に一致しました ✅")
            else:
                # 部分一致などの評価をここに入れることもできる
                # 例: 主要キー (text, role, index など) が一致するかチェック
                major_keys = ["text", "role", "index", "test_id"]
                partial_match = True
                mismatched_keys = []
                for key in major_keys:
                    if expected.get(key) != generated_info.get(key):
                        # index が両方 None の場合は一致とみなすなど、細かい調整が可能
                        if not (key == 'index' and expected.get(key) is None and generated_info.get(key) is None):
                            partial_match = False
                            mismatched_keys.append(key)

                if partial_match and not mismatched_keys: # 主要キーが一致
                    passed = True # 部分一致でも成功とみなす場合
                    reason = f"Partial match (Major keys matched)"
                    logging.info(f"  結果: 主要キーが一致しました (部分成功とみなす) ✅")
                    logging.debug(f"    生成値:\n{json.dumps(generated_info, ensure_ascii=False, indent=2)}")
                else:
                    reason = f"Mismatch (Keys: {mismatched_keys})"
                    logging.warning(f"  結果: 不一致 ❌ (Mismatched keys: {mismatched_keys})")
                    logging.warning(f"    期待値:\n{json.dumps(expected, ensure_ascii=False, indent=2)}")
                    logging.warning(f"    生成値:\n{json.dumps(generated_info, ensure_ascii=False, indent=2)}")
        else:
            reason = f"Unexpected return type: {type(generated_info)}"
            logging.error(f"  結果: 予期しない型が返されました ❌ ({type(generated_info)})")

        if passed:
            results["passed"] += 1
        else:
            results["failed"] += 1
            failed_cases.append({
                "name": case['name'],
                "reason": reason,
                "expected": expected,
                "generated": generated_info
            })
        print("-" * 30)

    print("=" * 50)
    logging.info(">>> 全テストケース完了 <<<")
    logging.info(f"結果: {results['passed']} / {results['total']} 件成功")
    if results['failed'] > 0:
        logging.warning(f"{results['failed']} 件失敗しました。")
        logging.warning("--- 失敗したケース詳細 ---")
        for failure in failed_cases:
            logging.warning(f"  Case: {failure['name']} ({failure['reason']})")
            # logging.warning(f"    Expected: {json.dumps(failure['expected'], ensure_ascii=False, indent=2)}")
            # logging.warning(f"    Generated: {json.dumps(failure['generated'], ensure_ascii=False, indent=2)}")
    print("=" * 50)


if __name__ == "__main__":
    run_all_tests()




---


- フォルダ名: .
- ファイル名: json_generator.html
- 内容:
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Playwright 入力データ ジェネレーター (JSON)</title>
    <style>
        /* --- スタイルは変更なし --- */
        body { font-family: sans-serif; line-height: 1.6; padding: 20px; max-width: 800px; margin: auto; }
        h1, h2 { border-bottom: 1px solid #ccc; padding-bottom: 5px; }
        label { display: block; margin-bottom: 5px; font-weight: bold; }
        input[type="text"], input[type="url"], input[type="number"], select, textarea {
            width: 95%;
            padding: 8px;
            margin-bottom: 15px;
            border: 1px solid #ccc;
            border-radius: 4px;
            box-sizing: border-box; /* paddingを含めて幅計算 */
        }
        button { padding: 10px 15px; background-color: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; margin-top: 10px; }
        button:hover { background-color: #0056b3; }
        button:disabled { background-color: #cccccc; cursor: not-allowed;}
        button.remove-step { background-color: #dc3545; margin-left: 10px; }
        button.remove-step:hover { background-color: #c82333; }
        .step { border: 1px solid #eee; padding: 15px; margin-bottom: 20px; border-radius: 5px; background-color: #f9f9f9; position: relative; }
        .step h3 { margin-top: 0; }
        .step .remove-step { position: absolute; top: 10px; right: 10px; padding: 5px 10px; font-size: 0.8em;}
        .form-group { margin-bottom: 15px; }
        .hidden { display: none; }
        .option-group label { display: inline-block; margin-right: 10px; font-weight: normal;}
        .option-group input[type="radio"] { margin-right: 5px;}
        #generated-json-container { margin-top: 20px; border: 1px solid #ddd; padding: 15px; background-color: #f0f0f0; border-radius: 5px;}
        #generated-json { display: block; white-space: pre-wrap; word-wrap: break-word; font-family: monospace; max-height: 500px; overflow-y: auto; }
        #error-message { color: red; font-weight: bold; margin-top: 10px; white-space: pre-wrap;}
        .loader { border: 4px solid #f3f3f3; border-radius: 50%; border-top: 4px solid #3498db; width: 20px; height: 20px; animation: spin 1s linear infinite; display: inline-block; vertical-align: middle; margin-left: 10px;}
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
        .button-container { display: flex; align-items: center; flex-wrap: wrap; margin-top: 20px; gap: 10px; }
        #copy-json-button { background-color: #28a745; }
        #copy-json-button:hover { background-color: #218838; }
        #download-json-button { background-color: #17a2b8; }
        #download-json-button:hover { background-color: #117a8b; }
         /* ▼▼▼ 追加: 属性名フィールド用の補足説明スタイル ▼▼▼ */
        .attribute-hint { font-size: 0.9em; color: #555; margin-top: -10px; margin-bottom: 10px;}
        /* ▲▲▲ 追加 ▲▲▲ */
    </style>
</head>
<body>

    <h1>Playwright 入力データ ジェネレーター (JSON)</h1>
    <p>Webサイトの自動化手順を入力し、Web-Runner 用の入力データ (<code>input.json</code>) を生成・ダウンロードします。</p>

    <form id="mcp-form">

        <h2>1. 開始URL</h2>
        <div class="form-group">
            <label for="start_url">自動化を開始するURL:</label>
            <input type="url" id="start_url" name="start_url" placeholder="https://example.com" required>
        </div>

        <h2>2. 操作ステップ</h2>
        <div id="steps-container">
            <!-- ステップ1 (初期表示用) -->
            <div class="step" data-step-index="0">
                <h3>ステップ 1 <button type="button" class="remove-step" onclick="removeStep(this)">削除</button></h3>
                 <!-- ▼▼▼ メモ欄を追加 ▼▼▼ -->
                <div class="form-group">
                    <label for="memo_0">メモ:</label>
                    <input type="text" id="memo_0" name="memo_0" placeholder="例: クリックする, contentを取得する, URLを取得する">
                    <small>※ このメモはJSONに保存されますが、実行時には無視されます。</small>
                </div>
                <!-- ▲▲▲ メモ欄を追加 ▲▲▲ -->
                <div class="form-group">
                    <label for="action_0">操作:</label>
                    <select id="action_0" name="action_0" required onchange="toggleActionFields(this)">
                        <option value="">-- 選択してください --</option>
                        <option value="click">要素をクリック (Click)</option>
                        <option value="input">要素に入力 (Input Text)</option>
                        <option value="hover">要素にマウスオーバー (Hover)</option>
                        <option value="get_inner_text">テキスト取得 (単一: innerText)</option>
                        <option value="get_text_content">テキスト取得 (単一: textContent)</option>
                        <option value="get_inner_html">HTML取得 (単一: innerHTML)</option>
                        <option value="get_attribute">属性値を取得 (単一: Get Attribute)</option>
                        <option value="get_all_attributes">属性値/コンテンツ取得 (複数: Get All Attribute)</option> <!-- 名称変更 -->
                        <option value="get_all_text_contents">テキストリストを取得 (複数: Get All textContents)</option>
                        <option value="wait_visible">要素が表示されるまで待つ (Wait Visible)</option>
                        <option value="select_option">ドロップダウンを選択 (Select Option)</option>
                        <option value="screenshot">スクリーンショットを撮る (Screenshot)</option>
                        <option value="scroll_page_to_bottom">ページ最下部へスクロール (Scroll Page Bottom)</option>
                        <option value="scroll_to_element">要素までスクロール (Scroll To Element)</option>
                        <option value="wait_page_load">ページ読み込み完了を待つ (Wait Page Load)</option>
                        <option value="sleep">指定時間待機 (Sleep)</option>
                        <option value="switch_to_iframe">iframe に切り替える (Switch to iframe)</option>
                        <option value="switch_to_parent_frame">親フレームに戻る (Switch to Parent Frame)</option>
                    </select>
                </div>
                <div class="form-group selector-group">
                    <label for="selector_0">対象要素のCSSセレクター:</label>
                    <input type="text" id="selector_0" name="selector_0" placeholder="#id, .class, tag[attribute=value]">
                    <small><br/>※ ページ全体操作(スクロール, 読み込み待機, sleep, 親フレームへ戻る)では不要</small>
                </div>
                 <!-- --- 各アクションの付加情報フィールド --- -->
                 <div class="form-group action-field iframe_selector-group hidden">
                    <label for="iframe_selector_0">iframeのCSSセレクター:</label>
                    <input type="text" id="iframe_selector_0" name="iframe_selector_0" placeholder="#frame-id, iframe[name=frame-name]">
                    <small>※ <code>switch_to_iframe</code> を選択した場合に必須</small>
                </div>
                <div class="form-group action-field input-field hidden">
                    <label for="value_0">入力するテキスト:</label>
                    <input type="text" id="value_0" name="value_0" placeholder="入力する値">
                </div>
                 <!-- ▼▼▼ get_attribute / get_all_attributes 用フィールド ▼▼▼ -->
                <div class="form-group action-field get_attribute-field hidden">
                    <label for="attribute_name_0">取得する属性名:</label>
                    <input type="text" id="attribute_name_0" name="attribute_name_0" placeholder="通常の属性名 (例: value, src, class)">
                     <!-- ▼▼▼ 補足説明を追加 ▼▼▼ -->
                    <small class="attribute-hint">
                        ※ <code>get_all_attributes</code> の場合、特別な値も指定可能:<br/>
                           ・ <strong><code>href</code></strong>: リンク先のURLリストを取得<br/>
                           ・ <strong><code>pdf</code></strong>: リンク先のPDFファイルの内容（テキスト）を取得<br/>
                           ・ <strong><code>content</code></strong>: リンク先ページの内容（innerText）を取得 (PDF以外)
                    </small>
                    <!-- ▲▲▲ 補足説明を追加 ▲▲▲ -->
                </div>
                <!-- ▲▲▲ get_attribute / get_all_attributes 用フィールド ▲▲▲ -->
                <div class="form-group action-field select_option-field hidden">
                    <label>ドロップダウン選択方法:</label>
                    <div class="option-group">
                         <label><input type="radio" name="option_type_0" value="value" checked> 値 (Value)</label>
                         <label><input type="radio" name="option_type_0" value="index"> インデックス (Index)</label>
                         <label><input type="radio" name="option_type_0" value="label"> 表示ラベル (Label)</label>
                    </div>
                    <label for="option_value_0">選択する値/インデックス/ラベル:</label>
                    <input type="text" id="option_value_0" name="option_value_0" placeholder="選択する項目">
                    <small>※ インデックスは0から始まる数値</small>
                </div>
                <div class="form-group action-field sleep-field hidden">
                    <label for="sleep_seconds_0">待機時間 (秒):</label>
                    <input type="number" id="sleep_seconds_0" name="sleep_seconds_0" placeholder="例: 3" step="0.1" min="0">
                </div>
                 <div class="form-group action-field screenshot-field hidden">
                    <label for="screenshot_filename_0">ファイル名 (任意):</label>
                    <input type="text" id="screenshot_filename_0" name="screenshot_filename_0" placeholder="例: screenshot_step1.png">
                 </div>
                 <div class="form-group action-field wait-field hidden">
                    <label for="wait_time_ms_0">最大待機時間 (ミリ秒、任意):</label>
                    <input type="number" id="wait_time_ms_0" name="wait_time_ms_0" placeholder="デフォルト値はサーバー設定" value="3000" min="1"> <!-- デフォルト値を更新 -->
                </div>
            </div>
        </div>
        <button type="button" id="add-step" onclick="addStep()">ステップを追加</button>

        <div class="button-container">
            <button type="button" id="generate-json-button" onclick="generateJsonData()">
                 入力データ生成 (JSON)
                 <span id="loading-indicator" class="loader hidden"></span>
            </button>
            <button type="button" id="copy-json-button" onclick="copyJson()" class="hidden">JSONをコピー</button>
            <button type="button" id="download-json-button" onclick="downloadJson()" class="hidden">input.json をダウンロード</button>
        </div>
    </form>

    <div id="generated-json-container" class="hidden">
        <h2>生成された入力データ (JSON):</h2>
        <pre><code id="generated-json"></code></pre>
    </div>
    <div id="error-message"></div>

    <script>
        function toggleActionFields(selectElement) {
            const stepDiv = selectElement.closest('.step');
            const action = selectElement.value;
            const stepIndex = stepDiv.dataset.stepIndex;

            stepDiv.querySelectorAll('.action-field').forEach(el => el.classList.add('hidden'));

            const selectorGroup = stepDiv.querySelector('.selector-group');
            const selectorInput = stepDiv.querySelector(`input[name="selector_${stepIndex}"]`);
            const iframeSelectorGroup = stepDiv.querySelector('.iframe_selector-group');
            const iframeSelectorInput = stepDiv.querySelector(`input[name="iframe_selector_${stepIndex}"]`);

            const noSelectorNeeded = ['scroll_page_to_bottom', 'wait_page_load', 'sleep', 'switch_to_parent_frame'];
            const iframeSelectorNeeded = ['switch_to_iframe'];
            const elementSelectorNeeded = !noSelectorNeeded.includes(action) && !iframeSelectorNeeded.includes(action);

            if (selectorGroup && selectorInput) {
                selectorGroup.classList.toggle('hidden', !elementSelectorNeeded);
                selectorInput.required = elementSelectorNeeded;
                selectorInput.disabled = !elementSelectorNeeded;
                if (!elementSelectorNeeded) selectorInput.value = '';
            }
            if (iframeSelectorGroup && iframeSelectorInput) {
                iframeSelectorGroup.classList.toggle('hidden', !iframeSelectorNeeded.includes(action));
                iframeSelectorInput.required = iframeSelectorNeeded.includes(action);
                iframeSelectorInput.disabled = !iframeSelectorNeeded.includes(action);
                if (!iframeSelectorNeeded.includes(action)) iframeSelectorInput.value = '';
            }

            const fieldsToShow = {
                'input': '.input-field',
                'get_attribute': '.get_attribute-field',
                'get_all_attributes': '.get_attribute-field', // 属性名入力フィールドを共用
                'select_option': '.select_option-field',
                'sleep': '.sleep-field',
                'screenshot': '.screenshot-field'
            };
             if (fieldsToShow[action]) {
                const fieldDiv = stepDiv.querySelector(fieldsToShow[action]);
                if (fieldDiv) fieldDiv.classList.remove('hidden');
            }

            const waitField = stepDiv.querySelector('.wait-field');
            if (waitField) {
                const showWait = elementSelectorNeeded || iframeSelectorNeeded.includes(action) || action === 'wait_page_load' || action === 'get_all_attributes'; // get_all_attributesでも待機時間表示
                waitField.classList.toggle('hidden', !showWait);
            }
        }

        // --- ステップ追加 (変更なし) ---
        function addStep() {
            const stepsContainer = document.getElementById('steps-container');
            const stepIndex = stepsContainer.children.length;
            const newStep = document.createElement('div');
            newStep.classList.add('step');
            newStep.dataset.stepIndex = stepIndex;
            const firstStepHtml = document.querySelector('.step[data-step-index="0"]').innerHTML;
            const stepContentHtml = firstStepHtml.replace(/<h3.*?<\/h3>/s, '');
            newStep.innerHTML = `<h3>ステップ ${stepIndex + 1} <button type="button" class="remove-step" onclick="removeStep(this)">削除</button></h3>` +
                                stepContentHtml.replace(/_0"/g, `_${stepIndex}"`).replace(/_0'/g, `_${stepIndex}'`).replace(/_0</g, `_${stepIndex}<`);
            stepsContainer.appendChild(newStep);
            newStep.querySelectorAll('input[type="text"], input[type="number"], input[type="url"]').forEach(input => input.value = '');
            newStep.querySelectorAll('select').forEach(select => select.selectedIndex = 0);
            newStep.querySelectorAll('input[type="radio"]').forEach((radio, idx) => radio.checked = (idx === 0));
            toggleActionFields(newStep.querySelector('select'));
            updateStepNumbers();
        }

        // --- ステップ削除 (変更なし) ---
        function removeStep(button) {
            const stepDiv = button.closest('.step');
            const stepsContainer = document.getElementById('steps-container');
            if (stepsContainer.children.length > 1) {
                stepDiv.remove();
                updateStepNumbers();
            } else {
                alert('最初のステップは削除できません。');
            }
        }

        // --- ステップ番号更新 (変更なし) ---
        function updateStepNumbers() {
            const steps = document.querySelectorAll('#steps-container .step');
            steps.forEach((step, index) => {
                step.dataset.stepIndex = index;
                step.querySelector('h3').firstChild.textContent = `ステップ ${index + 1} `;
                step.querySelectorAll('[id]').forEach(el => { el.id = el.id.replace(/_\d+$/, `_${index}`); });
                step.querySelectorAll('[name]').forEach(el => { el.name = el.name.replace(/_\d+$/, `_${index}`); });
                step.querySelectorAll('label[for]').forEach(el => { el.htmlFor = el.htmlFor.replace(/_\d+$/, `_${index}`); });
            });
        }

        // --- JSONデータ生成 (変更) ---
        function generateJsonData() {
            const form = document.getElementById('mcp-form');
            const generateButton = document.getElementById('generate-json-button');
            const loadingIndicator = document.getElementById('loading-indicator');
            const jsonContainer = document.getElementById('generated-json-container');
            const jsonElement = document.getElementById('generated-json');
            const errorElement = document.getElementById('error-message');
            const copyButton = document.getElementById('copy-json-button');
            const downloadButton = document.getElementById('download-json-button');

            generateButton.disabled = true;
            loadingIndicator.classList.remove('hidden');
            jsonElement.textContent = 'JSONデータ生成中...';
            errorElement.textContent = '';
            jsonContainer.classList.remove('hidden');
            copyButton?.classList.add('hidden');
            downloadButton?.classList.add('hidden');

            const outputData = {
                target_url: form.querySelector('#start_url')?.value,
                actions: []
            };

            let formIsValid = true;
            if (!outputData.target_url || !isValidHttpUrl(outputData.target_url)) {
                errorElement.textContent = '有効な開始URL (http:// または https://) を入力してください。';
                formIsValid = false;
            }

            const steps = document.querySelectorAll('#steps-container .step');
            steps.forEach((step, index) => {
                if (!formIsValid) return;
                const stepIndex = index;
                const actionSelect = step.querySelector(`select[name="action_${stepIndex}"]`);
                const action = actionSelect ? actionSelect.value : '';
                if (!action) { errorElement.textContent = `ステップ ${index + 1}: 操作を選択してください。`; formIsValid = false; return; }
                const actionData = { action: action };

                 // --- メモを追加 ---
                const memoInput = step.querySelector(`input[name="memo_${stepIndex}"]`);
                const memo = memoInput ? memoInput.value.trim() : '';
                if (memo) { actionData.memo = memo; }

                const noSelectorNeeded = ['scroll_page_to_bottom', 'wait_page_load', 'sleep', 'switch_to_parent_frame'];
                const iframeSelectorNeeded = ['switch_to_iframe'];
                const elementSelectorNeeded = !noSelectorNeeded.includes(action) && !iframeSelectorNeeded.includes(action);

                if (elementSelectorNeeded) {
                    const selectorInput = step.querySelector(`input[name="selector_${stepIndex}"]`);
                    const selector = selectorInput ? selectorInput.value.trim() : null;
                    if (!selector) { errorElement.textContent = `ステップ ${index + 1}: アクション '${action}' には要素のCSSセレクターが必要です。`; formIsValid = false; return; }
                    actionData.selector = selector;
                }
                if (iframeSelectorNeeded.includes(action)) {
                    const iframeSelectorInput = step.querySelector(`input[name="iframe_selector_${stepIndex}"]`);
                    const iframeSelector = iframeSelectorInput ? iframeSelectorInput.value.trim() : null;
                    if (!iframeSelector) { errorElement.textContent = `ステップ ${index + 1}: アクション '${action}' にはiframeのCSSセレクターが必要です。`; formIsValid = false; return; }
                    actionData.iframe_selector = iframeSelector;
                }

                const waitTimeoutInput = step.querySelector(`input[name="wait_time_ms_${stepIndex}"]`);
                if (waitTimeoutInput && waitTimeoutInput.value.trim() !== '') {
                    const timeout = parseInt(waitTimeoutInput.value.trim(), 10);
                    if (!isNaN(timeout) && timeout >= 1) { actionData.wait_time_ms = timeout; }
                    else { errorElement.textContent = `ステップ ${index + 1}: 待機時間は1以上の数値をミリ秒で入力してください。`; formIsValid = false; return; }
                }

                if (action === 'input') {
                    actionData.value = step.querySelector(`input[name="value_${stepIndex}"]`)?.value ?? '';
                } else if (action === 'get_attribute' || action === 'get_all_attributes') {
                    const attrName = step.querySelector(`input[name="attribute_name_${stepIndex}"]`)?.value.trim();
                    if (!attrName) { errorElement.textContent = `ステップ ${index + 1}: アクション '${action}' には取得する属性名が必要です。`; formIsValid = false; return; }
                    actionData.attribute_name = attrName;
                } else if (action === 'select_option') {
                    const optionType = step.querySelector(`input[name="option_type_${stepIndex}"]:checked`)?.value;
                    let optionValue = step.querySelector(`input[name="option_value_${stepIndex}"]`)?.value;
                    if (!optionType || optionValue === null || optionValue === undefined) { errorElement.textContent = `ステップ ${index + 1}: ドロップダウン選択方法と値を入力してください。`; formIsValid = false; return; }
                    actionData.option_type = optionType;
                    if (optionType === 'index') {
                        const indexVal = parseInt(optionValue, 10);
                        if (isNaN(indexVal) || indexVal < 0) { errorElement.textContent = `ステップ ${index + 1}: インデックスは0以上の数値を入力してください。`; formIsValid = false; return; }
                        actionData.option_value = indexVal;
                    } else { actionData.option_value = optionValue; }
                } else if (action === 'sleep') {
                    const secondsInput = step.querySelector(`input[name="sleep_seconds_${stepIndex}"]`);
                    if (!secondsInput || secondsInput.value.trim() === '') { errorElement.textContent = `ステップ ${index + 1}: sleep アクションには待機時間 (秒) が必要です。`; formIsValid = false; return; }
                    const seconds = parseFloat(secondsInput.value);
                    if (isNaN(seconds) || seconds < 0) { errorElement.textContent = `ステップ ${index + 1}: 待機時間は0以上の数値を秒で入力してください。`; formIsValid = false; return; }
                    actionData.value = seconds;
                } else if (action === 'screenshot') {
                    const filename = step.querySelector(`input[name="screenshot_filename_${stepIndex}"]`)?.value.trim();
                    actionData.value = filename || null;
                }
                outputData.actions.push(actionData);
            });

            if (!formIsValid) {
                jsonElement.textContent = '入力エラーがあります。フォームを確認してください。';
                generateButton.disabled = false;
                loadingIndicator.classList.add('hidden');
                copyButton?.classList.add('hidden');
                downloadButton?.classList.add('hidden');
                return;
            }

            const jsonString = JSON.stringify(outputData, null, 2);
            jsonElement.textContent = jsonString;
            errorElement.textContent = '';
            copyButton?.classList.remove('hidden');
            downloadButton?.classList.remove('hidden');
            generateButton.disabled = false;
            loadingIndicator.classList.add('hidden');
        }

        // URL簡易バリデーション
        function isValidHttpUrl(string) { try { const url = new URL(string); return url.protocol === "http:" || url.protocol === "https:"; } catch (_) { return false; } }

        // JSONコピー
        function copyJson() {
            const jsonElement = document.getElementById('generated-json');
            if (!jsonElement || !jsonElement.textContent || jsonElement.textContent.startsWith('JSON') || jsonElement.textContent.startsWith('入力エラー')) { alert('コピーする有効なJSONデータがありません。'); return; }
            navigator.clipboard.writeText(jsonElement.textContent).then(() => alert('JSONデータがクリップボードにコピーされました！')).catch(err => { alert('コピーに失敗しました。コンソールを確認してください。'); console.error('Copy failed:', err); });
        }

        // JSONダウンロード
        function downloadJson() {
            const jsonElement = document.getElementById('generated-json');
            const jsonString = jsonElement.textContent;
            if (!jsonString || jsonString.startsWith('JSON') || jsonString.startsWith('入力エラー')) { alert('ダウンロードする有効なJSONデータがありません。'); return; }
            try {
                const blob = new Blob([jsonString], { type: 'application/json' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'input.json'; // ファイル名を input.json に固定
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            } catch (error) { alert('ダウンロードに失敗しました。'); console.error('Download failed', error); }
        }

        // 初期表示時のフィールド更新
        document.addEventListener('DOMContentLoaded', () => {
             document.querySelectorAll('.step').forEach(step => {
                 const select = step.querySelector('select');
                 if (select) toggleActionFields(select);
             });
         });
    </script>

</body>
</html>


---


- フォルダ名: .
- ファイル名: main.py
- 内容:
# --- ファイル: main.py (修正版) ---
"""
スクリプトのエントリーポイント。引数解析、初期化、実行、結果出力を行う。
MCPサーバーとは独立して、このファイル単体でも実行可能。
"""
import argparse
import asyncio
import logging
import os
import sys
import pprint

# --- 各モジュールをインポート ---
import config
import utils
# --- ▼▼▼ 修正 ▼▼▼ ---
# import playwright_handler -> playwright_launcher をインポート
import playwright_launcher
# --- ▲▲▲ 修正 ▲▲▲ ---

# --- エントリーポイント ---
if __name__ == "__main__":
    # --- 1. ロギング設定 (単体実行用) ---
    # --- ▼▼▼ 修正 ▼▼▼ ---
    # ログファイルのパスを MCP_SERVER_LOG_FILE に変更
    utils.setup_logging_for_standalone(config.MCP_SERVER_LOG_FILE)
    # --- ▲▲▲ 修正 ▲▲▲ ---

    # --- 2. コマンドライン引数解析 ---
    parser = argparse.ArgumentParser(
        description="JSON入力に基づき Playwright 自動化を実行 (iframe動的探索対応)。",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "--input",
        default=config.DEFAULT_INPUT_FILE,
        metavar="FILE",
        help="URL とアクションを含む JSON ファイルのパス。"
    )
    parser.add_argument(
        '--headless',
        action=argparse.BooleanOptionalAction, # --headless / --no-headless を使えるように
        default=False, # デフォルトは表示 (False)
        help="ブラウザをヘッドレスモードで実行 (--no-headless で表示)。"
    )
    parser.add_argument(
        '--slowmo',
        type=int,
        default=100,
        metavar="MS",
        help="各操作間の待機時間(ms)。"
    )
    args = parser.parse_args()

    # --- 3. 入力ファイルパス解決 ---
    input_arg = args.input
    json_file_path = input_arg
    # 入力がファイル名のみで、json/ ディレクトリに存在する場合、そちらを優先
    if not os.path.isabs(input_arg) and \
       not os.path.dirname(input_arg) and \
       os.path.exists(os.path.join('json', input_arg)):
        json_file_path = os.path.join('json', input_arg)
        logging.info(f"--input でファイル名のみ指定され、'json' ディレクトリ内に '{input_arg}' が見つかったため、'{json_file_path}' を使用します。")
    elif not os.path.exists(input_arg):
        logging.critical(f"指定された入力ファイル '{input_arg}' が見つかりません。") # criticalに変更
        sys.exit(1) # 単体実行時は見つからなければ終了

    # スクリーンショットディレクトリ作成
    os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)

    # --- 4. メイン処理実行 ---
    try:
        input_data = utils.load_input_from_json(json_file_path)
        target_url = input_data.get("target_url")
        actions = input_data.get("actions")

        # JSONファイル内のタイムアウト指定を優先、なければconfigの値
        effective_default_timeout = input_data.get("default_timeout_ms", config.DEFAULT_ACTION_TIMEOUT)
        logging.info(f"実行に使用するデフォルトアクションタイムアウト: {effective_default_timeout}ms")

        if not target_url or not actions:
            logging.critical(f"エラー: JSON '{json_file_path}' から target_url または actions を取得できませんでした。")
            sys.exit(1)

        # --- ▼▼▼ 修正 ▼▼▼ ---
        # Playwrightハンドラ -> ランチャー を呼び出し
        success, results = asyncio.run(playwright_launcher.run_playwright_automation_async(
            target_url=str(target_url), # URLは文字列として渡す
            actions=actions,
            headless_mode=args.headless, # BooleanOptionalAction の結果を渡す
            slow_motion=args.slowmo,
            default_timeout=effective_default_timeout
        ))
        # --- ▲▲▲ 修正 ▲▲▲ ---

        # --- 5. 結果表示・出力 ---
        print("\n--- 最終実行結果 ---")
        # pprintで見やすく整形して表示
        pprint.pprint(results)
        logging.info(f"最終実行結果(詳細):\n{pprint.pformat(results)}")

        # 結果ファイル書き込み (utils内の関数を使用)
        utils.write_results_to_file(results, config.RESULTS_OUTPUT_FILE) # 単体実行用出力ファイル

        sys.exit(0 if success else 1)

    except FileNotFoundError as e:
         logging.critical(f"入力ファイル処理中にエラー: {e}")
         sys.exit(1)
    except Exception as e:
        logging.critical(f"スクリプト実行の最上位で予期せぬエラーが発生: {e}", exc_info=True)
        sys.exit(1)


---


- フォルダ名: .
- ファイル名: output_results.txt
- 内容:
--- Web Runner 実行結果 ---

--- Step 1: click (success) ---
Selector: #searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)
New page did not open within timeout.

--- Step 2: select_option (success) ---
Selector: #searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)
Other Details:
  option_type: index
  option_value: 7

--- Step 3: input (success) ---
Selector: #freewordtxt
Other Details:
  value: 不動産

--- Step 4: click (success) ---
Selector: #searchbtn > img
New page did not open within timeout.

--- Step 5: get_all_text_contents (success) ---
Selector: tr td.title a
Result Text List (24 items):
- 完全子会社の吸収合併（簡易合併・略式合併）に関するお知らせ
- コミットメントラインの契約期間延長に関するお知らせ
- クラウドファンディングでのファンド組成に係る販売用不動産の取得に関するお知らせ
- 資金の借入れに関するお知らせ
- 2025年2月期　決算短信(REIT)
- 2025年2月期（第23期）決算説明資料
- 規約の一部変更及び役員の選任に関するお知らせ
- （訂正）「住友林業株式会社による当社株式に対する公開買付けに関する意見表明のお知らせ」の一部訂正について
- 販売用不動産取得のお知らせ
- 販売用不動産の売却に関するお知らせ
- 販売用不動産の売買契約の締結に関するお知らせ
- 資金の借入れ（借換え）に関するお知らせ
- 賃貸用不動産の保有目的の変更に関するお知らせ
- 金利スワップ契約の締結に関するお知らせ
- 資金の借入れに関するお知らせ
- 国内資産の譲渡に関するお知らせ（ＨＦ東新宿レジデンス、ＨＦ東心斎橋レジデンス）
- 本日付公表の適時開示に関する補足説明資料
- 2025年5月期（第47期）及び2025年11月期（第48期）の運用状況の予想の修正に関するお知らせ
- （訂正）「国内資産の取得及び譲渡に関するお知らせ」及び「本日付公表の適時開示に関する補足説明資料」の一部訂正に関するお知らせ
- 国内不動産信託受益権の取得及び貸借並びに譲渡に関するお知らせ
- 今後の成長戦略に関する説明資料
- 子会社の事業の全部休止、開発用不動産の減損損失並びに株式交換関連費用の発生、及びこれらに伴う特別損失の計上に関するお知らせ
- 販売用不動産の売却に関するお知らせ
- 投資法人債（グリーンボンド）の発行に関するお知らせ

--- Step 6: get_all_attributes (success) ---
Selector: .title a
Requested Attribute/Content: href
Results (24 items processed):
  Processed URLs (24):
    [1] https://www.release.tdnet.info/inbs/140120250415516437.pdf
    [2] https://www.release.tdnet.info/inbs/140120250415516016.pdf
    [3] https://www.release.tdnet.info/inbs/140120250411513862.pdf
    [4] https://www.release.tdnet.info/inbs/140120250415515850.pdf
    [5] https://www.release.tdnet.info/inbs/140120250414514976.pdf
    [6] https://www.release.tdnet.info/inbs/140120250414515595.pdf
    [7] https://www.release.tdnet.info/inbs/140120250414515589.pdf
    [8] https://www.release.tdnet.info/inbs/140120250414515451.pdf
    [9] https://www.release.tdnet.info/inbs/140120250411513609.pdf
    [10] https://www.release.tdnet.info/inbs/140120250410513021.pdf
    [11] https://www.release.tdnet.info/inbs/140120250411513381.pdf
    [12] https://www.release.tdnet.info/inbs/140120250411513190.pdf
    [13] https://www.release.tdnet.info/inbs/140120250411513651.pdf
    [14] https://www.release.tdnet.info/inbs/140120250411513868.pdf
    [15] https://www.release.tdnet.info/inbs/140120250411513346.pdf
    [16] https://www.release.tdnet.info/inbs/140120250410512822.pdf
    [17] https://www.release.tdnet.info/inbs/140120250410512824.pdf
    [18] https://www.release.tdnet.info/inbs/140120250410512830.pdf
    [19] https://www.release.tdnet.info/inbs/140120250410512832.pdf
    [20] https://www.release.tdnet.info/inbs/140120250409511912.pdf
    [21] https://www.release.tdnet.info/inbs/140120250409511914.pdf
    [22] https://www.release.tdnet.info/inbs/140120250410512673.pdf
    [23] https://www.release.tdnet.info/inbs/140120250410512662.pdf
    [24] https://www.release.tdnet.info/inbs/140120250409511555.pdf




---


- フォルダ名: .
- ファイル名: playwright_actions.py
- 内容:
# --- ファイル: playwright_actions.py (SyntaxError再修正 + 整形版) ---
import asyncio
import logging
import os
import time
import pprint
import traceback
import re
from urllib.parse import urljoin, urlparse
from typing import List, Tuple, Optional, Union, Dict, Any, Set

from playwright.async_api import (
    Page,
    Frame,
    Locator,
    FrameLocator,
    BrowserContext,
    TimeoutError as PlaywrightTimeoutError,
    Error as PlaywrightError,
    APIRequestContext
)

import config
import utils
from playwright_finders import find_element_dynamically, find_all_elements_dynamically
from playwright_helper_funcs import get_page_inner_text

logger = logging.getLogger(__name__)

# --- メールアドレス抽出用ヘルパー関数 ---
EMAIL_REGEX = re.compile(r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}")
async def _extract_emails_from_page_async(context: BrowserContext, url: str, timeout: int) -> List[str]:
    """指定されたURLからメールアドレスを抽出するヘルパー"""
    page = None
    emails_found: Set[str] = set()
    start_time = time.monotonic()
    page_access_timeout = max(int(timeout * 0.8), 15000)
    logger.info(f"URLからメール抽出開始: {url} (タイムアウト: {page_access_timeout}ms)")
    try:
        page = await context.new_page()
        nav_timeout = max(int(page_access_timeout * 0.9), 10000)
        await page.goto(url, wait_until="load", timeout=nav_timeout)
        remaining_time_for_text = page_access_timeout - (time.monotonic() - start_time) * 1000
        if remaining_time_for_text <= 1000: raise PlaywrightTimeoutError("Not enough time for text extraction")
        text_timeout = int(remaining_time_for_text)
        page_text = await page.locator(':root').inner_text(timeout=text_timeout)
        if page_text:
            found_in_text = EMAIL_REGEX.findall(page_text)
            if found_in_text: emails_found.update(found_in_text)
        mailto_links = await page.locator("a[href^='mailto:']").all()
        if mailto_links:
            for link in mailto_links:
                try:
                    href = await link.get_attribute('href', timeout=500)
                    if href and href.startswith('mailto:'):
                        email_part = href[len('mailto:'):].split('?')[0]
                        if email_part and EMAIL_REGEX.match(email_part): emails_found.add(email_part)
                except Exception: pass # Ignore errors for single mailto links
        elapsed = (time.monotonic() - start_time) * 1000
        logger.info(f"メール抽出完了 ({url}). ユニーク候補: {len(emails_found)} ({elapsed:.0f}ms)")
        return list(emails_found)
    except Exception as e: logger.warning(f"メール抽出エラー ({url}): {e}"); return []
    finally:
        if page and not page.is_closed():
            try: await page.close()
            except Exception: pass

# --- Locator試行ヘルパー関数 ---
async def try_locators_sequentially(
    target_scope: Union[Page, FrameLocator],
    hints: List[Dict[str, Any]],
    action_name: str,
    overall_timeout: int
) -> Tuple[Optional[Locator], Optional[Dict[str, Any]], List[Dict[str, Any]]]:
    """ヒントリストに基づいてLocatorを順番に試し、最初に見つかった有効なLocatorを返す。"""
    start_time = time.monotonic()
    successful_locator: Optional[Locator] = None
    successful_hint: Optional[Dict[str, Any]] = None
    attempt_logs: List[Dict[str, Any]] = []
    hint_count = len(hints) if hints else 1
    base_validation_timeout = max(500, min(2000, overall_timeout // hint_count))
    logger.info(f"[{action_name}] Trying {len(hints)} locator hints (overall timeout: {overall_timeout}ms, base validation timeout: {base_validation_timeout}ms)...")
    hints.sort(key=lambda x: {"high": 0, "medium": 1, "low": 2}.get(x.get("confidence", "low"), 2))

    for i, hint in enumerate(hints):
        elapsed_ms = (time.monotonic() - start_time) * 1000
        if elapsed_ms >= overall_timeout: logger.warning(f"[{action_name}] Overall timeout reached."); break
        remaining_ms = overall_timeout - elapsed_ms
        current_validation_timeout = min(base_validation_timeout, max(100, int(remaining_ms * 0.8)))

        hint_type = hint.get("type")
        hint_value = hint.get("value")
        hint_name = hint.get("name")
        hint_level = hint.get("level")
        hint_common_selector = hint.get("common_selector")
        hint_index = hint.get("index")
        hint_confidence = hint.get("confidence", "low")

        locator_description = f"Hint {i+1}: type={hint_type}, confidence={hint_confidence}"
        logging.info(f"  Trying: {locator_description} (value: {str(hint_value)[:50]}{'...' if len(str(hint_value)) > 50 else ''})")
        attempt_log = {"hint": hint, "status": "Skipped", "reason": "No locator generated"}
        locator_to_try: Optional[Locator] = None

        try:
            options = {}
            if hint_type == "role_and_text" and isinstance(hint_value, str):
                 role = hint_value
                 if isinstance(hint_name, str):
                     if hint_name.startswith('/') and hint_name.endswith('/') and len(hint_name) > 2:
                          try:
                              regex_pattern = hint_name[1:-1]
                              options["name"] = re.compile(regex_pattern, re.IGNORECASE)
                              logging.debug(f"    Using get_by_role with regex name: {options['name']}")
                          except re.error as re_err:
                              logging.warning(f"    Invalid regex pattern: {hint_name} - {re_err}")
                              options["name"] = "INVALID_REGEX_!@#$" # Match nothing
                     else:
                          options["name"] = hint_name
                          logging.debug(f"    Using get_by_role with exact name: {options['name']}")
                 if role == "heading" and isinstance(hint_level, int): options["level"] = hint_level
                 if isinstance(role, str) and role: locator_to_try = target_scope.get_by_role(role, **options)
                 else: logging.warning(f"    Invalid role value: {role}"); attempt_log["reason"] = f"Invalid role value: {role}"
            elif hint_type == "test_id" and isinstance(hint_value, str): locator_to_try = target_scope.get_by_test_id(hint_value)
            elif hint_type == "text_exact" and isinstance(hint_value, str): locator_to_try = target_scope.get_by_text(hint_value, exact=True)
            elif hint_type == "placeholder" and isinstance(hint_value, str): locator_to_try = target_scope.get_by_placeholder(hint_value)
            elif hint_type == "aria_label" and isinstance(hint_value, str): locator_to_try = target_scope.get_by_label(hint_value, exact=True)
            elif hint_type == "css_selector_candidate" and isinstance(hint_value, str): locator_to_try = target_scope.locator(hint_value)
            elif hint_type == "nth_child" and isinstance(hint_common_selector, str) and isinstance(hint_index, int) and hint_index >= 0:
                locator_to_try = target_scope.locator(hint_common_selector).nth(hint_index)
            else: attempt_log["reason"] = f"Invalid hint data: {hint}"; logging.warning(f"    -> Invalid hint data: {hint}")

            if locator_to_try:
                attempt_log["reason"] = "Checking validity..."
                try: attempt_log["final_selector_attempted"] = repr(locator_to_try)
                except: attempt_log["final_selector_attempted"] = "repr failed"
                count = await locator_to_try.count()
                attempt_log["count"] = count; logging.debug(f"    -> Count: {count}")
                if count == 1:
                    is_visible = False
                    try: await locator_to_try.wait_for(state='visible', timeout=current_validation_timeout); is_visible = True; logging.debug("    -> Visible.")
                    except PlaywrightTimeoutError: logging.debug("    -> Not visible within timeout.")
                    except Exception as vis_err: logging.warning(f"    -> Visibility check error: {vis_err}")
                    attempt_log["is_visible"] = is_visible
                    if is_visible:
                        successful_locator = locator_to_try; successful_hint = hint
                        attempt_log["status"] = "Success"; attempt_log["reason"] = "Found unique and visible element."
                        logging.info(f"    -> Success! Found element.")
                        attempt_logs.append(attempt_log); break
                    else: attempt_log["status"] = "Fail"; attempt_log["reason"] = "Element found but not visible."; logging.info(f"    -> Element found but not visible.")
                elif count > 1: attempt_log["status"] = "Fail"; attempt_log["reason"] = f"Multiple elements found ({count})."; logging.info(f"    -> Multiple elements found ({count}).")
                else: attempt_log["status"] = "Fail"; attempt_log["reason"] = "Element not found."; logging.info(f"    -> Element not found.")
            else: attempt_log["status"] = "Fail"
        except PlaywrightError as e: attempt_log["status"] = "Error"; attempt_log["reason"] = f"PlaywrightError: {e}"; logging.warning(f"    -> PlaywrightError: {e}")
        except Exception as e: attempt_log["status"] = "Error"; attempt_log["reason"] = f"Unexpected Error: {e}"; logging.warning(f"    -> Unexpected error: {e}"); logging.debug(traceback.format_exc())
        attempt_logs.append(attempt_log)

    if successful_locator: logger.info(f"[{action_name}] Located element using hint: {successful_hint}")
    else: logger.warning(f"[{action_name}] Failed to locate element.")
    return successful_locator, successful_hint, attempt_logs


# --- execute_actions_async 本体 ---
async def execute_actions_async(
    initial_page: Page,
    actions: List[Dict[str, Any]],
    api_request_context: APIRequestContext,
    default_timeout: int
) -> Tuple[bool, List[Dict[str, Any]]]:
    results: List[Dict[str, Any]] = []
    current_target: Union[Page, FrameLocator] = initial_page
    root_page: Page = initial_page
    current_context: BrowserContext = root_page.context
    iframe_stack: List[Union[Page, FrameLocator]] = []

    for i, step_data in enumerate(actions):
        step_num = i + 1
        action = step_data.get("action", "").lower()
        selector = step_data.get("selector")
        target_hints = step_data.get("target_hints")
        iframe_selector_input = step_data.get("iframe_selector")
        value = step_data.get("value")
        attribute_name = step_data.get("attribute_name")
        option_type = step_data.get("option_type")
        option_value = step_data.get("option_value")
        action_wait_time = step_data.get("wait_time_ms", default_timeout)

        logger.info(f"--- ステップ {step_num}/{len(actions)}: Action='{action}' ---")
        step_info = {
            "selector": selector, "target_hints_count": len(target_hints) if isinstance(target_hints, list) else None,
            "iframe(指定)": iframe_selector_input, "value": value, "attribute_name": attribute_name,
            "option_type": option_type, "option_value": option_value,
        }
        step_info_str = ", ".join([f"{k}='{str(v)[:50]}...'" if len(str(v)) > 50 else f"{k}='{v}'"
                                   for k, v in step_info.items() if v is not None])
        logger.info(f"詳細: {step_info_str} (timeout: {action_wait_time}ms)")
        if isinstance(target_hints, list): logger.debug(f"Target Hints:\n{pprint.pformat(target_hints)}")

        step_result_base = {"step": step_num, "action": action}
        if step_data.get("memo"): step_result_base["memo"] = step_data["memo"]

        try:
            if root_page.is_closed(): raise PlaywrightError(f"Root page closed.")
            current_base_url = root_page.url

            # --- Iframe/Parent Frame 切替 ---
            if action == "switch_to_iframe":
                if not iframe_selector_input: raise ValueError("iframe_selector required.")
                logger.info(f"Switching to iframe: {iframe_selector_input}")
                target_frame_locator = current_target.frame_locator(iframe_selector_input)
                try: await target_frame_locator.locator(':root').wait_for(state='attached', timeout=action_wait_time)
                except PlaywrightTimeoutError as e: raise PlaywrightTimeoutError(f"Iframe '{iframe_selector_input}' not found: {e}")
                if id(current_target) not in [id(s) for s in iframe_stack]: iframe_stack.append(current_target)
                current_target = target_frame_locator; logger.info(f"Switched to FrameLocator.")
                results.append({**step_result_base, "status": "success", "selector": iframe_selector_input}); continue
            elif action == "switch_to_parent_frame":
                status="warning"; message=None
                if not iframe_stack: logger.warning("Already at top-level."); message="Already at top-level..."
                else: current_target = iframe_stack.pop(); logger.info(f"Switched to parent: {type(current_target).__name__}"); status="success"
                if status == "warning" and isinstance(current_target, FrameLocator): current_target = root_page
                results.append({**step_result_base, "status": status, "message": message}); continue

            # --- ページ全体操作 ---
            if action in ["wait_page_load", "sleep", "scroll_page_to_bottom"]:
                 if action == "wait_page_load": await root_page.wait_for_load_state("load", timeout=action_wait_time); logger.info("Page load complete.")
                 elif action == "sleep":
                     try: seconds = float(value); assert seconds >= 0
                     except: raise ValueError("Invalid sleep value.")
                     await asyncio.sleep(seconds); logger.info(f"Slept for {seconds}s.")
                     results.append({**step_result_base, "status": "success", "duration_sec": seconds}); continue
                 elif action == "scroll_page_to_bottom": await root_page.evaluate('window.scrollTo(0, document.body.scrollHeight)'); await asyncio.sleep(0.5); logger.info("Scrolled to bottom.")
                 results.append({**step_result_base, "status": "success"}); continue

            # --- 要素操作準備 ---
            target_element: Optional[Locator] = None
            successful_hint_info: Optional[Dict[str, Any]] = None
            locator_attempt_logs: List[Dict[str, Any]] = []
            found_elements_list: List[Tuple[Locator, Union[Page, FrameLocator]]] = []
            found_scope: Optional[Union[Page, FrameLocator]] = None

            single_element_actions = ["click", "input", "hover", "get_inner_text", "get_text_content", "get_inner_html", "get_attribute", "wait_visible", "select_option", "scroll_to_element"]
            multiple_elements_actions = ["get_all_attributes", "get_all_text_contents"]
            is_screenshot_action = action == "screenshot"
            needs_single_element = action in single_element_actions or (is_screenshot_action and (target_hints or selector))
            needs_multiple_elements = action in multiple_elements_actions

            # --- 要素特定 ---
            if needs_single_element:
                if target_hints and isinstance(target_hints, list) and target_hints:
                    logger.info(f"Locating element based on target_hints...")
                    target_element, successful_hint_info, locator_attempt_logs = await try_locators_sequentially( current_target, target_hints, action, action_wait_time )
                    step_result_base["locator_attempts"] = locator_attempt_logs
                    if not target_element: raise PlaywrightError(f"Failed to locate element using provided hints.")
                    step_result_base["locator_hint_used"] = successful_hint_info
                elif selector:
                    required_state = 'visible' if action in ['click', 'hover', 'input', 'wait_visible', 'select_option', 'scroll_to_element', 'screenshot'] else 'attached'
                    logger.info(f"Locating element using selector '{selector}' (state: {required_state})...")
                    target_element, found_scope = await find_element_dynamically( current_target, selector, max_depth=config.DYNAMIC_SEARCH_MAX_DEPTH, timeout=action_wait_time, target_state=required_state )
                    if not target_element or not found_scope: raise PlaywrightError(f"Element '{selector}' ({required_state}) not found dynamically.")
                    step_result_base["selector"] = selector
                    if id(found_scope) != id(current_target):
                         logger.info(f"Scope updated to: {type(found_scope).__name__}")
                         if id(current_target) not in [id(s) for s in iframe_stack]: iframe_stack.append(current_target)
                         current_target = found_scope
                    logger.info(f"Final operating scope: {type(current_target).__name__}")
                else: raise ValueError(f"Action '{action}' requires 'target_hints' or 'selector'.")
            elif needs_multiple_elements:
                if not selector: raise ValueError(f"Action '{action}' requires a 'selector'.")
                logger.info(f"Locating multiple elements using selector '{selector}'...")
                found_elements_list = await find_all_elements_dynamically( current_target, selector, max_depth=config.DYNAMIC_SEARCH_MAX_DEPTH, timeout=action_wait_time )
                if not found_elements_list: logger.warning(f"Element(s) for '{selector}' not found.")
                step_result_base["selector"] = selector

            # --- 各アクション実行 ---
            action_result_details = {}

            if action == "click":
                if not target_element: raise ValueError("Click requires located element.")
                logger.info("Clicking element...")
                context_for_click = root_page.context; new_page: Optional[Page] = None
                try:
                    async with context_for_click.expect_page(timeout=config.NEW_PAGE_EVENT_TIMEOUT) as new_page_info:
                        await target_element.click(timeout=action_wait_time)
                    new_page = await new_page_info.value; new_page_url = new_page.url; logger.info(f"New page opened: {new_page_url}")
                    try: await new_page.wait_for_load_state("load", timeout=action_wait_time)
                    except PlaywrightTimeoutError: logger.warning(f"New page load timeout.")
                    root_page = new_page; current_target = new_page; current_context = new_page.context; iframe_stack.clear()
                    action_result_details.update({"new_page_opened": True, "new_page_url": new_page_url})
                except PlaywrightTimeoutError: logger.info(f"No new page opened."); action_result_details["new_page_opened"] = False
                except Exception as click_err: logger.error(f"Click error: {click_err}", exc_info=True); raise click_err

            elif action == "input":
                 if not target_element: raise ValueError("Input requires located element.")
                 if value is None: raise ValueError("Input requires 'value'.")
                 await target_element.fill(str(value), timeout=action_wait_time); logger.info("Input success.")
                 action_result_details["value"] = value

            elif action == "hover":
                 if not target_element: raise ValueError("Hover requires located element.")
                 await target_element.hover(timeout=action_wait_time); logger.info("Hover success.")

            elif action == "get_inner_text":
                 if not target_element: raise ValueError("Get innerText requires located element.")
                 text = await target_element.inner_text(timeout=action_wait_time); text = text.strip() if text else ""
                 logger.info(f"Got innerText: '{text[:100]}...'"); action_result_details["text"] = text

            elif action == "get_text_content":
                 if not target_element: raise ValueError("Get textContent requires located element.")
                 text = await target_element.text_content(timeout=action_wait_time); text = text.strip() if text else ""
                 logger.info(f"Got textContent: '{text[:100]}...'"); action_result_details["text"] = text

            elif action == "get_inner_html":
                 if not target_element: raise ValueError("Get innerHTML requires located element.")
                 html_content = await target_element.inner_html(timeout=action_wait_time)
                 logger.info(f"Got innerHTML: {html_content[:500]}..."); action_result_details["html"] = html_content

            elif action == "get_attribute":
                if not target_element: raise ValueError("Get attribute requires located element.")
                if not attribute_name: raise ValueError("Get attribute requires 'attribute_name'.")
                attr_value = await target_element.get_attribute(attribute_name, timeout=action_wait_time)
                pdf_text_content = None; processed_value = attr_value
                if attribute_name.lower() == 'href' and attr_value is not None:
                     try:
                         absolute_url = urljoin(current_base_url, attr_value); processed_value = absolute_url
                         if absolute_url.lower().endswith('.pdf'):
                             pdf_bytes = await utils.download_pdf_async(api_request_context, absolute_url)
                             if pdf_bytes: pdf_text_content = await asyncio.to_thread(utils.extract_text_from_pdf_sync, pdf_bytes)
                             else: pdf_text_content = "Error: PDF download failed."
                     except Exception as url_e: logger.error(f"URL/PDF error: {url_e}"); pdf_text_content = f"Error: {url_e}"
                logger.info(f"Got attribute '{attribute_name}': '{processed_value}'")
                action_result_details.update({"attribute": attribute_name, "value": processed_value})
                if pdf_text_content is not None: action_result_details["pdf_text"] = pdf_text_content

            elif action == "get_all_attributes":
                if not selector: raise ValueError("get_all_attributes requires 'selector'.")
                if not attribute_name: raise ValueError("get_all_attributes requires 'attribute_name'.")
                if not found_elements_list: logger.warning(f"No elements for '{selector}'."); action_result_details["results_count"] = 0
                else:
                    num_found = len(found_elements_list); logger.info(f"Getting '{attribute_name}' from {num_found} elements...")
                    url_list, pdf_list, content_list, mail_list, generic_list = [],[],[],[],[]
                    if attribute_name.lower() in ['href', 'pdf', 'content', 'mail']:
                        CONCURRENT_LIMIT=5; semaphore=asyncio.Semaphore(CONCURRENT_LIMIT)
                        async def process_single_element_for_href_related(locator: Locator, index: int, base_url: str, attr_mode: str, sem: asyncio.Semaphore) -> Tuple[Optional[str], Optional[str], Optional[str], Optional[List[str]]]:
                            original_href: Optional[str] = None; absolute_url: Optional[str] = None
                            pdf_text: Optional[str] = None; scraped_text: Optional[str] = None
                            emails_from_page: Optional[List[str]] = None
                            async with sem:
                                try:
                                    href_timeout = max(500, action_wait_time // num_found if num_found > 5 else action_wait_time // 3)
                                    original_href = await locator.get_attribute("href", timeout=href_timeout)
                                    if original_href is None: return None, None, None, None
                                    try:
                                        absolute_url = urljoin(base_url, original_href); parsed_url = urlparse(absolute_url)
                                        if parsed_url.scheme not in ['http', 'https']: return absolute_url, None, None, None
                                    except Exception: return f"Error converting URL: {original_href}", None, None, None
                                    if attr_mode == 'pdf' and absolute_url.lower().endswith('.pdf'):
                                         pdf_bytes = await utils.download_pdf_async(api_request_context, absolute_url)
                                         if pdf_bytes: pdf_text = await asyncio.to_thread(utils.extract_text_from_pdf_sync, pdf_bytes)
                                         else: pdf_text = "Error: PDF download failed."
                                    elif attr_mode == 'content' and not absolute_url.lower().endswith('.pdf'):
                                         success, content_or_error = await get_page_inner_text(current_context, absolute_url, action_wait_time); scraped_text = content_or_error
                                    elif attr_mode == 'mail': emails_from_page = await _extract_emails_from_page_async(current_context, absolute_url, action_wait_time)
                                    return absolute_url, pdf_text, scraped_text, emails_from_page
                                except Exception as e: return f"Error: {type(e).__name__}", None, None, None
                        tasks = [process_single_element_for_href_related(loc, idx, current_base_url, attribute_name.lower(), semaphore) for idx, (loc, _) in enumerate(found_elements_list)]
                        results_tuples = await asyncio.gather(*tasks)
                        flat_mails=[]; processed_domains=set()
                        for url, pdf, content, mails in results_tuples:
                            url_list.append(url)
                            if attribute_name.lower() == 'pdf': pdf_list.append(pdf)
                            if attribute_name.lower() == 'content': content_list.append(content)
                            if attribute_name.lower() == 'mail' and mails: flat_mails.extend(mails)
                        if attribute_name.lower() == 'mail':
                             for email in flat_mails:
                                 if isinstance(email, str) and '@' in email:
                                     try: domain = email.split('@',1)[1].lower();
                                     except IndexError: continue
                                     if domain and domain not in processed_domains: mail_list.append(email); processed_domains.add(domain)
                             if mail_list:
                                try: os.makedirs("output", exist_ok=True)
                                except OSError: pass
                                try:
                                     with open("output/server_mails.txt", "a", encoding="utf-8") as f: f.write('\n'.join(mail_list) + '\n') # ★ 複数行に修正済み ★
                                     logger.info(f"Appended {len(mail_list)} emails to output/server_mails.txt")
                                except Exception as mfwe: logger.error(f"Mail file write error: {mfwe}")
                        action_result_details["results_count"] = len(url_list)
                        if attribute_name.lower() in ['href', 'pdf', 'content', 'mail']: action_result_details["url_list"] = url_list
                        if attribute_name.lower() == 'pdf': action_result_details["pdf_texts"] = pdf_list
                        if attribute_name.lower() == 'content': action_result_details["scraped_texts"] = content_list
                        if attribute_name.lower() == 'mail': action_result_details["extracted_emails"] = mail_list
                    else: # 通常属性
                        async def get_single_attr(locator: Locator, attr_name: str, index: int, timeout_ms: int) -> Optional[str]: # ★ 複数行に修正済み ★
                            """Helper to get attribute with error handling"""
                            try: return await locator.get_attribute(attr_name, timeout=timeout_ms)
                            except PlaywrightTimeoutError: logger.warning(f"Timeout getting attr '{attr_name}' for element {index}"); return f"Error: Timeout"
                            except Exception as e: logger.warning(f"Error getting attr '{attr_name}' for element {index}: {type(e).__name__}"); return f"Error: {type(e).__name__}"
                        timeout = max(500, action_wait_time // num_found if num_found > 5 else action_wait_time // 3)
                        tasks = [get_single_attr(loc, attribute_name, idx, timeout) for idx, (loc, _) in enumerate(found_elements_list)]
                        generic_list = await asyncio.gather(*tasks)
                        action_result_details.update({"attribute": attribute_name, "attribute_list": generic_list, "results_count": len(generic_list)})
                    action_result_details["attribute"] = attribute_name

            elif action == "get_all_text_contents":
                if not selector: raise ValueError("get_all_text_contents requires 'selector'.")
                text_list: List[Optional[str]] = []
                if not found_elements_list: logger.warning(f"No elements for '{selector}'."); action_result_details["results_count"] = 0
                else:
                    num_found = len(found_elements_list); logger.info(f"Getting textContent from {num_found} elements...")
                    async def get_single_text(locator: Locator, index: int, timeout_ms: int) -> Optional[str]: # ★ 複数行に修正済み ★
                        """Helper to get text content with error handling"""
                        try: text = await locator.text_content(timeout=timeout_ms); return text.strip() if text else ""
                        except PlaywrightTimeoutError: logger.warning(f"Timeout getting text for element {index}"); return "Error: Timeout"
                        except Exception as e: logger.warning(f"Error getting text for element {index}: {type(e).__name__}"); return f"Error: {type(e).__name__}"
                    timeout = max(500, action_wait_time // num_found if num_found > 5 else action_wait_time // 3)
                    tasks = [get_single_text(loc, idx, timeout) for idx, (loc, _) in enumerate(found_elements_list)]
                    text_list = await asyncio.gather(*tasks)
                    action_result_details["results_count"] = len(text_list)
                action_result_details["text_list"] = text_list

            elif action == "wait_visible":
                if not target_element: raise ValueError("Wait visible requires located element.")
                logger.info("Element visibility confirmed.")

            elif action == "select_option":
                  if not target_element: raise ValueError("Select option requires located element.")
                  if option_type not in ['value', 'index', 'label'] or option_value is None: raise ValueError("Invalid option_type/value.")
                  logger.info(f"Selecting option (Type: {option_type}, Value: '{option_value}')...")
                  if option_type == 'value': await target_element.select_option(value=str(option_value), timeout=action_wait_time)
                  elif option_type == 'index': await target_element.select_option(index=int(option_value), timeout=action_wait_time)
                  elif option_type == 'label': await target_element.select_option(label=str(option_value), timeout=action_wait_time)
                  logger.info("Select option success.")
                  action_result_details.update({"option_type": option_type, "option_value": option_value})

            elif action == "scroll_to_element":
                   if not target_element: raise ValueError("Scroll action requires located element.")
                   await target_element.scroll_into_view_if_needed(timeout=action_wait_time); await asyncio.sleep(0.3); logger.info("Scroll success.")

            elif action == "screenshot":
                  filename_base = str(value).strip() if value else f"screenshot_step{step_num}"
                  filename = f"{filename_base}.png" if not filename_base.lower().endswith(('.png', '.jpg', '.jpeg')) else filename_base
                  screenshot_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, filename); os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                  logger.info(f"Saving screenshot to '{screenshot_path}'...")
                  if target_element: await target_element.screenshot(path=screenshot_path, timeout=action_wait_time); logger.info("Element screenshot saved.")
                  else: await root_page.screenshot(path=screenshot_path, full_page=True, timeout=action_wait_time*2); logger.info("Page screenshot saved.")
                  action_result_details["filename"] = screenshot_path

            else: # 未知のアクション
                known_actions = single_element_actions + multiple_elements_actions + \
                                ["switch_to_iframe", "switch_to_parent_frame", "wait_page_load",
                                 "sleep", "scroll_page_to_bottom", "screenshot"]
                if action not in known_actions:
                     logger.warning(f"Undefined action '{action}'. Skipping.")
                     results.append({**step_result_base, "status": "skipped", "message": f"Undefined action: {action}"})
                     continue

            # --- 正常終了時の結果追加 ---
            results.append({**step_result_base, "status": "success", **action_result_details})

        # --- ステップごとのエラーハンドリング ---
        except (PlaywrightTimeoutError, PlaywrightError, ValueError, IndexError, Exception) as e:
            error_message = f"ステップ {step_num} ({action}) エラー: {type(e).__name__} - {e}"
            logger.error(error_message, exc_info=True)
            error_screenshot_path = None
            if root_page and not root_page.is_closed():
                 timestamp = time.strftime("%Y%m%d_%H%M%S")
                 error_ss_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, f"error_step{step_num}_{timestamp}.png")
                 try:
                     os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                     await root_page.screenshot(path=error_ss_path, full_page=True, timeout=10000)
                     error_screenshot_path = error_ss_path; logger.info(f"Error screenshot saved: {error_ss_path}")
                 except Exception as ss_e: logger.error(f"Failed to save error screenshot: {ss_e}")

            error_details = {
                **step_result_base,
                "status": "error",
                "selector": selector, "target_hints": target_hints, "locator_attempts": locator_attempt_logs,
                "message": str(e), "full_error": error_message, "traceback": traceback.format_exc(),
            }
            if error_screenshot_path: error_details["error_screenshot"] = error_screenshot_path
            results.append(error_details)
            return False, results # 処理中断

    # --- 全ステップ完了 ---
    return True, results
# --- ▲▲▲ execute_actions_async 本体 (ここまで) ▲▲▲ ---


---


- フォルダ名: .
- ファイル名: playwright_finders.py
- 内容:
# --- ファイル: playwright_finders.py ---
"""
Playwrightを使った動的な要素探索機能を提供します。
"""
import asyncio
import logging
import time
from collections import deque
from playwright.async_api import (
    Page,
    FrameLocator,
    Locator,
    TimeoutError as PlaywrightTimeoutError,
)
from typing import List, Tuple, Optional, Union, Deque

import config

logger = logging.getLogger(__name__)

# --- 動的要素探索ヘルパー関数 (単一要素用) ---
async def find_element_dynamically(
    base_locator: Union[Page, FrameLocator],
    target_selector: str,
    max_depth: int = config.DYNAMIC_SEARCH_MAX_DEPTH,
    timeout: int = config.DEFAULT_ACTION_TIMEOUT,
    target_state: str = "attached"
) -> Tuple[Optional[Locator], Optional[Union[Page, FrameLocator]]]:
    """
    指定された起点からiframe内を含めて動的に単一の要素を探索します。
    見つかった要素のLocatorと、それが見つかったスコープ (Page or FrameLocator) を返します。
    タイムアウトするか見つからない場合は (None, None) を返します。
    """
    logger.info(f"動的探索(単一)開始: 起点={type(base_locator).__name__}, セレクター='{target_selector}', 最大深度={max_depth}, 状態='{target_state}', 全体タイムアウト={timeout}ms")
    start_time = time.monotonic()
    queue: Deque[Tuple[Union[Page, FrameLocator], int]] = deque([(base_locator, 0)])
    visited_scope_ids = {id(base_locator)}
    element_wait_timeout = 2000  # 要素存在確認のタイムアウト（短め）
    iframe_check_timeout = config.IFRAME_LOCATOR_TIMEOUT # iframe有効性確認のタイムアウト
    logger.debug(f"  要素待機タイムアウト: {element_wait_timeout}ms, フレーム確認タイムアウト: {iframe_check_timeout}ms")

    while queue:
        current_monotonic_time = time.monotonic()
        elapsed_time_ms = (current_monotonic_time - start_time) * 1000
        if elapsed_time_ms >= timeout:
            logger.warning(f"動的探索(単一)タイムアウト ({timeout}ms) - 経過時間: {elapsed_time_ms:.0f}ms")
            return None, None
        remaining_time_ms = timeout - elapsed_time_ms
        if remaining_time_ms < 100: # 残り時間が少なすぎる場合は探索打ち切り
             logger.warning(f"動的探索(単一)の残り時間がわずかなため ({remaining_time_ms:.0f}ms)、探索を打ち切ります。")
             return None, None

        current_scope, current_depth = queue.popleft()
        scope_type_name = type(current_scope).__name__
        scope_identifier = f" ({repr(current_scope)})" if isinstance(current_scope, FrameLocator) else ""
        logger.debug(f"  探索中(単一): スコープ={scope_type_name}{scope_identifier}, 深度={current_depth}, 残り時間: {remaining_time_ms:.0f}ms")

        step_start_time = time.monotonic()
        try:
            element = current_scope.locator(target_selector).first
            # 要素の待機タイムアウトは、全体タイムアウトの残り時間と設定値の小さい方、かつ最低50msを確保
            effective_element_timeout = max(50, min(element_wait_timeout, int(remaining_time_ms - 50))) # 50msのマージン
            await element.wait_for(state=target_state, timeout=effective_element_timeout)
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.info(f"要素 '{target_selector}' をスコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) で発見。({step_elapsed:.0f}ms)")
            return element, current_scope
        except PlaywrightTimeoutError:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' 直下では見つからず (タイムアウト {effective_element_timeout}ms)。({step_elapsed:.0f}ms)")
        except Exception as e:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.warning(f"    スコープ '{scope_type_name}{scope_identifier}' での要素 '{target_selector}' 探索中にエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)")

        # --- iframe探索 ---
        if current_depth < max_depth:
            # 再度時間チェック
            current_monotonic_time = time.monotonic()
            elapsed_time_ms = (current_monotonic_time - start_time) * 1000
            if elapsed_time_ms >= timeout: continue # 時間切れなら次のキューへ
            remaining_time_ms = timeout - elapsed_time_ms
            if remaining_time_ms < 100: continue # 残り時間が少なすぎる場合

            step_start_time = time.monotonic()
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) 内の可視iframeを探索...")
            try:
                iframe_base_selector = 'iframe:visible' # 可視iframeのみを対象
                visible_iframe_locators = current_scope.locator(iframe_base_selector)
                count = await visible_iframe_locators.count()
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                if count > 0: logger.debug(f"      発見した可視iframe候補数: {count} ({step_elapsed:.0f}ms)")

                for i in range(count):
                    # ループ内でも時間チェック
                    current_monotonic_time_inner = time.monotonic()
                    elapsed_time_ms_inner = (current_monotonic_time_inner - start_time) * 1000
                    if elapsed_time_ms_inner >= timeout:
                         logger.warning(f"動的探索(単一)タイムアウト ({timeout}ms) - iframeループ中")
                         break # このスコープのiframe探索を打ち切り
                    remaining_time_ms_inner = timeout - elapsed_time_ms_inner
                    if remaining_time_ms_inner < 50: break # 残り時間が少なすぎる場合

                    iframe_step_start_time = time.monotonic()
                    try:
                        # nth=i で i番目の可視iframeを特定
                        nth_iframe_selector = f"{iframe_base_selector} >> nth={i}"
                        next_frame_locator = current_scope.frame_locator(nth_iframe_selector)
                        # iframeが有効かどうかのチェックタイムアウト
                        effective_iframe_check_timeout = max(50, min(iframe_check_timeout, int(remaining_time_ms_inner - 50)))
                        # iframe内のルート要素が存在するかで有効性を判断
                        await next_frame_locator.locator(':root').wait_for(state='attached', timeout=effective_iframe_check_timeout)
                        # 訪問済みでなければキューに追加
                        scope_id = id(next_frame_locator) # FrameLocatorオブジェクトのIDで訪問管理
                        if scope_id not in visited_scope_ids:
                            visited_scope_ids.add(scope_id)
                            queue.append((next_frame_locator, current_depth + 1))
                            iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                            logger.debug(f"        キューに追加(単一): スコープ=FrameLocator(nth={i}), 新深度={current_depth + 1} ({iframe_step_elapsed:.0f}ms)")
                        else:
                            logger.debug(f"        スキップ(単一): FrameLocator(nth={i}) は訪問済み")
                    except PlaywrightTimeoutError:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.debug(f"      iframe {i} ('{nth_iframe_selector}') は有効でないかタイムアウト ({effective_iframe_check_timeout}ms)。({iframe_step_elapsed:.0f}ms)")
                    except Exception as e:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.warning(f"      iframe {i} ('{nth_iframe_selector}') の処理中にエラー: {type(e).__name__} - {e} ({iframe_step_elapsed:.0f}ms)")
            except Exception as e:
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                logger.error(f"    スコープ '{scope_type_name}{scope_identifier}' でのiframe探索中に予期せぬエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)", exc_info=True)

    final_elapsed_time = (time.monotonic() - start_time) * 1000
    logger.warning(f"動的探索(単一)完了: 要素 '{target_selector}' が最大深度 {max_depth} までで見つかりませんでした。({final_elapsed_time:.0f}ms)")
    return None, None

# --- 動的要素探索ヘルパー関数 (複数要素用) ---
async def find_all_elements_dynamically(
    base_locator: Union[Page, FrameLocator],
    target_selector: str,
    max_depth: int = config.DYNAMIC_SEARCH_MAX_DEPTH,
    timeout: int = config.DEFAULT_ACTION_TIMEOUT,
) -> List[Tuple[Locator, Union[Page, FrameLocator]]]:
    """
    指定された起点からiframe内を含めて動的に複数の要素を探索します。
    見つかったすべての要素のLocatorとそのスコープのタプルのリストを返します。
    タイムアウトした場合は、それまでに見つかった要素のリストを返します。
    """
    logger.info(f"動的探索(複数)開始: 起点={type(base_locator).__name__}, セレクター='{target_selector}', 最大深度={max_depth}, 全体タイムアウト={timeout}ms")
    start_time = time.monotonic()
    found_elements: List[Tuple[Locator, Union[Page, FrameLocator]]] = []
    queue: Deque[Tuple[Union[Page, FrameLocator], int]] = deque([(base_locator, 0)])
    visited_scope_ids = {id(base_locator)}
    iframe_check_timeout = config.IFRAME_LOCATOR_TIMEOUT # iframe有効性確認のタイムアウト
    logger.debug(f"  フレーム確認タイムアウト: {iframe_check_timeout}ms")

    while queue:
        current_monotonic_time = time.monotonic()
        elapsed_time_ms = (current_monotonic_time - start_time) * 1000
        if elapsed_time_ms >= timeout:
            logger.warning(f"動的探索(複数)タイムアウト ({timeout}ms) - 経過時間: {elapsed_time_ms:.0f}ms")
            break # 時間切れの場合はループを抜ける
        remaining_time_ms = timeout - elapsed_time_ms
        if remaining_time_ms < 100: # 残り時間が少なすぎる場合は探索打ち切り
             logger.warning(f"動的探索(複数)の残り時間がわずかなため ({remaining_time_ms:.0f}ms)、探索を打ち切ります。")
             break

        current_scope, current_depth = queue.popleft()
        scope_type_name = type(current_scope).__name__
        scope_identifier = f" ({repr(current_scope)})" if isinstance(current_scope, FrameLocator) else ""
        logger.debug(f"  探索中(複数): スコープ={scope_type_name}{scope_identifier}, 深度={current_depth}, 残り時間: {remaining_time_ms:.0f}ms")

        step_start_time = time.monotonic()
        try:
            # 要素が表示されているかに関わらず、スコープ内のすべての要素を取得
            # all() は要素がなくてもエラーにならない（空リストを返す）
            elements_in_scope = await current_scope.locator(target_selector).all()
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            if elements_in_scope:
                logger.info(f"  スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) で {len(elements_in_scope)} 個の要素を発見。({step_elapsed:.0f}ms)")
                for elem in elements_in_scope:
                    found_elements.append((elem, current_scope))
            else:
                logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' 直下では要素が見つからず。({step_elapsed:.0f}ms)")
        except Exception as e:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.warning(f"    スコープ '{scope_type_name}{scope_identifier}' での要素 '{target_selector}' 複数探索中にエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)")

        # --- iframe探索 ---
        if current_depth < max_depth:
            # 再度時間チェック
            current_monotonic_time = time.monotonic()
            elapsed_time_ms = (current_monotonic_time - start_time) * 1000
            if elapsed_time_ms >= timeout: continue # 時間切れなら次のキューへ
            remaining_time_ms = timeout - elapsed_time_ms
            if remaining_time_ms < 100: continue # 残り時間が少なすぎる場合

            step_start_time = time.monotonic()
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) 内の可視iframeを探索...")
            try:
                iframe_base_selector = 'iframe:visible' # 可視iframeのみを対象
                visible_iframe_locators = current_scope.locator(iframe_base_selector)
                count = await visible_iframe_locators.count()
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                if count > 0: logger.debug(f"      発見した可視iframe候補数: {count} ({step_elapsed:.0f}ms)")

                for i in range(count):
                    # ループ内でも時間チェック
                    current_monotonic_time_inner = time.monotonic()
                    elapsed_time_ms_inner = (current_monotonic_time_inner - start_time) * 1000
                    if elapsed_time_ms_inner >= timeout:
                         logger.warning(f"動的探索(複数)タイムアウト ({timeout}ms) - iframeループ中")
                         break # このスコープのiframe探索を打ち切り
                    remaining_time_ms_inner = timeout - elapsed_time_ms_inner
                    if remaining_time_ms_inner < 50: break # 残り時間が少なすぎる場合

                    iframe_step_start_time = time.monotonic()
                    try:
                        nth_iframe_selector = f"{iframe_base_selector} >> nth={i}"
                        next_frame_locator = current_scope.frame_locator(nth_iframe_selector)
                        # iframeが有効かどうかのチェックタイムアウト
                        effective_iframe_check_timeout = max(50, min(iframe_check_timeout, int(remaining_time_ms_inner - 50)))
                        await next_frame_locator.locator(':root').wait_for(state='attached', timeout=effective_iframe_check_timeout)
                        # 訪問済みでなければキューに追加
                        scope_id = id(next_frame_locator)
                        if scope_id not in visited_scope_ids:
                            visited_scope_ids.add(scope_id)
                            queue.append((next_frame_locator, current_depth + 1))
                            iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                            logger.debug(f"        キューに追加(複数): スコープ=FrameLocator(nth={i}), 新深度={current_depth + 1} ({iframe_step_elapsed:.0f}ms)")
                        else:
                             logger.debug(f"        スキップ(複数): FrameLocator(nth={i}) は訪問済み")
                    except PlaywrightTimeoutError:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.debug(f"      iframe {i} ('{nth_iframe_selector}') は有効でないかタイムアウト ({effective_iframe_check_timeout}ms)。({iframe_step_elapsed:.0f}ms)")
                    except Exception as e:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.warning(f"      iframe {i} ('{nth_iframe_selector}') の処理中にエラー: {type(e).__name__} - {e} ({iframe_step_elapsed:.0f}ms)")
            except Exception as e:
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                logger.error(f"    スコープ '{scope_type_name}{scope_identifier}' でのiframe探索中に予期せぬエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)", exc_info=True)

    final_elapsed_time = (time.monotonic() - start_time) * 1000
    logger.info(f"動的探索(複数)完了: 合計 {len(found_elements)} 個の要素が見つかりました。({final_elapsed_time:.0f}ms)")
    return found_elements


---


- フォルダ名: .
- ファイル名: playwright_handler-bup.py
- 内容:
# --- ファイル: playwright_handler.py ---
"""
Playwrightを使ったブラウザ操作とアクション実行のコアロジック。
"""
import asyncio
import logging
import os
import time
import pprint
import traceback
import warnings
from collections import deque
from playwright.async_api import (
    async_playwright,
    Page,
    Frame,
    Locator,
    FrameLocator,
    BrowserContext,
    TimeoutError as PlaywrightTimeoutError,
    Error as PlaywrightError,
    APIRequestContext
)
from playwright_stealth import stealth_async
from typing import List, Tuple, Optional, Union, Any, Deque, Dict
from urllib.parse import urljoin

import config
import utils

logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore", category=ResourceWarning, message="unclosed transport")


# --- 動的要素探索ヘルパー関数 (単一要素用 - 変更なし) ---
async def find_element_dynamically(
    base_locator: Union[Page, FrameLocator],
    target_selector: str,
    max_depth: int = config.DYNAMIC_SEARCH_MAX_DEPTH,
    timeout: int = config.DEFAULT_ACTION_TIMEOUT,
    target_state: str = "attached"
) -> Tuple[Optional[Locator], Optional[Union[Page, FrameLocator]]]:
    logger.info(f"動的探索(単一)開始: 起点={type(base_locator).__name__}, セレクター='{target_selector}', 最大深度={max_depth}, 状態='{target_state}', 全体タイムアウト={timeout}ms")
    start_time = time.monotonic()
    queue: Deque[Tuple[Union[Page, FrameLocator], int]] = deque([(base_locator, 0)])
    visited_scope_ids = {id(base_locator)}
    element_wait_timeout = 2000
    iframe_check_timeout = config.IFRAME_LOCATOR_TIMEOUT
    logger.debug(f"  要素待機タイムアウト: {element_wait_timeout}ms, フレーム確認タイムアウト: {iframe_check_timeout}ms")

    while queue:
        current_monotonic_time = time.monotonic()
        elapsed_time_ms = (current_monotonic_time - start_time) * 1000
        if elapsed_time_ms >= timeout:
            logger.warning(f"動的探索(単一)タイムアウト ({timeout}ms) - 経過時間: {elapsed_time_ms:.0f}ms")
            return None, None
        remaining_time_ms = timeout - elapsed_time_ms
        if remaining_time_ms < 100:
             logger.warning(f"動的探索(単一)の残り時間がわずかなため ({remaining_time_ms:.0f}ms)、探索を打ち切ります。")
             return None, None

        current_scope, current_depth = queue.popleft()
        scope_type_name = type(current_scope).__name__
        scope_identifier = f" ({repr(current_scope)})" if isinstance(current_scope, FrameLocator) else ""
        logger.debug(f"  探索中(単一): スコープ={scope_type_name}{scope_identifier}, 深度={current_depth}, 残り時間: {remaining_time_ms:.0f}ms")

        step_start_time = time.monotonic()
        try:
            element = current_scope.locator(target_selector).first
            effective_element_timeout = max(50, min(element_wait_timeout, int(remaining_time_ms - 50)))
            await element.wait_for(state=target_state, timeout=effective_element_timeout)
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.info(f"要素 '{target_selector}' をスコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) で発見。({step_elapsed:.0f}ms)")
            return element, current_scope
        except PlaywrightTimeoutError:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' 直下では見つからず (タイムアウト {effective_element_timeout}ms)。({step_elapsed:.0f}ms)")
        except Exception as e:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.warning(f"    スコープ '{scope_type_name}{scope_identifier}' での要素 '{target_selector}' 探索中にエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)")

        if current_depth < max_depth:
            current_monotonic_time = time.monotonic()
            elapsed_time_ms = (current_monotonic_time - start_time) * 1000
            if elapsed_time_ms >= timeout: continue
            remaining_time_ms = timeout - elapsed_time_ms
            if remaining_time_ms < 100: continue

            step_start_time = time.monotonic()
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) 内の可視iframeを探索...")
            try:
                iframe_base_selector = 'iframe:visible'
                visible_iframe_locators = current_scope.locator(iframe_base_selector)
                count = await visible_iframe_locators.count()
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                if count > 0: logger.debug(f"      発見した可視iframe候補数: {count} ({step_elapsed:.0f}ms)")

                for i in range(count):
                    current_monotonic_time_inner = time.monotonic()
                    elapsed_time_ms_inner = (current_monotonic_time_inner - start_time) * 1000
                    if elapsed_time_ms_inner >= timeout:
                         logger.warning(f"動的探索(単一)タイムアウト ({timeout}ms) - iframeループ中")
                         break
                    remaining_time_ms_inner = timeout - elapsed_time_ms_inner
                    if remaining_time_ms_inner < 50: break

                    iframe_step_start_time = time.monotonic()
                    try:
                        nth_iframe_selector = f"{iframe_base_selector} >> nth={i}"
                        next_frame_locator = current_scope.frame_locator(nth_iframe_selector)
                        effective_iframe_check_timeout = max(50, min(iframe_check_timeout, int(remaining_time_ms_inner - 50)))
                        await next_frame_locator.locator(':root').wait_for(state='attached', timeout=effective_iframe_check_timeout)
                        scope_id = id(next_frame_locator)
                        if scope_id not in visited_scope_ids:
                            visited_scope_ids.add(scope_id)
                            queue.append((next_frame_locator, current_depth + 1))
                            iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                            logger.debug(f"        キューに追加(単一): スコープ=FrameLocator(nth={i}), 新深度={current_depth + 1} ({iframe_step_elapsed:.0f}ms)")
                    except PlaywrightTimeoutError:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.debug(f"      iframe {i} ('{nth_iframe_selector}') は有効でないかタイムアウト ({effective_iframe_check_timeout}ms)。({iframe_step_elapsed:.0f}ms)")
                    except Exception as e:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.warning(f"      iframe {i} ('{nth_iframe_selector}') の処理中にエラー: {type(e).__name__} - {e} ({iframe_step_elapsed:.0f}ms)")
            except Exception as e:
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                logger.error(f"    スコープ '{scope_type_name}{scope_identifier}' でのiframe探索中に予期せぬエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)", exc_info=True)

    final_elapsed_time = (time.monotonic() - start_time) * 1000
    logger.warning(f"動的探索(単一)完了: 要素 '{target_selector}' が最大深度 {max_depth} までで見つかりませんでした。({final_elapsed_time:.0f}ms)")
    return None, None

# --- 動的要素探索ヘルパー関数 (複数要素用 - 変更なし) ---
async def find_all_elements_dynamically(
    base_locator: Union[Page, FrameLocator],
    target_selector: str,
    max_depth: int = config.DYNAMIC_SEARCH_MAX_DEPTH,
    timeout: int = config.DEFAULT_ACTION_TIMEOUT,
) -> List[Tuple[Locator, Union[Page, FrameLocator]]]:
    logger.info(f"動的探索(複数)開始: 起点={type(base_locator).__name__}, セレクター='{target_selector}', 最大深度={max_depth}, 全体タイムアウト={timeout}ms")
    start_time = time.monotonic()
    found_elements: List[Tuple[Locator, Union[Page, FrameLocator]]] = []
    queue: Deque[Tuple[Union[Page, FrameLocator], int]] = deque([(base_locator, 0)])
    visited_scope_ids = {id(base_locator)}
    iframe_check_timeout = config.IFRAME_LOCATOR_TIMEOUT
    logger.debug(f"  フレーム確認タイムアウト: {iframe_check_timeout}ms")

    while queue:
        current_monotonic_time = time.monotonic()
        elapsed_time_ms = (current_monotonic_time - start_time) * 1000
        if elapsed_time_ms >= timeout:
            logger.warning(f"動的探索(複数)タイムアウト ({timeout}ms) - 経過時間: {elapsed_time_ms:.0f}ms")
            break
        remaining_time_ms = timeout - elapsed_time_ms
        if remaining_time_ms < 100:
             logger.warning(f"動的探索(複数)の残り時間がわずかなため ({remaining_time_ms:.0f}ms)、探索を打ち切ります。")
             break

        current_scope, current_depth = queue.popleft()
        scope_type_name = type(current_scope).__name__
        scope_identifier = f" ({repr(current_scope)})" if isinstance(current_scope, FrameLocator) else ""
        logger.debug(f"  探索中(複数): スコープ={scope_type_name}{scope_identifier}, 深度={current_depth}, 残り時間: {remaining_time_ms:.0f}ms")

        step_start_time = time.monotonic()
        try:
            # 要素が表示されているかに関わらず全て取得する
            elements_in_scope = await current_scope.locator(target_selector).all()
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            if elements_in_scope:
                logger.info(f"  スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) で {len(elements_in_scope)} 個の要素を発見。({step_elapsed:.0f}ms)")
                for elem in elements_in_scope:
                    found_elements.append((elem, current_scope))
            else:
                logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' 直下では要素が見つからず。({step_elapsed:.0f}ms)")
        except Exception as e:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.warning(f"    スコープ '{scope_type_name}{scope_identifier}' での要素 '{target_selector}' 複数探索中にエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)")

        if current_depth < max_depth:
            current_monotonic_time = time.monotonic()
            elapsed_time_ms = (current_monotonic_time - start_time) * 1000
            if elapsed_time_ms >= timeout: continue
            remaining_time_ms = timeout - elapsed_time_ms
            if remaining_time_ms < 100: continue

            step_start_time = time.monotonic()
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) 内の可視iframeを探索...")
            try:
                # iframe自体は可視である必要がある
                iframe_base_selector = 'iframe:visible'
                visible_iframe_locators = current_scope.locator(iframe_base_selector)
                count = await visible_iframe_locators.count()
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                if count > 0: logger.debug(f"      発見した可視iframe候補数: {count} ({step_elapsed:.0f}ms)")

                for i in range(count):
                    current_monotonic_time_inner = time.monotonic()
                    elapsed_time_ms_inner = (current_monotonic_time_inner - start_time) * 1000
                    if elapsed_time_ms_inner >= timeout:
                         logger.warning(f"動的探索(複数)タイムアウト ({timeout}ms) - iframeループ中")
                         break
                    remaining_time_ms_inner = timeout - elapsed_time_ms_inner
                    if remaining_time_ms_inner < 50: break

                    iframe_step_start_time = time.monotonic()
                    try:
                        nth_iframe_selector = f"{iframe_base_selector} >> nth={i}"
                        next_frame_locator = current_scope.frame_locator(nth_iframe_selector)
                        effective_iframe_check_timeout = max(50, min(iframe_check_timeout, int(remaining_time_ms_inner - 50)))
                        # iframe内のルート要素が存在するかどうかを確認
                        await next_frame_locator.locator(':root').wait_for(state='attached', timeout=effective_iframe_check_timeout)
                        scope_id = id(next_frame_locator)
                        if scope_id not in visited_scope_ids:
                            visited_scope_ids.add(scope_id)
                            queue.append((next_frame_locator, current_depth + 1))
                            iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                            logger.debug(f"        キューに追加(複数): スコープ=FrameLocator(nth={i}), 新深度={current_depth + 1} ({iframe_step_elapsed:.0f}ms)")
                    except PlaywrightTimeoutError:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.debug(f"      iframe {i} ('{nth_iframe_selector}') は有効でないかタイムアウト ({effective_iframe_check_timeout}ms)。({iframe_step_elapsed:.0f}ms)")
                    except Exception as e:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.warning(f"      iframe {i} ('{nth_iframe_selector}') の処理中にエラー: {type(e).__name__} - {e} ({iframe_step_elapsed:.0f}ms)")
            except Exception as e:
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                logger.error(f"    スコープ '{scope_type_name}{scope_identifier}' でのiframe探索中に予期せぬエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)", exc_info=True)

    final_elapsed_time = (time.monotonic() - start_time) * 1000
    logger.info(f"動的探索(複数)完了: 合計 {len(found_elements)} 個の要素が見つかりました。({final_elapsed_time:.0f}ms)")
    return found_elements


# --- ページ内テキスト取得ヘルパー関数 (変更なし) ---
async def get_page_inner_text(context: BrowserContext, url: str, timeout: int) -> Tuple[bool, Optional[str]]:
    """
    指定されたURLにアクセスし、ページのinnerTextを取得する。
    成功したかどうかとテキスト内容（またはエラーメッセージ）のタプルを返す。
    """
    page = None
    start_time = time.monotonic()
    # ページ遷移自体のタイムアウトも考慮
    page_access_timeout = max(int(timeout * 0.8), 15000) # アクションタイムアウトの80%か15秒の大きい方
    logger.info(f"URLからテキスト取得開始: {url} (タイムアウト: {page_access_timeout}ms)")
    try:
        page = await context.new_page()
        # ナビゲーションタイムアウトを設定
        nav_timeout = max(int(page_access_timeout * 0.9), 10000)
        logger.debug(f"  Navigating to {url} with timeout {nav_timeout}ms")
        await page.goto(url, wait_until="load", timeout=nav_timeout)
        logger.debug(f"  Navigation to {url} successful.")

        # <body>要素が表示されるまで待機
        remaining_time_for_body = page_access_timeout - (time.monotonic() - start_time) * 1000
        body_wait_timeout = max(int(remaining_time_for_body * 0.5), 2000)
        if remaining_time_for_body <= 0:
            raise PlaywrightTimeoutError(f"No time left to wait for body after navigation to {url}")
        logger.debug(f"  Waiting for body element with timeout {body_wait_timeout}ms")
        body_locator = page.locator('body')
        await body_locator.wait_for(state='visible', timeout=body_wait_timeout)
        logger.debug("  Body element is visible.")

        # innerText取得タイムアウト
        remaining_time_for_text = page_access_timeout - (time.monotonic() - start_time) * 1000
        text_timeout = max(int(remaining_time_for_text * 0.8), 1000)
        if remaining_time_for_text <= 0:
            raise PlaywrightTimeoutError(f"No time left to get innerText from {url}")

        logger.debug(f"  Getting innerText with timeout {text_timeout}ms")
        text = await body_locator.inner_text(timeout=text_timeout)
        elapsed = (time.monotonic() - start_time) * 1000
        logger.info(f"テキスト取得成功 ({url})。文字数: {len(text)} ({elapsed:.0f}ms)")
        # 取得したテキストを返す
        return True, text.strip() if text else ""
    except PlaywrightTimeoutError as e:
        elapsed = (time.monotonic() - start_time) * 1000
        error_msg = f"Error: Timeout during processing {url} ({elapsed:.0f}ms). {e}"
        logger.warning(error_msg)
        # エラーメッセージを返す
        return False, error_msg
    except Exception as e:
        elapsed = (time.monotonic() - start_time) * 1000
        error_msg = f"Error: Failed to get text from {url} ({elapsed:.0f}ms) - {type(e).__name__}: {e}"
        logger.error(error_msg, exc_info=False)
        logger.debug(f"Detailed error getting text from {url}:", exc_info=True)
        # エラーメッセージを返す
        return False, error_msg
    finally:
        if page and not page.is_closed():
            try:
                await page.close()
                logger.debug(f"一時ページ ({url}) を閉じました。")
            except Exception as close_e:
                logger.warning(f"一時ページ ({url}) クローズ中にエラー (無視): {close_e}")


# --- Playwright アクション実行コア (変更なし) ---
async def execute_actions_async(initial_page: Page, actions: List[dict], api_request_context: APIRequestContext, default_timeout: int) -> Tuple[bool, List[dict]]:
    """Playwright アクションを非同期で実行する。iframe探索を動的に行う。"""
    results: List[dict] = []
    current_target: Union[Page, FrameLocator] = initial_page
    root_page: Page = initial_page
    current_context: BrowserContext = root_page.context
    iframe_stack: List[Union[Page, FrameLocator]] = []

    for i, step_data in enumerate(actions):
        step_num = i + 1
        action = step_data.get("action", "").lower()
        selector = step_data.get("selector")
        iframe_selector_input = step_data.get("iframe_selector")
        value = step_data.get("value")
        attribute_name = step_data.get("attribute_name")
        option_type = step_data.get("option_type")
        option_value = step_data.get("option_value")
        # アクション固有のタイムアウト > JSON全体のデフォルト > configのデフォルト
        action_wait_time = step_data.get("wait_time_ms", default_timeout)

        logger.info(f"--- ステップ {step_num}/{len(actions)}: Action='{action}' ---")
        step_info = {"selector": selector, "value": value, "iframe(指定)": iframe_selector_input,
                     "option_type": option_type, "option_value": option_value, "attribute_name": attribute_name}
        step_info_str = ", ".join([f"{k}='{v}'" for k, v in step_info.items() if v is not None])
        logger.info(f"詳細: {step_info_str} (timeout: {action_wait_time}ms)")

        try:
            if root_page.is_closed():
                raise PlaywrightError("Root page is closed.")
            current_base_url = root_page.url # 現在のページのベースURLを取得
            root_page_title = await root_page.title()
            current_target_type = type(current_target).__name__
            logger.info(f"現在のルートページ: URL='{current_base_url}', Title='{root_page_title}'")
            logger.info(f"現在の探索スコープ: {current_target_type}")
        except Exception as e:
            logger.error(f"現在のターゲット情報取得中にエラー: {e}", exc_info=True)
            results.append({"step": step_num, "status": "error", "action": action, "message": f"Failed to get target info: {e}"})
            return False, results

        try:
            # --- Iframe/Parent Frame 切替 (変更なし) ---
            if action == "switch_to_iframe":
                if not iframe_selector_input:
                    raise ValueError("Action 'switch_to_iframe' requires 'iframe_selector'")
                logger.info(f"[ユーザー指定] Iframe '{iframe_selector_input}' に切り替えます...")
                target_frame_locator: Optional[FrameLocator] = None
                try:
                    # 現在のターゲットから iframe を探す
                    target_frame_locator = current_target.frame_locator(iframe_selector_input)
                    # iframeが存在し、アクセス可能か確認 (ルート要素の存在確認)
                    await target_frame_locator.locator(':root').wait_for(state='attached', timeout=action_wait_time)
                except PlaywrightTimeoutError:
                    # logger.debug(f"現在のスコープ({type(current_target).__name__})に指定iframeなし。ルートページから再検索...")
                    # try:
                    #     target_frame_locator = root_page.frame_locator(iframe_selector_input)
                    #     await target_frame_locator.locator(':root').wait_for(state='attached', timeout=max(1000, action_wait_time // 2))
                    # except PlaywrightTimeoutError:
                        raise PlaywrightTimeoutError(f"指定されたiframe '{iframe_selector_input}' が見つからないか、タイムアウト({action_wait_time}ms)しました。")
                except Exception as e:
                    raise PlaywrightError(f"Iframe '{iframe_selector_input}' への切り替え中に予期せぬエラーが発生しました: {e}")

                # 切り替え成功
                if id(current_target) not in [id(s) for s in iframe_stack]: # 重複を避ける
                    iframe_stack.append(current_target) # 現在のターゲットをスタックに追加
                current_target = target_frame_locator # ターゲットを新しい FrameLocator に更新
                logger.info("FrameLocator への切り替え成功。")
                results.append({"step": step_num, "status": "success", "action": action, "selector": iframe_selector_input})
                continue # 次のステップへ

            elif action == "switch_to_parent_frame":
                if not iframe_stack:
                    logger.warning("既にトップレベルフレームか、iframeスタックが空です。")
                    # FrameLocatorの場合のみルートページに戻す（安全策）
                    if isinstance(current_target, FrameLocator):
                        logger.info("現在のターゲットがFrameLocatorのため、ルートページに戻します。")
                        current_target = root_page
                    results.append({"step": step_num, "status": "warning", "action": action, "message": "Already at top-level or stack empty."})
                else:
                    logger.info("[ユーザー指定] 親ターゲットに戻ります...")
                    current_target = iframe_stack.pop() # スタックから親ターゲットを取り出す
                    target_type = type(current_target).__name__
                    logger.info(f"親ターゲットへの切り替え成功。現在の探索スコープ: {target_type}")
                    results.append({"step": step_num, "status": "success", "action": action})
                continue # 次のステップへ


            # --- ページ全体操作 (変更なし) ---
            if action in ["wait_page_load", "sleep", "scroll_page_to_bottom"]:
                if action == "wait_page_load":
                    logger.info("ページの読み込み完了 (load) を待ちます...")
                    await root_page.wait_for_load_state("load", timeout=action_wait_time)
                    logger.info("ページの読み込みが完了しました。")
                    results.append({"step": step_num, "status": "success", "action": action})
                elif action == "sleep":
                    try:
                        seconds = float(value) if value is not None else 1.0
                        if seconds < 0: raise ValueError("Sleep time cannot be negative.")
                    except (TypeError, ValueError):
                        raise ValueError("Invalid value for sleep action. Must be a non-negative number (seconds).")
                    logger.info(f"{seconds:.1f} 秒待機します...")
                    await asyncio.sleep(seconds)
                    results.append({"step": step_num, "status": "success", "action": action, "duration_sec": seconds})
                elif action == "scroll_page_to_bottom":
                    logger.info("ページ最下部へスクロールします...")
                    await root_page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                    await asyncio.sleep(0.5) # スクロール後の描画待ち
                    logger.info("ページ最下部へのスクロールが完了しました。")
                    results.append({"step": step_num, "status": "success", "action": action})
                continue # 次のステップへ


            # --- 要素操作のための準備 ---
            element: Optional[Locator] = None
            found_elements_list: List[Tuple[Locator, Union[Page, FrameLocator]]] = []
            found_scope: Optional[Union[Page, FrameLocator]] = None

            # アクションが単一要素を必要とするか、複数要素を対象とするか
            single_element_required_actions = ["click", "input", "hover", "get_inner_text", "get_text_content", "get_inner_html", "get_attribute", "wait_visible", "select_option", "scroll_to_element"]
            multiple_elements_actions = ["get_all_attributes", "get_all_text_contents"]
            is_single_element_required = action in single_element_required_actions
            is_multiple_elements_action = action in multiple_elements_actions
            # スクリーンショットは要素指定がある場合のみ要素探索が必要
            is_screenshot_element = action == "screenshot" and selector is not None

            if is_single_element_required or is_multiple_elements_action or is_screenshot_element:
                if not selector:
                    raise ValueError(f"Action '{action}' requires a 'selector'.")

                # --- 要素探索 ---
                if is_single_element_required or is_screenshot_element:
                    # 探索する要素の状態を決定
                    required_state = 'visible' if action in ['click', 'hover', 'screenshot', 'select_option', 'input', 'get_inner_text', 'wait_visible', 'scroll_to_element'] else 'attached'
                    element, found_scope = await find_element_dynamically(
                        current_target, selector, max_depth=config.DYNAMIC_SEARCH_MAX_DEPTH, timeout=action_wait_time, target_state=required_state
                    )
                    if not element or not found_scope:
                        error_msg = f"要素 '{selector}' (状態: {required_state}) が現在のスコープおよび探索可能なiframe (深さ{config.DYNAMIC_SEARCH_MAX_DEPTH}まで) 内で見つかりませんでした。"
                        logger.error(error_msg)
                        # エラー結果を追加して終了
                        results.append({"step": step_num, "status": "error", "action": action, "selector": selector, "message": error_msg})
                        return False, results # Falseを返して処理中断

                    # 要素が見つかったスコープが現在のスコープと異なる場合、ターゲットを更新
                    if id(found_scope) != id(current_target):
                        logger.info(f"探索スコープを要素が見つかった '{type(found_scope).__name__}' に更新します。")
                        if id(current_target) not in [id(s) for s in iframe_stack]:
                            iframe_stack.append(current_target) # 元のターゲットをスタックに追加
                        current_target = found_scope
                    logger.info(f"最終的な単一操作対象スコープ: {type(current_target).__name__}")

                elif is_multiple_elements_action:
                    found_elements_list = await find_all_elements_dynamically(
                        current_target, selector, max_depth=config.DYNAMIC_SEARCH_MAX_DEPTH, timeout=action_wait_time
                    )
                    if not found_elements_list:
                        # 要素が見つからなくてもエラーとはせず、警告ログのみ（後続処理で空リストとして扱う）
                        logger.warning(f"要素 '{selector}' が現在のスコープおよび探索可能なiframe (深さ{config.DYNAMIC_SEARCH_MAX_DEPTH}まで) 内で見つかりませんでした。")
                    # 複数要素の場合、見つかった各要素のスコープは異なる可能性があるため、current_target は更新しない


            # --- 各アクション実行 ---
            action_result_details = {"selector": selector} if selector else {} # 結果にセレクター情報を含める

            if action == "click":
                if not element: raise ValueError("Click action requires an element, but it was not found or assigned.")
                logger.info("要素をクリックします...")
                context = root_page.context # クリックによるページ遷移を検知するためルートページのコンテキストを使用
                new_page: Optional[Page] = None
                try:
                    # 新しいページが開く可能性を考慮して待機
                    async with context.expect_page(timeout=config.NEW_PAGE_EVENT_TIMEOUT) as new_page_info:
                        await element.click(timeout=action_wait_time)
                    # タイムアウト内に新しいページが開いた場合
                    new_page = await new_page_info.value
                    new_page_url = new_page.url
                    logger.info(f"新しいページが開きました: URL={new_page_url}")
                    try:
                        # 新しいページのロード完了を待つ
                        await new_page.wait_for_load_state("load", timeout=action_wait_time)
                    except PlaywrightTimeoutError:
                        logger.warning(f"新しいページのロード待機がタイムアウトしました ({action_wait_time}ms)。")
                    # 操作対象を新しいページに切り替え、iframeスタックをクリア
                    root_page = new_page
                    current_target = new_page
                    current_context = new_page.context
                    iframe_stack.clear()
                    logger.info("スコープを新しいページにリセットしました。")
                    action_result_details.update({"new_page_opened": True, "new_page_url": new_page_url})
                    results.append({"step": step_num, "status": "success", "action": action, **action_result_details})
                except PlaywrightTimeoutError:
                    # expect_pageがタイムアウトした場合 (新しいページが開かなかった場合)
                    logger.info(f"クリックは完了しましたが、{config.NEW_PAGE_EVENT_TIMEOUT}ms 以内に新しいページは開きませんでした。")
                    action_result_details["new_page_opened"] = False
                    results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "input":
                 if not element: raise ValueError("Input action requires an element.")
                 if value is None: raise ValueError("Input action requires 'value'.")
                 logger.info(f"要素に '{str(value)[:50]}{'...' if len(str(value)) > 50 else ''}' を入力します...") # 長い値は省略してログ表示
                 await element.fill(str(value), timeout=action_wait_time)
                 logger.info("入力が成功しました。")
                 action_result_details["value"] = value # 結果には元の値を保持
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "hover":
                 if not element: raise ValueError("Hover action requires an element.")
                 logger.info("要素にマウスオーバーします...")
                 await element.hover(timeout=action_wait_time)
                 logger.info("ホバーが成功しました。")
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_inner_text":
                 if not element: raise ValueError("Get text action requires an element.")
                 logger.info("要素の innerText を取得します...")
                 text = await element.inner_text(timeout=action_wait_time)
                 logger.info(f"取得テキスト(innerText): '{text[:100]}{'...' if len(text) > 100 else ''}'") # 長いテキストは省略
                 action_result_details["text"] = text
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_text_content":
                 if not element: raise ValueError("Get text action requires an element.")
                 logger.info("要素の textContent を取得します...")
                 text = await element.text_content(timeout=action_wait_time)
                 text = text.strip() if text else "" # 前後の空白を除去
                 logger.info(f"取得テキスト(textContent): '{text[:100]}{'...' if len(text) > 100 else ''}'")
                 action_result_details["text"] = text
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_inner_html":
                 if not element: raise ValueError("Get HTML action requires an element.")
                 logger.info("要素の innerHTML を取得します...")
                 html_content = await element.inner_html(timeout=action_wait_time)
                 logger.info(f"取得HTML(innerHTML):\n{html_content[:500]}{'...' if len(html_content) > 500 else ''}") # 先頭のみ表示
                 action_result_details["html"] = html_content
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_attribute":
                if not element: raise ValueError("Get attribute action requires an element.")
                if not attribute_name: raise ValueError("Action 'get_attribute' requires 'attribute_name'.")
                logger.info(f"要素の属性 '{attribute_name}' を取得します...")
                attr_value = await element.get_attribute(attribute_name, timeout=action_wait_time)
                pdf_text_content = None
                processed_url = attr_value # 変換後のURLも保持

                # href属性の場合、絶対URLに変換し、PDFなら内容を取得
                if attribute_name.lower() == 'href' and attr_value is not None:
                    original_url = attr_value
                    try:
                        absolute_url = urljoin(current_base_url, original_url) # 相対URLを絶対URLに
                        if original_url != absolute_url:
                            logger.info(f"  href属性値を絶対URLに変換: '{original_url}' -> '{absolute_url}'")
                        processed_url = absolute_url # 変換後のURLを保持

                        # PDFかどうかを判定して処理
                        if isinstance(absolute_url, str) and absolute_url.lower().endswith('.pdf'):
                            logger.info(f"  リンク先がPDFファイルです。ダウンロードとテキスト抽出を試みます: {absolute_url}")
                            pdf_bytes = await utils.download_pdf_async(api_request_context, absolute_url)
                            if pdf_bytes:
                                # 同期関数を非同期で実行
                                pdf_text_content = await asyncio.to_thread(utils.extract_text_from_pdf_sync, pdf_bytes)
                                logger.info(f"  PDFテキスト抽出完了 (先頭200文字): {pdf_text_content[:200] if pdf_text_content else 'None'}...")
                            else:
                                pdf_text_content = "Error: PDF download failed or returned no data."
                                logger.error(f"  PDFダウンロード失敗: {absolute_url}")
                        else:
                             logger.debug(f"  リンク先はPDFではありません ({absolute_url})。")
                    except Exception as url_e:
                        logger.error(f"  URL処理またはPDF処理中にエラーが発生しました (URL: '{original_url}'): {url_e}")
                        pdf_text_content = f"Error processing URL or PDF: {url_e}"

                logger.info(f"取得した属性値 ({attribute_name}): '{processed_url}'") # 変換後のURLを表示
                action_result_details.update({"attribute": attribute_name, "value": processed_url}) # 結果には処理後のURLを保存
                if pdf_text_content is not None:
                    action_result_details["pdf_text"] = pdf_text_content # PDFテキストも結果に含める
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})


            # --- get_all_attributes (変更なし) ---
            elif action == "get_all_attributes":
                if not selector: raise ValueError("Action 'get_all_attributes' requires 'selector'.")
                if not attribute_name: raise ValueError("Action 'get_all_attributes' requires 'attribute_name'.")

                if not found_elements_list:
                    logger.warning(f"動的探索で要素 '{selector}' が見つからなかったため、属性取得をスキップします。")
                    action_result_details["attribute_list"] = [] # 空リストを結果として設定
                else:
                    logger.info(f"動的探索で見つかった {len(found_elements_list)} 個の要素から属性 '{attribute_name}' を取得します。")

                    # --- 結果格納用のリスト ---
                    url_list_for_file: List[Optional[str]] = []       # 最終的な結果ファイル用 (絶対URL)
                    pdf_texts_list_for_file: List[Optional[str]] = [] # 最終的な結果ファイル用
                    scraped_texts_list_for_file: List[Optional[str]] = [] # 最終的な結果ファイル用
                    generic_attribute_list_for_file: List[Optional[str]] = [] # 最終的な結果ファイル用

                    # --- href属性を取得する内部関数 ---
                    async def get_single_href(locator: Locator, index: int) -> Optional[str]:
                         try:
                             href = await locator.get_attribute("href", timeout=max(500, action_wait_time // 5)) # 個々のタイムアウトは短めに
                             return href
                         except Exception as e:
                             logger.warning(f"  要素 {index+1} の href 属性取得中にエラー: {type(e).__name__}")
                             return None

                    # --- 属性名に応じて処理 ---
                    if attribute_name.lower() in ['href', 'pdf', 'content']:
                        logger.info("href属性を取得し、絶対URLに変換します...")
                        # まず全要素からhref属性(元URL)を取得
                        original_href_list: List[Optional[str]] = []
                        for idx, (loc, _) in enumerate(found_elements_list):
                             original_href = await get_single_href(loc, idx)
                             original_href_list.append(original_href)

                        # 逐次処理のための準備
                        absolute_urls_processed: List[Optional[str]] = [None] * len(original_href_list)

                        logger.info(f"--- Processing {len(original_href_list)} URLs for '{attribute_name.lower()}' ---")
                        process_start_time = time.monotonic()

                        for idx, original_url in enumerate(original_href_list):
                            item_start_time = time.monotonic()
                            if original_url is None:
                                logger.info(f"[{idx+1}/{len(original_href_list)}] URL: None (Skipping)")
                                url_list_for_file.append(None)
                                pdf_texts_list_for_file.append(None)
                                scraped_texts_list_for_file.append(None)
                                continue

                            abs_url: Optional[str] = None
                            try:
                                abs_url = urljoin(current_base_url, original_url)
                                logger.info(f"[{idx+1}/{len(original_href_list)}] URL: {abs_url} (Original: {original_url})")
                                absolute_urls_processed[idx] = abs_url # 処理済みURLを保持
                            except Exception as url_e:
                                logger.error(f"  [{idx+1}] URL変換エラー ({original_url}): {url_e}")
                                url_list_for_file.append(f"Error converting URL: {original_url}")
                                pdf_texts_list_for_file.append(None)
                                scraped_texts_list_for_file.append(None)
                                continue

                            # --- pdf モードの場合 ---
                            if attribute_name.lower() == 'pdf':
                                if isinstance(abs_url, str) and abs_url.lower().endswith('.pdf'):
                                    pdf_text_content = "Error: PDF download or extraction failed." # デフォルトエラーメッセージ
                                    try:
                                        pdf_bytes = await utils.download_pdf_async(api_request_context, abs_url)
                                        if pdf_bytes:
                                            pdf_text_content = await asyncio.to_thread(utils.extract_text_from_pdf_sync, pdf_bytes)
                                            logger.info(f"  [{idx+1}] PDF Text Extracted (Length: {len(pdf_text_content or '')})")
                                            logger.debug(f"    Text: {pdf_text_content[:200] if pdf_text_content else 'None'}...")
                                        else:
                                            pdf_text_content = "Error: PDF download failed or returned no data."
                                            logger.error(f"  [{idx+1}] PDF download failed.")
                                    except Exception as pdf_err:
                                        logger.error(f"  [{idx+1}] PDF processing error: {pdf_err}")
                                        pdf_text_content = f"Error: {pdf_err}"
                                    pdf_texts_list_for_file.append(pdf_text_content)
                                    # 他のリストはこのURLでは関係ないのでNoneを追加
                                    url_list_for_file.append(abs_url)
                                    scraped_texts_list_for_file.append(None)
                                else:
                                    logger.info(f"  [{idx+1}] Not a PDF link. Skipping PDF processing.")
                                    url_list_for_file.append(abs_url) # URLは記録
                                    pdf_texts_list_for_file.append(None) # PDFテキストはない
                                    scraped_texts_list_for_file.append(None)

                            # --- content モードの場合 ---
                            elif attribute_name.lower() == 'content':
                                if isinstance(abs_url, str) and not abs_url.lower().endswith('.pdf'):
                                    content_success, scraped_text_or_error = await get_page_inner_text(current_context, abs_url, action_wait_time)
                                    if content_success:
                                        logger.info(f"  [{idx+1}] Page Content Scraped (Length: {len(scraped_text_or_error or '')})")
                                        logger.debug(f"    Content: {scraped_text_or_error[:200] if scraped_text_or_error else ''}...")
                                        scraped_texts_list_for_file.append(scraped_text_or_error)
                                    else:
                                        logger.error(f"  [{idx+1}] Page Content Scraping Failed: {scraped_text_or_error}")
                                        scraped_texts_list_for_file.append(f"Error scraping content: {scraped_text_or_error}")
                                    # 他のリストはこのURLでは関係ないのでNoneを追加
                                    url_list_for_file.append(abs_url)
                                    pdf_texts_list_for_file.append(None)
                                else:
                                    logger.info(f"  [{idx+1}] Is PDF or invalid URL. Skipping content scraping.")
                                    url_list_for_file.append(abs_url) # URLは記録
                                    scraped_texts_list_for_file.append(None) # スクレイプテキストはない
                                    pdf_texts_list_for_file.append(None)

                            # --- href モードの場合 ---
                            elif attribute_name.lower() == 'href':
                                url_list_for_file.append(abs_url)
                                # 他のリストはこのモードでは関係ないのでNoneを追加
                                pdf_texts_list_for_file.append(None)
                                scraped_texts_list_for_file.append(None)

                            item_elapsed = (time.monotonic() - item_start_time) * 1000
                            logger.debug(f"  [{idx+1}] Item processing time: {item_elapsed:.0f}ms")

                        process_elapsed = (time.monotonic() - process_start_time) * 1000
                        logger.info(f"--- Finished processing {len(original_href_list)} URLs ({process_elapsed:.0f}ms) ---")

                        # 結果を action_result_details に格納
                        action_result_details["attribute"] = attribute_name # 元の要求属性名を記録
                        action_result_details["url_list"] = url_list_for_file # 常にURLリストを含める
                        if attribute_name.lower() == 'pdf':
                             action_result_details["pdf_texts"] = pdf_texts_list_for_file
                        elif attribute_name.lower() == 'content':
                             action_result_details["scraped_texts"] = scraped_texts_list_for_file
                        # hrefの場合は url_list のみが主要な結果

                    else: # href, pdf, content 以外の場合 (通常の属性取得)
                        logger.info(f"指定された属性 '{attribute_name}' を取得します...")
                        generic_attribute_list_for_file = [None] * len(found_elements_list)
                        # --- 属性値を取得する内部関数 ---
                        async def get_single_attr(locator: Locator, attr_name: str, index: int) -> Optional[str]:
                            try:
                                return await locator.get_attribute(attr_name, timeout=max(500, action_wait_time // 5))
                            except Exception as e:
                                logger.warning(f"  要素 {index+1} の属性 '{attr_name}' 取得中にエラー: {type(e).__name__}")
                                return None

                        # 逐次処理で属性を取得
                        for idx, (loc, _) in enumerate(found_elements_list):
                             attr_val = await get_single_attr(loc, attribute_name, idx)
                             logger.info(f"  [{idx+1}/{len(found_elements_list)}] Attribute '{attribute_name}': {attr_val}")
                             generic_attribute_list_for_file[idx] = attr_val

                        action_result_details.update({"attribute": attribute_name, "attribute_list": generic_attribute_list_for_file})
                        logger.info(f"取得した属性値リスト ({len(generic_attribute_list_for_file)}件)")
                        # pprint はログが冗長になるので logger.info で十分か

                # 最後に結果を追加
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_all_text_contents":
                 # ... (変更なし) ...
                if not selector: raise ValueError("Action 'get_all_text_contents' requires 'selector'.")
                text_list: List[Optional[str]] = []
                if not found_elements_list:
                    logger.warning(f"動的探索で要素 '{selector}' が見つからなかったため、テキスト取得をスキップします。")
                else:
                    logger.info(f"動的探索で見つかった {len(found_elements_list)} 個の要素から textContent を取得します。")
                    get_text_tasks = []
                    # --- textContent を取得する内部関数 ---
                    async def get_single_text(locator: Locator, index: int) -> Optional[str]:
                        try:
                            text = await locator.text_content(timeout=max(500, action_wait_time // 5))
                            return text.strip() if text else "" # 前後空白除去
                        except Exception as e:
                            logger.warning(f"  要素 {index+1} の textContent 取得中にエラー: {type(e).__name__}")
                            return None

                    for loc_index, (loc, _) in enumerate(found_elements_list):
                         get_text_tasks.append(get_single_text(loc, loc_index))

                    text_list = await asyncio.gather(*get_text_tasks)
                    logger.info(f"取得したテキストリスト ({len(text_list)}件)")

                action_result_details["text_list"] = text_list
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "wait_visible":
                 # ... (変更なし) ...
                if not element: raise ValueError("Wait visible action requires an element.")
                logger.info("要素が表示されるのを待ちます...")
                await element.wait_for(state='visible', timeout=action_wait_time)
                logger.info("要素が表示されていることを確認しました。")
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "select_option":
                 # ... (変更なし) ...
                  if not element: raise ValueError("Select option action requires an element.")
                  if option_type not in ['value', 'index', 'label'] or option_value is None:
                       raise ValueError("Invalid 'option_type' or 'option_value' for select_option action.")
                  logger.info(f"ドロップダウンを選択します (Type: {option_type}, Value: '{option_value}')...")
                  if option_type == 'value':
                      await element.select_option(value=str(option_value), timeout=action_wait_time)
                  elif option_type == 'index':
                      try: index_val = int(option_value)
                      except (ValueError, TypeError): raise ValueError("Option type 'index' requires an integer value.")
                      await element.select_option(index=index_val, timeout=action_wait_time)
                  elif option_type == 'label':
                      await element.select_option(label=str(option_value), timeout=action_wait_time)
                  logger.info("ドロップダウンの選択が成功しました。")
                  action_result_details.update({"option_type": option_type, "option_value": option_value})
                  results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "scroll_to_element":
                 # ... (変更なし) ...
                   if not element: raise ValueError("Scroll action requires an element.")
                   logger.info("要素が表示されるまでスクロールします...")
                   await element.scroll_into_view_if_needed(timeout=action_wait_time)
                   await asyncio.sleep(0.3) # スクロール後の安定待ち
                   logger.info("要素へのスクロールが成功しました。")
                   results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "screenshot":
                 # ... (変更なし) ...
                  # ファイル名の決定 (valueがあればそれ、なければデフォルト名)
                  filename_base = str(value) if value else f"screenshot_step{step_num}"
                  # 拡張子がなければ .png を追加
                  filename = f"{filename_base}.png" if not filename_base.lower().endswith(('.png', '.jpg', '.jpeg')) else filename_base
                  screenshot_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, filename)
                  # ディレクトリが存在しない場合は作成
                  os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                  logger.info(f"スクリーンショットを '{screenshot_path}' に保存します...")
                  if element: # 要素が指定されていれば要素のスクリーンショット
                       await element.screenshot(path=screenshot_path, timeout=action_wait_time)
                       logger.info("要素のスクリーンショットを保存しました。")
                  else: # 要素が指定されていなければページ全体
                       await root_page.screenshot(path=screenshot_path, full_page=True)
                       logger.info("ページ全体のスクリーンショットを保存しました。")
                  action_result_details["filename"] = screenshot_path # 結果にファイルパスを含める
                  results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            else:
                 # ... (変更なし) ...
                  known_actions = ["click", "input", "hover", "get_inner_text", "get_text_content", "get_inner_html", "get_attribute", "get_all_attributes", "get_all_text_contents", "wait_visible", "select_option", "screenshot", "scroll_page_to_bottom", "scroll_to_element", "wait_page_load", "sleep", "switch_to_iframe", "switch_to_parent_frame"]
                  if action not in known_actions:
                     logger.warning(f"未定義または不明なアクション '{action}' です。このステップはスキップされます。")
                     results.append({"step": step_num, "status": "skipped", "action": action, "message": f"Undefined action: {action}"})

        # --- エラーハンドリング (変更なし) ---
        except (PlaywrightTimeoutError, PlaywrightError, ValueError, Exception) as e:
            error_message = f"ステップ {step_num} ({action}) の実行中にエラーが発生しました: {type(e).__name__} - {e}"
            logger.error(error_message, exc_info=True) # スタックトレース付きでログ出力
            error_screenshot_path = None
            # エラー発生時のスクリーンショットを試みる
            if root_page and not root_page.is_closed():
                 timestamp = time.strftime("%Y%m%d_%H%M%S")
                 error_ss_filename = f"error_step{step_num}_{timestamp}.png"
                 error_ss_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, error_ss_filename)
                 try:
                     os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                     await root_page.screenshot(path=error_ss_path, full_page=True)
                     logger.info(f"エラー発生時のスクリーンショットを保存しました: {error_ss_path}")
                     error_screenshot_path = error_ss_path
                 except Exception as ss_e:
                     logger.error(f"エラー発生時のスクリーンショット保存に失敗しました: {ss_e}")
            elif root_page and root_page.is_closed():
                 # ページが閉じられている場合、エラーメッセージに追記
                 error_message += " (Root page was closed during execution)"
                 logger.warning("根本原因: ルートページが閉じられた可能性があります。")

            # エラー情報を結果リストに追加
            error_details = {
                "step": step_num,
                "status": "error",
                "action": action,
                "selector": selector,
                "message": str(e), # エラーメッセージ本文
                "full_error": error_message # より詳細なエラー情報
            }
            if error_screenshot_path:
                error_details["error_screenshot"] = error_screenshot_path
            results.append(error_details)
            return False, results # Falseを返して処理中断

    # 全てのステップが正常に完了した場合
    return True, results


# --- Playwright 実行メイン関数 (修正: クリーンアップ処理) ---
async def run_playwright_automation_async(
        target_url: str,
        actions: List[dict],
        headless_mode: bool = False,
        slow_motion: int = 100,
        default_timeout: int = config.DEFAULT_ACTION_TIMEOUT
    ) -> Tuple[bool, List[dict]]:
    """Playwright を非同期で初期化、アクション実行、終了処理を行う。"""
    logger.info("--- Playwright 自動化開始 (非同期) ---")
    all_success = False
    final_results: List[dict] = []
    playwright = None; browser = None; context = None; page = None
    try:
        playwright = await async_playwright().start()
        logger.info(f"ブラウザ起動 (Chromium, Headless: {headless_mode}, SlowMo: {slow_motion}ms)...")
        browser = await playwright.chromium.launch(headless=headless_mode, slow_mo=slow_motion)
        logger.info("新しいブラウザコンテキストを作成します...")
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36', # 一般的なUA
            viewport={'width': 1920, 'height': 1080}, # 一般的な解像度
            locale='ja-JP', # 日本語ロケール
            timezone_id='Asia/Tokyo', # 日本時間
            # accept_downloads=True, # PDFダウンロード等に必要なら有効化
            extra_http_headers={'Accept-Language': 'ja-JP,ja;q=0.9,en-US;q=0.8,en;q=0.7'} # Accept-Languageヘッダ
        )
        # デフォルトタイムアウト設定
        effective_default_timeout = default_timeout if default_timeout else config.DEFAULT_ACTION_TIMEOUT
        context.set_default_timeout(effective_default_timeout)
        logger.info(f"コンテキストのデフォルトタイムアウトを {effective_default_timeout}ms に設定しました。")
        # APIリクエスト用のコンテキスト (PDFダウンロード等で使用)
        api_request_context = context.request

        ## --- Stealth モード (必要であればコメント解除) ---
        logger.info("Applying stealth mode to the context...")
        try:
            await stealth_async(context)
            logger.info("Stealth mode applied successfully.")
        except Exception as stealth_err:
             logger.warning(f"Failed to apply stealth mode: {stealth_err}")

        logger.info("新しいページを作成します...")
        page = await context.new_page()

        # 最初のページへのナビゲーション (タイムアウトを長めに設定)
        initial_nav_timeout = max(effective_default_timeout * 3, 30000) # デフォルトの3倍か30秒の長い方
        logger.info(f"最初のナビゲーション: {target_url} (タイムアウト: {initial_nav_timeout}ms)...")
        await page.goto(target_url, wait_until="load", timeout=initial_nav_timeout)
        logger.info("最初のナビゲーション成功。アクションの実行を開始します...")

        # アクション実行
        all_success, final_results = await execute_actions_async(page, actions, api_request_context, effective_default_timeout)

        if all_success:
            logger.info("すべてのステップが正常に完了しました。")
        else:
            logger.error("自動化タスクの途中でエラーが発生しました。")

    # --- 全体的なエラーハンドリング ---
    except (PlaywrightTimeoutError, PlaywrightError, Exception) as e:
         error_msg_overall = f"Playwright 処理全体で予期せぬエラーが発生しました: {type(e).__name__} - {e}"
         logger.error(error_msg_overall, exc_info=True) # スタックトレース付きログ
         overall_error_screenshot_path = None
         # エラー発生時のスクリーンショット (ページが存在すれば)
         if page and not page.is_closed():
              timestamp = time.strftime("%Y%m%d_%H%M%S")
              overall_error_ss_filename = f"error_overall_{timestamp}.png"
              overall_error_ss_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, overall_error_ss_filename)
              try:
                  os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                  await page.screenshot(path=overall_error_ss_path, full_page=True)
                  logger.info(f"全体エラー発生時のスクリーンショットを保存しました: {overall_error_ss_path}")
                  overall_error_screenshot_path = overall_error_ss_path
              except Exception as ss_e:
                  logger.error(f"全体エラー発生時のスクリーンショット保存に失敗しました: {ss_e}")
         # 最終結果リストに全体エラー情報を追加 (既に追加されていなければ)
         if not final_results or final_results[-1].get("status") != "error":
             error_details = {"step": "Overall", "status": "error", "message": str(e), "full_error": error_msg_overall}
             if overall_error_screenshot_path:
                 error_details["error_screenshot"] = overall_error_screenshot_path
             final_results.append(error_details)
         all_success = False # 全体エラーなので失敗扱い

    # --- クリーンアップ処理 ---
    finally:
        logger.info("クリーンアップ処理を開始します...")
        # --- ▼▼▼ 修正箇所 ▼▼▼ ---
        if context: # is_closed() チェックを削除
            try:
                await context.close()
                logger.info("ブラウザコンテキストを閉じました。")
            except Exception as context_close_e:
                # 既に閉じられている場合などのエラーは警告レベルに留める
                logger.warning(f"ブラウザコンテキストのクローズ中にエラーが発生しました (無視): {context_close_e}")
        # --- ▲▲▲ 修正箇所 ▲▲▲ ---
        else:
             logger.debug("ブラウザコンテキストは存在しません (既に閉じられたか、作成されませんでした)。")

        if browser and browser.is_connected():
            try: await browser.close(); logger.info("ブラウザを閉じました。")
            except Exception as browser_close_e: logger.error(f"ブラウザのクローズ中にエラーが発生しました: {browser_close_e}")
        else: logger.debug("ブラウザは接続されていないか、存在しません。")

        if playwright:
            try: await playwright.stop(); logger.info("Playwright を停止しました。")
            except Exception as playwright_stop_e: logger.error(f"Playwright の停止中にエラーが発生しました: {playwright_stop_e}")

        # イベントループのクリーンアップを促すための短い待機
        try: await asyncio.sleep(0.1)
        except Exception as sleep_e: logger.warning(f"クリーンアップ後の待機中にエラーが発生しました: {sleep_e}")

    logger.info("--- Playwright 自動化終了 (非同期) ---")
    return all_success, final_results


---


- フォルダ名: .
- ファイル名: playwright_helper_funcs.py
- 内容:
# --- ファイル: playwright_helper_funcs.py ---
"""
Playwrightに関連するヘルパー関数 (要素探索以外) を提供します。
例: ページテキスト取得、iframeセレクター生成など。
"""
import asyncio
import logging
import time
from playwright.async_api import (
    Page,
    Frame,
    Locator,
    BrowserContext,
    TimeoutError as PlaywrightTimeoutError,
    Error as PlaywrightError
)
from typing import Tuple, Optional, Union
from urllib.parse import urljoin

import config
import utils # PDF関連の関数を使用するため

logger = logging.getLogger(__name__)


async def get_page_inner_text(context: BrowserContext, url: str, timeout: int) -> Tuple[bool, Optional[str]]:
    """
    指定されたURLに新しいページでアクセスし、ページのinnerTextを取得する。
    成功したかどうかとテキスト内容（またはエラーメッセージ）のタプルを返す。
    """
    page = None
    start_time = time.monotonic()
    # ページ遷移自体のタイムアウトも考慮
    page_access_timeout = max(int(timeout * 0.8), 15000) # アクションタイムアウトの80%か15秒の大きい方
    logger.info(f"URLからテキスト取得開始: {url} (タイムアウト: {page_access_timeout}ms)")
    try:
        page = await context.new_page()
        # ナビゲーションタイムアウトを設定 (ページアクセスタイムアウトの90%か10秒の大きい方)
        nav_timeout = max(int(page_access_timeout * 0.9), 10000)
        logger.debug(f"  Navigating to {url} with timeout {nav_timeout}ms")
        await page.goto(url, wait_until="load", timeout=nav_timeout)
        logger.debug(f"  Navigation to {url} successful.")

        # <body>要素が表示されるまで待機 (残り時間の50%か2秒の大きい方)
        remaining_time_for_body = page_access_timeout - (time.monotonic() - start_time) * 1000
        if remaining_time_for_body <= 0:
            raise PlaywrightTimeoutError(f"No time left to wait for body after navigation to {url}")
        body_wait_timeout = max(int(remaining_time_for_body * 0.5), 2000)
        logger.debug(f"  Waiting for body element with timeout {body_wait_timeout}ms")
        body_locator = page.locator('body')
        await body_locator.wait_for(state='visible', timeout=body_wait_timeout)
        logger.debug("  Body element is visible.")

        # innerText取得タイムアウト (残り時間の80%か1秒の大きい方)
        remaining_time_for_text = page_access_timeout - (time.monotonic() - start_time) * 1000
        if remaining_time_for_text <= 0:
            raise PlaywrightTimeoutError(f"No time left to get innerText from {url}")
        text_timeout = max(int(remaining_time_for_text * 0.8), 1000)

        logger.debug(f"  Getting innerText with timeout {text_timeout}ms")
        text = await body_locator.inner_text(timeout=text_timeout)
        elapsed = (time.monotonic() - start_time) * 1000
        logger.info(f"テキスト取得成功 ({url})。文字数: {len(text)} ({elapsed:.0f}ms)")
        # 取得したテキストを返す (stripして空白を除去)
        return True, text.strip() if text else ""
    except PlaywrightTimeoutError as e:
        elapsed = (time.monotonic() - start_time) * 1000
        error_msg = f"Error: Timeout during processing {url} ({elapsed:.0f}ms). {e}"
        logger.warning(error_msg)
        # エラーメッセージを返す
        return False, error_msg
    except Exception as e:
        elapsed = (time.monotonic() - start_time) * 1000
        error_msg = f"Error: Failed to get text from {url} ({elapsed:.0f}ms) - {type(e).__name__}: {e}"
        logger.error(error_msg, exc_info=False)
        logger.debug(f"Detailed error getting text from {url}:", exc_info=True)
        # エラーメッセージを返す
        return False, error_msg
    finally:
        if page and not page.is_closed():
            try:
                await page.close()
                logger.debug(f"一時ページ ({url}) を閉じました。")
            except Exception as close_e:
                logger.warning(f"一時ページ ({url}) クローズ中にエラー (無視): {close_e}")


async def generate_iframe_selector_async(iframe_locator: Locator) -> Optional[str]:
    """
    iframe要素のLocatorから、特定しやすいセレクター文字列を生成する試み (id, name, src の順)。
    属性取得は短いタイムアウトで並行実行し、エラーは無視します。
    """
    try:
        # 属性取得を並行実行 (タイムアウト短め: 200ms)
        attrs = await asyncio.gather(
            iframe_locator.get_attribute('id', timeout=200),
            iframe_locator.get_attribute('name', timeout=200),
            iframe_locator.get_attribute('src', timeout=200),
            return_exceptions=True # エラーが発生しても処理を止めない
        )
        # 結果から例外を除外して値を取得
        iframe_id, iframe_name, iframe_src = [a if not isinstance(a, Exception) else None for a in attrs]

        # 優先度順にセレクターを生成
        if iframe_id:
            return f'iframe[id="{iframe_id}"]'
        if iframe_name:
            return f'iframe[name="{iframe_name}"]'
        if iframe_src:
            # srcは長すぎる場合があるので注意が必要だが、特定には役立つ場合がある
            return f'iframe[src="{iframe_src}"]'

    except Exception as e:
        # 属性取得中のエラーはデバッグレベルでログ記録し、無視
        logger.debug(f"iframe属性取得中にエラー（無視）: {e}")

    # 適切なセレクターが見つからなければNoneを返す
    return None


---


- フォルダ名: .
- ファイル名: playwright_launcher.py
- 内容:
# --- ファイル: playwright_launcher.py (修正版) ---
"""
Playwrightの起動、初期設定、アクション実行の呼び出し、終了処理を行います。
ステルスモードエラー時のリトライ機能を追加。
"""
import asyncio
import logging
import os
import time
import traceback
import warnings
from playwright.async_api import (
    async_playwright,
    Page,
    Browser, # Browser 型ヒント追加
    BrowserContext,
    TimeoutError as PlaywrightTimeoutError,
    Error as PlaywrightError,
)
from playwright_stealth import stealth_async
from typing import List, Tuple, Dict, Any, Optional # Optional を追加

import config
from playwright_actions import execute_actions_async # アクション実行関数をインポート

logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore", category=ResourceWarning, message="unclosed transport") # Playwrightの既知の警告を抑制

# --- ▼▼▼ 追加: ステルスモードエラー検出用 ▼▼▼ ---
# 検出対象のエラーメッセージ（完全一致）
STEALTH_ERROR_MESSAGE = "大変申し訳ありませんが、ページを正しく表示できませんでした。\n推奨されているブラウザであるかをご確認の上、時間をおいて再度お試しください。"
# エラーメッセージが含まれる可能性のある要素のセレクター（例: body全体や特定のエラー表示領域）
ERROR_MESSAGE_SELECTOR = "body"
# --- ▲▲▲ 追加 ▲▲▲ ---


# --- ▼▼▼ 追加: ブラウザとコンテキストを起動するヘルパー関数 ▼▼▼ ---
async def _launch_browser_and_context(
    playwright_instance,
    headless_mode: bool,
    slow_motion: int,
    default_timeout: int,
    apply_stealth: bool = True # ステルスモードを適用するかどうかのフラグ
) -> Tuple[Browser, BrowserContext]:
    """ブラウザとコンテキストを起動し、オプションでステルスモードを適用する"""
    logger.info(f"ブラウザ起動 (Chromium, Headless: {headless_mode}, SlowMo: {slow_motion}ms)...")
    browser = await playwright_instance.chromium.launch(
        headless=headless_mode,
        slow_mo=slow_motion,
    )
    logger.info("新しいブラウザコンテキストを作成します...")
    context = await browser.new_context(
        user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
        viewport={'width': 1920, 'height': 1080},
        locale='ja-JP',
        timezone_id='Asia/Tokyo',
        java_script_enabled=True,
        extra_http_headers={'Accept-Language': 'ja-JP,ja;q=0.9,en-US;q=0.8,en;q=0.7'}
    )
    context.set_default_timeout(default_timeout)
    logger.info(f"コンテキストのデフォルトタイムアウトを {default_timeout}ms に設定しました。")

    if apply_stealth:
        logger.info("Applying stealth mode to the context...")
        try:
            await stealth_async(context)
            logger.info("Stealth mode applied successfully.")
        except Exception as stealth_err:
            logger.warning(f"Failed to apply stealth mode: {stealth_err}")
    else:
        logger.info("Stealth mode is disabled for this context.")

    return browser, context
# --- ▲▲▲ 追加 ▲▲▲ ---


async def run_playwright_automation_async(
        target_url: str,
        actions: List[Dict[str, Any]],
        headless_mode: bool = False,
        slow_motion: int = 100,
        default_timeout: int = config.DEFAULT_ACTION_TIMEOUT
    ) -> Tuple[bool, List[Dict[str, Any]]]:
    """
    Playwright を非同期で初期化し、指定されたURLにアクセス後、一連のアクションを実行します。
    ステルスモードでエラーが発生した場合、ステルスモードなしでリトライします。
    """
    logger.info("--- Playwright 自動化開始 (非同期) ---")
    all_success = False
    final_results: List[Dict[str, Any]] = []
    playwright = None
    browser: Optional[Browser] = None # Optional に変更
    context: Optional[BrowserContext] = None
    page: Optional[Page] = None
    initial_navigation_successful = False
    retry_attempted = False # リトライフラグ

    try:
        playwright = await async_playwright().start()
        effective_default_timeout = default_timeout if default_timeout else config.DEFAULT_ACTION_TIMEOUT

        # --- 1回目の試行 (ステルスモードあり) ---
        logger.info("--- Initial attempt (with Stealth Mode) ---")
        apply_stealth_mode = True # 最初はステルスモードを適用
        browser, context = await _launch_browser_and_context(
            playwright, headless_mode, slow_motion, effective_default_timeout, apply_stealth=apply_stealth_mode
        )

        logger.info("新しいページを作成します...")
        page = await context.new_page()
        api_request_context = context.request # APIリクエストコンテキストはここで取得

        # 最初のページへのナビゲーション (タイムアウトを長めに設定)
        initial_nav_timeout = max(effective_default_timeout * 3, 30000)
        logger.info(f"最初のナビゲーション: {target_url} (タイムアウト: {initial_nav_timeout}ms)...")
        try:
            await page.goto(target_url, wait_until="load", timeout=initial_nav_timeout)
            initial_navigation_successful = True
            logger.info("最初のナビゲーション成功。")

            # --- ▼▼▼ エラーメッセージチェック ▼▼▼ ---
            logger.info("Checking for stealth error message...")
            try:
                # エラーメッセージが表示されるまで少し待つ（必要に応じて調整）
                await page.wait_for_timeout(1000)
                # 指定されたセレクター内のテキストを取得
                page_content = await page.locator(ERROR_MESSAGE_SELECTOR).inner_text(timeout=5000) # タイムアウト設定
                # 改行も含めて完全一致で比較
                if STEALTH_ERROR_MESSAGE in page_content:
                     logger.warning(f"検出されたエラーメッセージ: \"{STEALTH_ERROR_MESSAGE}\"")
                     logger.warning("Stealth mode may be blocked. Retrying without stealth mode...")
                     retry_attempted = True
                     initial_navigation_successful = False # リトライするので一旦失敗扱い

                     # --- 現在のブラウザとコンテキストを閉じる ---
                     logger.info("Closing current browser and context for retry...")
                     if context: await context.close()
                     if browser: await browser.close()
                     browser, context, page = None, None, None # リセット

                     # --- 2回目の試行 (ステルスモードなし) ---
                     logger.info("--- Retry attempt (without Stealth Mode) ---")
                     apply_stealth_mode = False # ステルスモードを無効化
                     browser, context = await _launch_browser_and_context(
                         playwright, headless_mode, slow_motion, effective_default_timeout, apply_stealth=apply_stealth_mode
                     )
                     logger.info("新しいページを作成します (リトライ)...")
                     page = await context.new_page()
                     api_request_context = context.request # APIリクエストコンテキストを再取得

                     logger.info(f"再ナビゲーション: {target_url} (タイムアウト: {initial_nav_timeout}ms)...")
                     await page.goto(target_url, wait_until="load", timeout=initial_nav_timeout)
                     initial_navigation_successful = True # リトライ成功
                     logger.info("再ナビゲーション成功。")
                else:
                    logger.info("Stealth error message not found.")
            except PlaywrightTimeoutError:
                 logger.warning(f"Timeout while checking for error message in '{ERROR_MESSAGE_SELECTOR}'. Assuming no error message found.")
            except Exception as check_err:
                logger.warning(f"Error checking for stealth message: {check_err}. Proceeding...", exc_info=True)
            # --- ▲▲▲ エラーメッセージチェック ▲▲▲ ---

        except (PlaywrightTimeoutError, PlaywrightError) as nav_error:
            logger.error(f"最初のナビゲーションに失敗しました ({target_url}): {nav_error}")
            # ナビゲーション失敗は致命的エラーとして扱う
            raise nav_error # エラーを再送出して全体のエラーハンドリングに任せる

        # --- ナビゲーション成功後、アクション実行 ---
        if initial_navigation_successful and page:
            logger.info("アクションの実行を開始します...")
            all_success, final_results = await execute_actions_async(
                page, actions, api_request_context, effective_default_timeout
            )
            if all_success:
                logger.info("すべてのステップが正常に完了しました。")
            else:
                logger.error("自動化タスクの途中でエラーが発生しました。")
        elif not initial_navigation_successful and retry_attempted:
             # リトライ後のナビゲーションも失敗した場合
             raise PlaywrightError(f"Navigation failed even after retrying without stealth mode for URL: {target_url}")
        else:
             # 最初のナビゲーションが失敗し、リトライもされなかった場合（エラーチェック中のエラーなど）
             raise PlaywrightError(f"Initial navigation failed and could not proceed for URL: {target_url}")


    # --- 全体的なエラーハンドリング ---
    except (PlaywrightTimeoutError, PlaywrightError, Exception) as e:
         error_msg_overall = f"Playwright 処理全体で予期せぬエラーが発生しました: {type(e).__name__} - {e}"
         logger.error(error_msg_overall, exc_info=True)
         overall_error_screenshot_path = None
         if page and not page.is_closed():
              timestamp = time.strftime("%Y%m%d_%H%M%S")
              overall_error_ss_filename = f"error_overall_{timestamp}.png"
              overall_error_ss_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, overall_error_ss_filename)
              try:
                  os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                  await page.screenshot(path=overall_error_ss_path, full_page=True, timeout=10000)
                  logger.info(f"全体エラー発生時のスクリーンショットを保存しました: {overall_error_ss_path}")
                  overall_error_screenshot_path = overall_error_ss_path
              except Exception as ss_e:
                  logger.error(f"全体エラー発生時のスクリーンショット保存に失敗しました: {ss_e}")
         if not final_results or (isinstance(final_results[-1].get("status"), str) and final_results[-1].get("status") != "error"):
             error_details = {
                 "step": "Overall Execution",
                 "status": "error",
                 "message": str(e),
                 "full_error": error_msg_overall,
                 "traceback": traceback.format_exc()
             }
             if overall_error_screenshot_path:
                 error_details["error_screenshot"] = overall_error_screenshot_path
             final_results.append(error_details)
         all_success = False

    # --- クリーンアップ処理 ---
    finally:
        logger.info("クリーンアップ処理を開始します...")
        if context:
            try:
                await context.close()
                logger.info("ブラウザコンテキストを閉じました。")
            except Exception as context_close_e:
                if "closed" not in str(context_close_e).lower():
                    logger.warning(f"ブラウザコンテキストのクローズ中にエラーが発生しました (無視): {context_close_e}")
        else:
             logger.debug("ブラウザコンテキストは存在しません。")

        if browser and browser.is_connected():
            try:
                await browser.close()
                logger.info("ブラウザを閉じました。")
            except Exception as browser_close_e:
                logger.error(f"ブラウザのクローズ中にエラーが発生しました: {browser_close_e}")
        else:
             logger.debug("ブラウザは接続されていないか、存在しません。")

        if playwright:
            try:
                await playwright.stop()
                logger.info("Playwright を停止しました。")
            except Exception as playwright_stop_e:
                logger.error(f"Playwright の停止中にエラーが発生しました: {playwright_stop_e}")
        try:
            await asyncio.sleep(0.1)
        except Exception as sleep_e:
            logger.warning(f"クリーンアップ後の待機中にエラーが発生しました: {sleep_e}")

    logger.info("--- Playwright 自動化終了 (非同期) ---")
    return all_success, final_results


---


- フォルダ名: .
- ファイル名: playwright_locator_test_results.json
- 内容:
{
  "google_search_top": [
    {
      "name": "Search Textbox (by Role/Label)",
      "locator_type": "get_by_... (0)",
      "status": "Fail (Not Found)",
      "count": 0,
      "is_visible": false,
      "error": null,
      "selector_used": "get_by_... (0)",
      "duration_ms": 31
    },
    {
      "name": "Search Textbox (by Role/Label)",
      "locator_type": "get_by_... (1)",
      "status": "Success",
      "count": 1,
      "is_visible": true,
      "error": null,
      "selector_used": "get_by_... (1)",
      "duration_ms": 3047
    },
    {
      "name": "Search Button (by Role/Name)",
      "locator_type": "get_by_... (0)",
      "status": "Success",
      "count": 1,
      "is_visible": true,
      "error": null,
      "selector_used": "get_by_... (0)",
      "duration_ms": 3031
    },
    {
      "name": "Search Button (by Role/Name)",
      "locator_type": "get_by_... (1)",
      "status": "Fail (Found 2 elements)",
      "count": 2,
      "is_visible": false,
      "error": null,
      "selector_used": "get_by_... (1)",
      "duration_ms": 16
    },
    {
      "name": "Feeling Lucky Button (by Role/Name)",
      "locator_type": "get_by_... (0)",
      "status": "Success",
      "count": 1,
      "is_visible": true,
      "error": null,
      "selector_used": "get_by_... (0)",
      "duration_ms": 3031
    },
    {
      "name": "Feeling Lucky Button (by Role/Name)",
      "locator_type": "get_by_... (1)",
      "status": "Fail (Found 2 elements)",
      "count": 2,
      "is_visible": false,
      "error": null,
      "selector_used": "get_by_... (1)",
      "duration_ms": 0
    }
  ],
  "google_results": [
    {
      "name": "Result 1 Link (by Text/Role)",
      "locator_type": "get_by_... (0)",
      "status": "Fail (Not Found)",
      "count": 0,
      "is_visible": false,
      "error": null,
      "selector_used": "get_by_... (0)",
      "duration_ms": 62
    },
    {
      "name": "Result 1 Link (by Text/Role)",
      "locator_type": "get_by_... (1)",
      "status": "Fail (Not Found)",
      "count": 0,
      "is_visible": false,
      "error": null,
      "selector_used": "get_by_... (1)",
      "duration_ms": 16
    },
    {
      "name": "Result 2 Link (by nth)",
      "locator_type": "get_by_... (0)",
      "status": "Fail (Not Found)",
      "count": 0,
      "is_visible": false,
      "error": null,
      "selector_used": "get_by_... (0)",
      "duration_ms": 0
    },
    {
      "name": "Result 2 Link (by nth)",
      "locator_type": "get_by_... (1)",
      "status": "Fail (Found 14 elements)",
      "count": 14,
      "is_visible": false,
      "error": null,
      "selector_used": "get_by_... (1)",
      "duration_ms": 15
    },
    {
      "name": "Next Page Link (by Role/Text)",
      "locator_type": "get_by_... (0)",
      "status": "Fail (Not Visible)",
      "count": 1,
      "is_visible": false,
      "error": null,
      "selector_used": "get_by_... (0)",
      "duration_ms": 32
    },
    {
      "name": "Next Page Link (by Role/Text)",
      "locator_type": "get_by_... (1)",
      "status": "Fail (Not Visible)",
      "count": 1,
      "is_visible": false,
      "error": null,
      "selector_used": "get_by_... (1)",
      "duration_ms": 15
    }
  ],
  "news_article": [
    {
      "site": "news_article",
      "status": "Navigation Failed",
      "error": "Page.goto: net::ERR_NAME_NOT_RESOLVED at https://news.example.com/article123\nCall log:\n  - navigating to \"https://news.example.com/article123\", waiting until \"load\"\n"
    }
  ]
}


---


- フォルダ名: .
- ファイル名: README copy.md
- 内容:
# Web-Runner-mcp

![Web-Runner Logo](./Web-Runner.png)

* Effortless Web Automation with Playwright & JSON. *

## Overview

Streamline your web automation tasks! Web-Runner is a powerful yet user-friendly Python application built on Playwright that allows you to define and execute complex browser interactions using a simple JSON configuration. Forget writing boilerplate Playwright code – define your automation logic declaratively and let Web-Runner handle the rest.

It's perfect for web scraping (including PDF content!), automated testing, and automating repetitive online tasks without requiring extensive Playwright expertise.

## Why Web-Runner?

*   **Simplified Workflow:** Define your automation logic declaratively using our intuitive JSON format.
*   **Visual JSON Generator:** Use the included `json_generator.html` tool to visually build your automation steps and generate the required JSON input, making setup quick and easy.
*   **Robust Action Support:** Handles a wide range of browser interactions: clicks, text input, hovering, dropdown selection, scrolling, waiting for elements/page loads, and taking screenshots.
*   **Advanced Data Extraction:** Go beyond basic scraping. Extract `innerText`, `textContent`, `innerHTML`, specific element attributes (single or multiple), and automatically resolve relative URLs to absolute ones when getting `href` attributes.
*   **Intelligent iframe Handling:** Features smart, automatic iframe scope detection, attempting to find elements even within nested frames without requiring explicit `switch_to_iframe` commands in many common scenarios. (Manual switching is also supported).
*   **Unique PDF Text Extraction:** Automatically detects `.pdf` links (when extracting `href`), downloads the file, and extracts its text content, seamlessly integrating it into your results.
*   **Asynchronous Power:** Built with `asyncio` for efficient handling of network operations and parallel processing.
*   **Debugging Made Easy:** Provides detailed logging (`playwright_runner_async.log`) and automatically saves screenshots upon errors (`screenshots/` directory).

## Ideal For

*   Developers needing to quickly automate web interactions.
*   QA Engineers setting up browser tests.
*   Data Analysts and Researchers scraping web data, including from PDFs.
*   Anyone looking to automate repetitive online tasks.

## Getting Started

### Prerequisites

*   Python 3.8+
*   Playwright browsers installed (Run `playwright install` after installing the library)

### Installation

1.  Clone this repository:
    ```bash
    git clone https://github.com/your-username/web-runner.git # Replace with your repo URL
    cd web-runner
    ```
2.  Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```
    *(If you don't have a requirements.txt yet, list the command: `pip install playwright PyMuPDF`)*
3.  Install Playwright browsers:
    ```bash
    playwright install
    ```

### Usage

1.  **Create your actions JSON file:**
    *   Use the `json_generator.html` file in your browser to visually build the steps.
    *   Alternatively, manually create a JSON file (e.g., `my_task.json`) following this structure:
        ```json
        {
          "target_url": "https://example.com",
          "actions": [
            {
              "action": "input",
              "selector": "#search",
              "value": "Playwright"
            },
            {
              "action": "click",
              "selector": "button[type='submit']"
            },
            {
              "action": "get_text_content",
              "selector": "h1"
            }
            // Add more actions...
          ]
        }
        ```
2.  **Run the application:**
    ```bash
    python main.py --input my_task.json
    ```
    *   Use `--headless` to run without opening a browser window.
    *   Use `--slowmo <milliseconds>` (e.g., `--slowmo 500`) to slow down execution for observation.
3.  **Check the results:**
    *   The execution log will be printed to the console and saved to `playwright_runner_async.log`.
    *   The final extracted data and step results will be printed at the end.
    *   Any error screenshots will be saved in the `screenshots/` directory.

## Dependencies

*   [Playwright](https://playwright.dev/python/)
*   [PyMuPDF (fitz)](https://pymupdf.readthedocs.io/en/latest/)

*(You can list specific versions if needed, especially if you provide a `requirements.txt`)*

## Contributing

*(Optional: Add guidelines here if you welcome contributions)*
Contributions are welcome! Please feel free to submit a pull request or open an issue.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details. 


---


- フォルダ名: .
- ファイル名: README.md
- 内容:
# Web-Runner-mcp: Advanced Web Browser Operation Protocol for AI

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/python-3.12%2B-blue.svg)](https://www.python.org/)
<!-- Add/modify badges as needed -->

**Web-Runner-mcp** is a Python project designed to make Playwright's powerful browser automation capabilities easily accessible to AI agents and other applications through the standardized **Model Context Protocol (MCP)**.

![Web-Runner Logo](./Web-Runner.png)


## Table of Contents

*   [Overview](#overview)
*   [Why Web-Runner-mcp?](#why-web-runner-mcp)
*   [Key Features](#key-features)
    *   [Supported Actions](#supported-actions)
    *   [PDF Text Extraction](#pdf-text-extraction)
    *   [Error Handling](#error-handling)
*   [Usage](#usage)
    *   [1. Setup](#1-setup)
    *   [2. Starting the Server (SSE Mode Example)](#2-starting-the-server-sse-mode-example)
    *   [3. Creating JSON Data for Web-Runner](#3-creating-json-data-for-web-runner)
        *   [Step 1: Prepare the JSON Generator](#step-1-prepare-the-json-generator)
        *   [Step 2: Get CSS Selectors for Target Elements](#step-2-get-css-selectors-for-target-elements)
        *   [Step 3: Create Operation Steps in json_generator.html](#step-3-create-operation-steps-in-json_generatorhtml)
        *   [Step 4: Place the JSON File](#step-4-place-the-json-file)
    *   [4. Command-Line Execution (for Testing)](#4-command-line-execution-for-testing)
    *   [5. Running from the GUI Client](#5-running-from-the-gui-client)
    *   [6. Usage from AI Applications](#6-usage-from-ai-applications)
*   [JSON Format (Reference)](#json-format-reference)
*   [Comparison with Other Tools](#comparison-with-other-tools)
*   [Future Plans](#future-plans)
*   [Contributing](#contributing)
*   [License](#license)

---

## Overview

Information gathering and interaction with the web are essential for today's AI agents, but existing tools have limitations. While simple content retrieval or fetching search result lists is possible, tasks like interacting with login-required sites, handling pages rendered with complex JavaScript, navigating iframe structures, and processing PDF content remain challenging. Furthermore, reliably controlling low-level APIs like Playwright directly from Large Language Models (LLMs) presents a significant hurdle.

Web-Runner-mcp proposes a new approach to tackle these challenges.

Instead of instructing the LLM to perform individual browser operations, Web-Runner-mcp allows you to define a sequence of desired operations in a JSON format and pass it to an MCP server for execution. The current version executes these operations reliably based on the JSON file instructions, without direct LLM involvement in the browser control loop itself.

This might be a **"small revolution"** in how AI interacts with the web, opening doors to the deeper, more complex parts of the web that were previously inaccessible to AI.

## Why Web-Runner-mcp?

*   **Advanced Web Operations:**
    *   **Login:** Access and interact with websites requiring authentication.
    *   **PDF:** Download linked PDFs and extract their text content.
    *   **Iframe:** Explore and interact with elements within nested iframes (dynamic discovery).
    *   **Multiple Tabs/Pages:** Follow new pages opened by clicks.
    *   **Dynamic Content:** Wait for and interact with elements generated by JavaScript.
*   **Versatile Data Extraction:**
    *   Flexible text/HTML retrieval using `innerText`, `textContent`, `innerHTML`.
    *   Get specific attribute values using `getAttribute`.
    *   Efficient data collection from multiple elements using `getAllAttributes`, `getAllTextContents` (with dynamic iframe discovery).
*   **Declarative Operation Definition:**
    *   Describe the desired steps in JSON.
    *   Ensures reproducibility and simplifies debugging.
*   **MCP Compliance:**
    *   Standardized protocol enables integration with various MCP clients (Dify custom tools, Python AI agent frameworks, custom clients, etc.).
    *   Separates client and server concerns.
*   **Reliable Execution:**
    *   Stable browser operations powered by Playwright.
    *   Appropriate waiting mechanisms and error handling.

## Key Features

*   **MCP Server (`web_runner_mcp_server.py`):** Implemented in Python (based on `FastMCP`), exposes Web-Runner functionality as the `execute_web_runner` tool.
*   **Web-Runner Core (`playwright_handler.py`, `utils.py`, `config.py`):** Uses Playwright (async) to execute browser operations based on input JSON. Handles core logic, settings, utility functions, dynamic iframe discovery, and PDF processing.
*   **Web-Runner Standalone Execution (`main.py`):** An entry point for running Web-Runner directly from the command line without the MCP server (for debugging and unit testing).
*   **MCP Client Core (`web_runner_mcp_client_core.py`):** Provides the core function (`execute_web_runner_via_mcp`) for invoking the MCP server programmatically (e.g., from AI agents).
*   **GUI Client (`web_runner_mcp_client_GUI.py`):** A convenient graphical interface for selecting JSON files, running tasks manually, and launching the JSON generator.

### Supported Actions

*   `click`: Clicks an element.
*   `input`: Enters text into an element.
*   `hover`: Hovers over an element.
*   `get_inner_text`, `get_text_content`, `get_inner_html`: Gets text/HTML (single element).
*   `get_attribute`: Gets an attribute value (single element).
*   `get_all_attributes`, `get_all_text_contents`: Gets attribute values/text content as a list (multiple elements, searches within iframes).
*   `wait_visible`: Waits for an element to become visible.
*   `select_option`: Selects an option from a dropdown list.
*   `screenshot`: Saves a screenshot of the page or an element (server-side).
*   `scroll_page_to_bottom`, `scroll_to_element`: Performs scroll operations.
*   `wait_page_load`: Waits for the page to finish loading.
*   `sleep`: Pauses execution for a specified duration.
*   `switch_to_iframe`, `switch_to_parent_frame`: Moves focus between iframes (explicitly specified).

### PDF Text Extraction

Automatically downloads PDFs linked via `get_attribute(href=...)` or `get_all_attributes(href=...)` and includes the extracted text in the results.

### Error Handling

Records error information for each step, including the screenshot path (on the server's filesystem) if an error occurs.

## Usage

### 1. Setup

**(1) Clone the repository:**

```bash
git clone https://github.com/sinzy0925/web-runner-mcp.git
cd web-runner-mcp
```

**(2) Prepare Python environment (Python 3.12+ recommended):**
```bash
# Create a virtual environment (e.g., venv312)
python -m venv venv312
# Activate the virtual environment
# Windows PowerShell
.\venv312\Scripts\Activate
# Linux/macOS
source venv312/bin/activate
```

**(3) Install dependencies:**
Install using the requirements.txt file.
```bash
pip install -r requirements.txt
```

**(4) Install Playwright browsers:**
```bash
playwright install
```

### 2. Starting the Server (SSE Mode Example)
**Note: This mode has not been fully verified and might require adjustments.**
To allow access over the network (e.g., for Dify integration), start the server in SSE mode.

```bash
# Run web_runner_mcp_server.py directly
python web_runner_mcp_server.py --transport sse --host 0.0.0.0 --port 8000
```
*   Use `--host 0.0.0.0` to allow access from other machines. Use `127.0.0.1` (default) for local access only.
*   `--port 8000` specifies the port the server listens on.
*   Server logs are output to `web_runner_mcp_server.log` (default setting).

### 3. Creating JSON Data for Web-Runner
You can use the included `json_generator.html` to interactively create the JSON file in your browser.

#### Step 1: Prepare the JSON Generator
1. Open the `json_generator.html` file located in the project folder with your web browser (double-click).

#### Step 2: Get CSS Selectors for Target Elements
1. Open the target website you want to automate in a separate browser tab or window.
2. Open the developer tools on that page (usually F12 key or right-click > "Inspect"/"Inspect Element").
3. Click the element selection icon (↖) in the developer tools.
4. Click the element you want to interact with (button, input field, etc.) on the webpage.
5. In the developer tools, right-click the highlighted HTML element and select [Copy] > [Copy selector].

#### Step 3: Create Operation Steps in json_generator.html
1. Go back to the `json_generator.html` tab.
2. Enter the website's URL in "1. Target URL:".
3. In "2. Operation Steps", fill in the following:
    *   Target Element CSS Selector: Paste the selector you copied.
    *   Operation: Choose the desired action.
    *   Additional Parameters: Enter values if needed (e.g., `value`, `attribute_name`).
4. Click "Add Step" and repeat step 3 for all required actions.
5. Click "Generate JSON Data" to see the generated JSON.
6. Click "Download input.json" to save the JSON file.

#### Step 4: Place the JSON File
1. Move the downloaded JSON file into the `json/` folder within the project directory. You can rename the file as needed (e.g., `my_task.json`).

### 4. Command-Line Execution (for Testing)
You can test the Web-Runner directly from the command line using the core client function (`web_runner_mcp_client_core.py`) without the GUI. This is useful for verifying programmatic calls, like those from an AI agent.
1. Ensure your desired JSON file is in the `json/` folder (e.g., `tdnet.json`).
2. Run the following command in your activated terminal:
```bash
python web_runner_mcp_client_core.py --jsonfile json/tdnet.json --no-headless --slowmo 500
```
*   `--jsonfile`: Specifies the path to the JSON file to execute (default: `json/tdnet.json`).
*   `--no-headless`: Use this flag to display the browser during execution (default is visible). Use `--headless` to run in the background.
*   `--slowmo`: (Optional) Adds a delay (in milliseconds) between operations (e.g., `--slowmo 500`).
*   `--output`: (Optional) Specifies the path for the output file (default: `output_web_runner.txt`).

The execution results (successful data retrieval or error information) will be printed to the console in JSON format and also written to the specified output file.

### 5. Running from the GUI Client
For manual testing and debugging, the GUI client (`web_runner_mcp_client_GUI.py`) is convenient.
1. Run the following command in your activated terminal:
```bash
python web_runner_mcp_client_GUI.py
```
2. In the application window, select the desired JSON file from the dropdown list.
3. Click the "実行 ▶" (Run) button.
4. The execution results will be displayed in the text area below.
5. You can also click the "JSONジェネレーター" (JSON Generator) button to open `json_generator.html`.

### 6. Usage from AI Applications
To use Web-Runner-mcp from other Python scripts or AI agent frameworks, import and use the `execute_web_runner_via_mcp` function from `web_runner_mcp_client_core.py`.

```python
import asyncio
import json
import sys # Add sys import
# Ensure web_runner_mcp_client_core.py is in the import path
try:
    from web_runner_mcp_client_core import execute_web_runner_via_mcp
except ImportError:
    print("Error: web_runner_mcp_client_core.py not found.")
    # Error handling or path configuration needed
    sys.exit(1) # Example

async def run_task():
    input_data = {
        "target_url": "https://example.com",
        "actions": [
            {"action": "get_text_content", "selector": "h1"},
            {"action": "get_attribute", "selector": "img", "attribute_name": "src"}
        ]
        # Optionally specify timeouts etc.
        # "default_timeout_ms": 15000
    }
    # Execute in headless mode with 50ms slow motion
    success, result_or_error = await execute_web_runner_via_mcp(
        input_data, headless=True, slow_mo=50 # Specify headless, slow_mo
    )

    if success and isinstance(result_or_error, str):
        print("Task successful! Result (JSON):")
        try:
            result_dict = json.loads(result_or_error)
            print(json.dumps(result_dict, indent=2, ensure_ascii=False))
            # --- Process the results, potentially pass to an LLM ---
            # llm_prompt = f"Analyze the following website operation results:\n```json\n{result_or_error}\n```"
            # llm_response = await call_llm(llm_prompt)
        except json.JSONDecodeError:
            print("Error: Response from server is not valid JSON:")
            print(result_or_error)
    else:
        print("Task failed:")
        print(result_or_error) # Display error information (dictionary)
        # --- Process the error information, potentially pass to an LLM ---
        # error_prompt = f"Website operation failed. Error details:\n{result_or_error}\nInfer the cause."
        # llm_response = await call_llm(error_prompt)

if __name__ == "__main__":
    asyncio.run(run_task())
```

## JSON Format (Reference)
Refer to the JSON files provided in the `json/` folder for examples.
Here is the basic structure of the input JSON:
```json
{
  "target_url": "Starting URL (e.g., https://www.example.com)",
  "actions": [
    {
      "action": "Action name (e.g., click)",
      "selector": "CSS selector (required for element actions)",
      "value": "Input value, wait time, etc. (depends on action)",
      "attribute_name": "Attribute to get (for get_attribute actions)",
      "option_type": "Dropdown selection type (for select_option)",
      "option_value": "Dropdown selection value (for select_option)",
      "wait_time_ms": "Action-specific timeout (optional)",
      "iframe_selector": "Iframe selector (for switch_to_iframe)"
    },
    // ... other action steps ...
  ]
  // Options (can be specified when calling the tool)
  // "headless": true, // Overrides client's headless setting if provided
  // "slow_mo": 100,   // Overrides client's slow_mo setting if provided
  // "default_timeout_ms": 15000 // Overrides the default action timeout
}
```

## Comparison with Other Tools
*   **General Web Scraping Libraries (BeautifulSoup, Scrapy):** Excellent for parsing static HTML, but struggle with or cannot handle JavaScript execution, logins, complex user interactions, iframes, and PDFs. Web-Runner-mcp, being Playwright-based, handles these advanced operations.
*   **Playwright-MCP:** Exposes Playwright's low-level API directly as MCP tools. Highly flexible, but requires complex prompt engineering and state management for reliable control from LLMs. Web-Runner-mcp offers a more declarative and reliable interface by defining operation sequences in JSON.
*   **Simple Web Fetching Tools (e.g., URL content fetchers):** Easy for getting content from a single URL, but incapable of multi-step operations or interactions. Web-Runner-mcp executes multi-step workflows.

## Future Plans
*   **LLM-Powered JSON Generation:** Integrate functionality to automatically generate Web-Runner JSON from natural language instructions.
*   **Expanded Action Support:** Add support for more Playwright features (e.g., file uploads, cookie manipulation).
*   **Official Dify Custom Tool Support:** Stabilize the HTTP/SSE interface aiming for potential registration in the Dify marketplace.
*   **Enhanced Error Handling and Recovery:** Implement more detailed error analysis and potentially automatic retry/recovery mechanisms.

## Contributing
Bug reports, feature suggestions, and pull requests are welcome! Please see CONTRIBUTING.md for details (to be created if not present).

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


---


- フォルダ名: .
- ファイル名: script.js
- 内容:
(function() {
    console.log("[JavaScript] Script loaded and running.");

    function getSelector(element) {
        let path = [];
        while (element) {
            let selector = element.tagName.toLowerCase();

            if (element.id) {
                selector += `#${element.id}`;
            } else if (element.className) {
                selector += `.${element.className.replace(/ /g, '.')}`;
            } else {
                let index = 1;
                let sibling = element.previousElementSibling;
                while (sibling) {
                    if (sibling.tagName === element.tagName) {
                        index++;
                    }
                    sibling = sibling.previousElementSibling;
                }
                selector += `:nth-of-type(${index})`;
            }

            path.unshift(selector);
            element = element.parentNode;
        }
        return path.slice(1).join(' > ');
    }

    // DOMContentLoaded イベントを使用して、DOM がロードされた後にイベントリスナーを登録する
    document.addEventListener('DOMContentLoaded', function() {
        console.log("[JavaScript] DOMContentLoaded event fired.");

        // イベント委譲を使用する
        document.body.addEventListener('click', function(event) {
            const target = event.target;
            const selector = getSelector(target);
            window.clickSelector = selector;
            console.log("[JavaScript] Click event on:", selector, target);
        });

        document.body.addEventListener('focus', function(event) {
            const target = event.target;
            const selector = getSelector(target);
            window.focusSelector = selector;
            console.log("[JavaScript] Focus event on:", selector, target);
        }, true); // キャプチャフェーズを使用

         document.body.addEventListener('blur', function(event) {
            const target = event.target;
            const selector = getSelector(target);
            window.blurSelector = selector;
            console.log("[JavaScript] Blur event on:", selector, target);
        }, true); // キャプチャフェーズを使用

        // 他のイベントも同様に処理する
        console.log("[JavaScript] Event listeners added.");
    });
})();


---


- フォルダ名: .
- ファイル名: utils.py
- 内容:
# --- ファイル: utils.py (結果追記機能追加版) ---
import json
import logging
import os
import sys
import asyncio
import time
import traceback
import fitz  # PyMuPDF
from playwright.async_api import APIRequestContext, TimeoutError as PlaywrightTimeoutError
# <<< typing に Optional, Dict, Any, List, Union を追加 >>>
from typing import Optional, Dict, Any, List, Union
from urllib.parse import urljoin

import config

logger = logging.getLogger(__name__)

# --- setup_logging_for_standalone, load_input_from_json, ---
# --- extract_text_from_pdf_sync, download_pdf_async は変更なし ---
# (コードは省略)
def setup_logging_for_standalone(log_file_path: str = config.LOG_FILE):
    """Web-Runner単体実行用のロギング設定を行います。"""
    log_level = logging.INFO # デフォルトレベル
    root_logger = logging.getLogger()
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    handlers = [console_handler]
    log_target = "Console"
    file_handler = None
    try:
        log_dir = os.path.dirname(log_file_path)
        if log_dir:
            if not os.path.exists(log_dir):
                try:
                    os.makedirs(log_dir, exist_ok=True)
                    print(f"DEBUG [utils]: Created directory '{log_dir}'")
                except Exception as e:
                    print(f"警告 [utils]: ログディレクトリ '{log_dir}' の作成に失敗しました: {e}", file=sys.stderr)
                    raise
            else:
                print(f"DEBUG [utils]: Directory '{log_dir}' already exists.")
        try:
            with open(log_file_path, 'a') as f:
                print(f"DEBUG [utils]: Successfully opened (or created) '{log_file_path}' for appending.")
        except Exception as e:
             print(f"警告 [utils]: ログファイル '{log_file_path}' を開けません（権限確認）: {e}", file=sys.stderr)
             raise
        file_handler = logging.FileHandler(log_file_path, encoding='utf-8', mode='a')
        file_handler.setFormatter(formatter)
        handlers.append(file_handler)
        log_target += f" and File ('{log_file_path}')"
        print(f"DEBUG [utils]: FileHandler created for '{log_file_path}'")
    except Exception as e:
        print(f"警告 [utils]: ログファイル '{log_file_path}' のハンドラ設定に失敗しました: {e}", file=sys.stderr)
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=handlers,
        force=True
    )
    logging.getLogger('playwright').setLevel(logging.WARNING)
    current_logger = logging.getLogger(__name__)
    current_logger.info(f"Standalone logger setup complete. Level: {logging.getLevelName(log_level)}. Target: {log_target}")
    print(f"DEBUG [utils]: Logging setup finished. Root handlers: {logging.getLogger().handlers}")

def load_input_from_json(filepath: str) -> Dict[str, Any]:
    """指定されたJSONファイルから入力データを読み込む。"""
    logger.info(f"入力ファイル '{filepath}' の読み込みを開始します...")
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        if "target_url" not in data or not data["target_url"]:
            raise ValueError("JSONファイルに必須キー 'target_url' が存在しないか、値が空です。")
        if "actions" not in data or not isinstance(data["actions"], list):
            raise ValueError("JSONファイルに必須キー 'actions' が存在しないか、リスト形式ではありません。")
        if not data["actions"]:
             logger.warning(f"入力ファイル '{filepath}' の 'actions' リストが空です。")
        logger.info(f"入力ファイル '{filepath}' を正常に読み込みました。")
        return data
    except FileNotFoundError:
        logger.error(f"入力ファイルが見つかりません: {filepath}")
        raise
    except json.JSONDecodeError as e:
        logger.error(f"JSON形式のエラーです ({filepath}): {e}")
        raise
    except ValueError as ve:
        logger.error(f"入力データの形式が不正です ({filepath}): {ve}")
        raise
    except Exception as e:
        logger.error(f"入力ファイルの読み込み中に予期せぬエラーが発生しました ({filepath}): {e}", exc_info=True)
        raise

def extract_text_from_pdf_sync(pdf_data: bytes) -> Optional[str]:
    """PDFのバイトデータからテキストを抽出する (同期的)。エラー時はエラーメッセージ文字列を返す。"""
    doc = None
    try:
        logger.info(f"PDFデータ (サイズ: {len(pdf_data)} bytes) からテキスト抽出を開始します...")
        doc = fitz.open(stream=pdf_data, filetype="pdf")
        text_parts = []
        logger.info(f"PDFページ数: {len(doc)}")
        for page_num in range(len(doc)):
            page_start_time = time.monotonic()
            try:
                page = doc.load_page(page_num)
                page_text = page.get_text("text", sort=True)
                if page_text:
                    text_parts.append(page_text.strip())
                page_elapsed = (time.monotonic() - page_start_time) * 1000
                logger.debug(f"ページ {page_num + 1} 処理完了 ({page_elapsed:.0f}ms)。")
            except Exception as page_e:
                logger.warning(f"ページ {page_num + 1} の処理中にエラー: {page_e}")
                text_parts.append(f"--- Error processing page {page_num + 1}: {page_e} ---")
        full_text = "\n--- Page Separator ---\n".join(text_parts)
        cleaned_text = '\n'.join([line.strip() for line in full_text.splitlines() if line.strip()])
        logger.info(f"PDFテキスト抽出完了。総文字数 (整形後): {len(cleaned_text)}")
        return cleaned_text if cleaned_text else "(No text extracted from PDF)"
    except fitz.fitz.TryingToReadFromEmptyFileError:
         logger.error("PDF処理エラー: ファイルデータが空または破損しています。")
         return "Error: PDF data is empty or corrupted."
    except fitz.fitz.FileDataError as e:
         logger.error(f"PDF処理エラー (PyMuPDF FileDataError): {e}", exc_info=False)
         return f"Error: PDF file data error - {e}"
    except RuntimeError as e:
        logger.error(f"PDF処理エラー (PyMuPDF RuntimeError): {e}", exc_info=True)
        return f"Error: PDF processing failed (PyMuPDF RuntimeError) - {e}"
    except Exception as e:
        logger.error(f"PDFテキスト抽出中に予期せぬエラーが発生しました: {e}", exc_info=True)
        return f"Error: Unexpected error during PDF text extraction - {e}"
    finally:
        if doc:
            try: doc.close(); logger.debug("PDFドキュメントを閉じました。")
            except Exception as close_e: logger.warning(f"PDFドキュメントのクローズ中にエラーが発生しました (無視): {close_e}")

async def download_pdf_async(api_request_context: APIRequestContext, url: str) -> Optional[bytes]:
    """指定されたURLからPDFを非同期でダウンロードし、バイトデータを返す。失敗時はNoneを返す。"""
    logger.info(f"PDFを非同期でダウンロード中: {url} (Timeout: {config.PDF_DOWNLOAD_TIMEOUT}ms)")
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
            'Accept': 'application/pdf,text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Accept-Language': 'ja-JP,ja;q=0.9,en-US;q=0.8,en;q=0.7'
        }
        response = await api_request_context.get(url, headers=headers, timeout=config.PDF_DOWNLOAD_TIMEOUT, fail_on_status_code=False)
        if not response.ok:
            logger.error(f"PDFダウンロード失敗 ({url}) - Status: {response.status} {response.status_text}")
            try:
                error_body = await response.text(timeout=5000)
                logger.debug(f"エラーレスポンスボディ (一部): {error_body[:500]}")
            except Exception as body_err: logger.warning(f"エラーレスポンスボディの読み取り中にエラーが発生しました: {body_err}")
            return None
        content_type = response.headers.get('content-type', '').lower()
        if 'application/pdf' not in content_type:
            logger.warning(f"レスポンスのContent-TypeがPDFではありません ({url}): '{content_type}'。ダウンロードは続行しますが、後続処理で失敗する可能性があります。")
        body = await response.body()
        if not body:
             logger.warning(f"PDFダウンロード成功 ({url}) Status: {response.status} ですが、レスポンスボディが空です。")
             return None
        logger.info(f"PDFダウンロード成功 ({url})。サイズ: {len(body)} bytes")
        return body
    except PlaywrightTimeoutError:
        logger.error(f"PDFダウンロード中にタイムアウトが発生しました ({url})。設定タイムアウト: {config.PDF_DOWNLOAD_TIMEOUT}ms")
        return None
    except Exception as e:
        logger.error(f"PDF非同期ダウンロード中に予期せぬエラーが発生しました ({url}): {e}", exc_info=True)
        return None

# --- ▼▼▼ write_results_to_file 修正 ▼▼▼ ---
def write_results_to_file(
    results: List[Dict[str, Any]],
    filepath: str,
    final_summary_data: Optional[Dict[str, Any]] = None # <<< 集約結果を受け取る引数を追加
):
    """
    実行結果を指定されたファイルに書き込む。
    オプションで最終的な集約結果も追記する。
    """
    logger.info(f"実行結果を '{filepath}' に書き込みます...")
    try:
        output_dir = os.path.dirname(filepath)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
            logger.info(f"出力ディレクトリ '{output_dir}' を作成しました。")

        with open(filepath, "w", encoding="utf-8") as file:
            file.write("--- Web Runner 実行結果 ---\n\n")
            # --- 各ステップ結果の書き込み (ここは変更なし) ---
            if not results:
                 file.write("(実行ステップ結果がありません)\n")
            for i, res in enumerate(results):
                 # ステップ結果が辞書でない場合のエラーハンドリングを追加
                if not isinstance(res, dict):
                    file.write(f"--- Step {i+1}: Invalid Format ---\n")
                    file.write(f"Received non-dict data: {res}\n\n")
                    continue

                step_num = res.get('step', i + 1)
                action_type = res.get('action', 'Unknown')
                status = res.get('status', 'Unknown')
                selector = res.get('selector')

                file.write(f"--- Step {step_num}: {action_type} ({status}) ---\n")
                if res.get('memo'): file.write(f"Memo: {res.get('memo')}\n") # メモも表示
                if selector: file.write(f"Selector: {selector}\n")
                if res.get('iframe_selector'): file.write(f"IFrame Selector (for switch): {res.get('iframe_selector')}\n")
                if res.get('required_state'): file.write(f"Required Element State: {res.get('required_state')}\n")

                if status == "error":
                     file.write(f"Message: {res.get('message')}\n")
                     if res.get('full_error') and res.get('full_error') != res.get('message'): file.write(f"Details: {res.get('full_error')}\n")
                     if res.get('error_screenshot'): file.write(f"Screenshot: {res.get('error_screenshot')}\n")
                     if res.get('traceback'): file.write(f"Traceback:\n{res.get('traceback')}\n")
                elif status == "success":
                    details_to_write = res.copy()
                    for key in ['step', 'status', 'action', 'selector', 'iframe_selector', 'required_state', 'memo']: details_to_write.pop(key, None)
                    # --- アクションタイプに応じた整形出力 (ここは変更なし) ---
                    if action_type == 'get_all_attributes':
                        attr_name = details_to_write.pop('attribute', 'N/A')
                        results_count = details_to_write.pop('results_count', 0)
                        url_list = details_to_write.pop('url_list', None)
                        pdf_texts = details_to_write.pop('pdf_texts', None)
                        scraped_texts = details_to_write.pop('scraped_texts', None)
                        email_list = details_to_write.pop('extracted_emails', None)
                        attr_list = details_to_write.pop('attribute_list', None)
                        file.write(f"Requested Attribute/Content: {attr_name}\n")
                        file.write(f"Results ({results_count} items processed):\n")
                        if results_count > 0:
                            if email_list is not None:
                                file.write("  Extracted Emails (Unique Domains for this step):\n")
                                if email_list: file.write('\n'.join(f"  - {email}" for email in email_list) + "\n")
                                else: file.write("    (No unique domain emails found for this step)\n")
                            if url_list is not None and attr_name.lower() != 'mail':
                                file.write(f"  Processed URLs ({len(url_list)}):\n")
                                for idx, url in enumerate(url_list): file.write(f"    [{idx+1}] {url if url else '(URL not processed or invalid)'}\n")
                            if pdf_texts is not None:
                                file.write("  Extracted PDF Texts:\n")
                                for idx, pdf_content in enumerate(pdf_texts):
                                    if pdf_content is not None:
                                        file.write(f"    [{idx+1}]")
                                        if isinstance(pdf_content, str) and pdf_content.startswith("Error:"): file.write(f" (Error): {pdf_content}\n")
                                        elif pdf_content == "(No text extracted from PDF)": file.write(": (No text extracted)\n")
                                        else:
                                            file.write(f" (Length: {len(pdf_content or '')}):\n")
                                            indented_content = "\n".join(["      " + line for line in str(pdf_content).splitlines()])
                                            file.write(indented_content + "\n")
                            if scraped_texts is not None:
                                file.write("  Scraped Page Texts:\n")
                                for idx, scraped_content in enumerate(scraped_texts):
                                    if scraped_content is not None:
                                        file.write(f"    [{idx+1}]")
                                        if isinstance(scraped_content, str) and scraped_content.startswith("Error"): file.write(f" (Error): {scraped_content}\n")
                                        else:
                                            file.write(f" (Length: {len(scraped_content or '')}):\n")
                                            indented_content = "\n".join(["      " + line for line in str(scraped_content).splitlines()])
                                            file.write(indented_content + "\n")
                            if attr_list is not None:
                                file.write(f"  Attribute '{attr_name}' Values:\n")
                                for idx, attr_content in enumerate(attr_list): file.write(f"    [{idx+1}] {attr_content}\n")
                        else: file.write("  (No items found matching the selector for this step)\n")
                    elif action_type == 'get_all_text_contents':
                        text_list_result = details_to_write.pop('text_list', [])
                        results_count = details_to_write.pop('results_count', len(text_list_result) if isinstance(text_list_result, list) else 0)
                        file.write(f"Result Text List ({results_count} items):\n")
                        if isinstance(text_list_result, list):
                            valid_texts = [str(text) for text in text_list_result if text is not None]
                            if valid_texts: file.write('\n'.join(f"- {text}" for text in valid_texts) + "\n")
                            else: file.write("(No text content found)\n")
                        else: file.write("(Invalid format received)\n")
                    elif action_type in ['get_text_content', 'get_inner_text'] and 'text' in details_to_write: file.write(f"Result Text:\n{details_to_write.pop('text', '')}\n")
                    elif action_type == 'get_inner_html' and 'html' in details_to_write: file.write(f"Result HTML:\n{details_to_write.pop('html', '')}\n")
                    elif action_type == 'get_attribute':
                        attr_name = details_to_write.pop('attribute', ''); attr_value = details_to_write.pop('value', None)
                        file.write(f"Result Attribute ('{attr_name}'): {attr_value}\n")
                        if 'pdf_text' in details_to_write:
                            pdf_text = details_to_write.pop('pdf_text', '')
                            prefix = "Extracted PDF Text"
                            if isinstance(pdf_text, str) and pdf_text.startswith("Error:"): file.write(f"{prefix} (Error): {pdf_text}\n")
                            elif pdf_text == "(No text extracted from PDF)": file.write(f"{prefix}: (No text extracted)\n")
                            else: file.write(f"{prefix}:\n{pdf_text}\n")
                    elif action_type == 'screenshot' and 'filename' in details_to_write: file.write(f"Screenshot saved to: {details_to_write.pop('filename')}\n")
                    elif action_type == 'click' and 'new_page_opened' in details_to_write:
                        if details_to_write.get('new_page_opened'): file.write(f"New page opened: {details_to_write.get('new_page_url')}\n")
                        else: file.write("New page did not open within timeout.\n")
                        details_to_write.pop('new_page_opened', None); details_to_write.pop('new_page_url', None)
                    if details_to_write:
                        file.write("Other Details:\n")
                        for key, val in details_to_write.items(): file.write(f"  {key}: {val}\n")
                elif status == "skipped" or status == "warning": file.write(f"Message: {res.get('message', 'No message provided.')}\n")
                else: file.write(f"Raw Data: {res}\n") # 不明な場合は生データを書き出す
                file.write("\n")

            # --- ▼▼▼ 最終集約結果の追記処理 ▼▼▼ ---
            if final_summary_data:
                file.write("--- Final Aggregated Summary ---\n\n")
                for summary_key, summary_value in final_summary_data.items():
                    file.write(f"{summary_key}:\n")
                    if isinstance(summary_value, list):
                        # リスト（配列）形式で出力
                        # JSON形式でインデント付きで書き込む
                        try:
                             json_output = json.dumps(summary_value, indent=2, ensure_ascii=False)
                             file.write(json_output + "\n")
                        except TypeError:
                             # JSONシリアライズできない場合は repr で出力
                             file.write(repr(summary_value) + "\n")
                    else:
                        # リスト以外はそのまま出力
                        file.write(f"{summary_value}\n")
                file.write("\n")
            # --- ▲▲▲ 最終集約結果の追記処理 ▲▲▲ ---

        logger.info(f"結果の書き込みが完了しました: '{filepath}'")
    except IOError as e:
        logger.error(f"結果ファイル '{filepath}' の書き込み中にIOエラーが発生しました: {e}")
    except Exception as e:
        logger.error(f"結果の処理またはファイル書き込み中に予期せぬエラーが発生しました: {e}", exc_info=True)

# --- utils.py のテスト用コード (変更なし) ---
# (コードは省略)
if __name__ == "__main__":
    print("--- Testing logging setup from utils.py ---")
    TEST_LOG_FILE = config.MCP_SERVER_LOG_FILE
    print(f"Test log file path: {TEST_LOG_FILE}")
    if os.path.exists(TEST_LOG_FILE):
        try: os.remove(TEST_LOG_FILE); print(f"Removed existing test log file: {TEST_LOG_FILE}")
        except Exception as e: print(f"Could not remove existing test log file: {e}")
    try:
        setup_logging_for_standalone(log_file_path=TEST_LOG_FILE)
        test_logger = logging.getLogger("utils_test")
        print("\nAttempting to log messages...")
        test_logger.info("INFO message from utils_test.")
        test_logger.warning("WARNING message from utils_test.")
        test_logger.error("ERROR message from utils_test.")
        print(f"\nLogging test complete.")
        print(f"Please check the console output above and the content of the file: {os.path.abspath(TEST_LOG_FILE)}")
        print(f"Root logger handlers: {logging.getLogger().handlers}")
    except Exception as e: print(f"\n--- Error during logging test ---"); print(f"{type(e).__name__}: {e}"); traceback.print_exc()


---


- フォルダ名: .
- ファイル名: web_runner_google_email_crawler.py
- 内容:
# --- ファイル: generate_and_run_google_crawl.py (結果処理 再々修正版) ---
import asyncio
import json
import sys
import os
import time
import argparse
import traceback
from pathlib import Path
from typing import List, Set, Dict, Any, Optional, Tuple, Union
import re # <<< 正規表現モジュールをインポート

# --- インポート (変更なし) ---
try: from web_runner_mcp_client_core import execute_web_runner_via_mcp
except ImportError: print("Error: web_runner_mcp_client_core.py not found..."); sys.exit(1)
try:
    import config
    import utils
    DEFAULT_OUTPUT_FILE = Path(config.MCP_CLIENT_OUTPUT_FILE)
    DEFAULT_OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
except ImportError: print("Warning: config/utils not found..."); utils = None; DEFAULT_OUTPUT_FILE = None

# --- 定数 (次へセレクターを実績値に戻す) ---
GOOGLE_SEARCH_URL = "https://www.google.com/"
SEARCH_BOX_SELECTOR = "#APjFqb"
SEARCH_BUTTON_SELECTOR = "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b"
EMAIL_EXTRACT_SELECTOR = "#rso div.kb0PBd.A9Y9g.jGGQ5e span a"
# 「次へ」セレクターを実績値に戻す
NEXT_PAGE_SELECTOR = "#pnnext > span.oeN89d"
# NEXT_PAGE_SELECTOR = "#pnnext" # こちらの方が安定する場合もある

DEFAULT_WAIT_MS = 5000
EMAIL_EXTRACT_WAIT_MS = 7000
DEFAULT_SLEEP_SEC = 2

# --- JSON生成ヘルパー関数 (次へセレクター変更) ---
def generate_google_crawl_json(search_term: str, max_pages: int) -> Dict[str, Any]:
    actions: List[Dict[str, Any]] = []
    actions.append({"memo": "検索ボックスに入力", "action": "input", "selector": SEARCH_BOX_SELECTOR, "value": search_term})
    actions.append({"memo": "検索ボタンをクリック", "action": "click", "selector": SEARCH_BUTTON_SELECTOR, "wait_time_ms": DEFAULT_WAIT_MS})
    actions.append({"memo": f"検索結果表示待機 ({DEFAULT_SLEEP_SEC}秒)", "action": "sleep", "value": DEFAULT_SLEEP_SEC})
    for page_num in range(1, max_pages + 1):
        actions.append({"memo": f"ページ {page_num} メール抽出", "action": "get_all_attributes", "selector": EMAIL_EXTRACT_SELECTOR, "attribute_name": "mail", "wait_time_ms": EMAIL_EXTRACT_WAIT_MS})
        if page_num < max_pages:
            actions.append({
                "memo": f"ページ {page_num + 1} へ移動",
                "action": "click",
                "selector": NEXT_PAGE_SELECTOR, # <<< 実績値に戻したセレクター
                "wait_time_ms": DEFAULT_WAIT_MS
            })
            actions.append({"memo": f"ページ遷移待機 ({DEFAULT_SLEEP_SEC}秒)", "action": "sleep", "value": DEFAULT_SLEEP_SEC})
    return {"target_url": GOOGLE_SEARCH_URL, "actions": actions}

# --- 結果処理ヘルパー関数 (エラー時のJSON抽出を修正) ---
def process_results(
    success: bool,
    result_data_or_error: Union[str, Dict[str, Any]]
) -> Tuple[List[str], List[Dict[str, Any]]]:
    """
    Web-Runnerからの結果またはエラー情報を処理し、
    ユニークドメインメールアドレスリストと全ステップ結果リストを返す。
    エラー発生時でも、それまでに成功したメール抽出結果は集約する。
    """
    all_steps_results: List[Dict[str, Any]] = []
    collected_emails: List[str] = []
    processed_domains: Set[str] = set()

    # --- 結果/エラーデータの解析 ---
    if success and isinstance(result_data_or_error, str):
        try:
            all_steps_results = json.loads(result_data_or_error)
            if not isinstance(all_steps_results, list):
                print("[エラー] Web-Runnerからの成功結果がリスト形式ではありません。")
                all_steps_results = [{"raw_success_result": result_data_or_error}]
        except json.JSONDecodeError:
            print("[エラー] Web-Runnerからの成功結果JSONの解析に失敗しました。")
            all_steps_results = [{"raw_success_result": result_data_or_error}]

    elif not success and isinstance(result_data_or_error, dict):
        print("[情報] Web-Runner実行中にエラーが発生しました。エラー詳細を解析します。")
        raw_details_str = result_data_or_error.get("raw_details")

        # --- ▼▼▼ エラー詳細からのJSON抽出ロジック (正規表現使用) ▼▼▼ ---
        if isinstance(raw_details_str, str):
            # "raw_error" の値を取得し、そこからJSONリストを抽出する試み
            raw_error_val = result_data_or_error.get("raw_error")
            if isinstance(raw_error_val, str):
                # "Details in JSON content: " の後の最初の '[' から最後の ']' までを抽出
                # (?s) は '.' が改行にもマッチするようにするフラグ
                match = re.search(r"Details in JSON content:\s*(\[(?s:.*)\])", raw_error_val)
                if match:
                    potential_json_str = match.group(1) # 括弧の中身を取得
                    print(f"  -> Extracted potential JSON from error (length {len(potential_json_str)}): {potential_json_str[:100]}...")
                    try:
                        # ここで抽出した文字列を直接パース
                        parsed_data = json.loads(potential_json_str)
                        if isinstance(parsed_data, list):
                            all_steps_results = parsed_data
                            print("  -> エラー詳細からステップ結果リストを抽出・解析しました。")
                        else:
                            print("  [警告] エラー詳細から抽出したJSONがリスト形式ではありません。")
                            all_steps_results = [{"parsed_error_detail": parsed_data}]
                    except json.JSONDecodeError as e:
                        print(f"  [警告] 抽出したJSON部分の解析に失敗しました。エラー: {e}")
                        # エラーが発生したJSON文字列をデバッグ用に記録
                        all_steps_results = [{"error_parsing_json_from_error": potential_json_str}]
                    except Exception as e:
                         print(f"  [警告] エラー詳細内のJSON処理中に予期せぬエラー: {e}")
                         all_steps_results = [result_data_or_error] # 元のエラー辞書
                else:
                    print("  [警告] エラー詳細内で 'Details in JSON content: [...]' パターンが見つかりません。")
                    all_steps_results = [result_data_or_error] # 元のエラー辞書
            else:
                print("  [警告] エラー詳細に 'raw_error' キーがないか、値が文字列ではありません。")
                all_steps_results = [result_data_or_error]
        else:
             # raw_details がないか文字列でない場合
             all_steps_results = [result_data_or_error] # 元のエラー辞書をそのままリストに
        # --- ▲▲▲ エラー詳細からのJSON抽出ロジック (正規表現使用) ▲▲▲ ---

    elif isinstance(result_data_or_error, str): # success=False で文字列の場合
        print("[エラー] Web-Runnerからエラー文字列を受け取りました。")
        all_steps_results = [{"error_string": result_data_or_error}]
    else: # その他の予期しない形式
        print("[エラー] 不明な結果/エラー形式を受け取りました。")
        all_steps_results = [{"unknown_result": str(result_data_or_error)}]

    # --- ステップ結果の処理とメール集約 (変更なし) ---
    print("\n--- 各ステップの結果サマリ (エラー発生時も含む) ---")
    if not all_steps_results:
        print("(有効なステップ結果がありません)")
        return [], []

    for step_result in all_steps_results:
        if not isinstance(step_result, dict): print(f"  [警告] 無効なステップデータ形式をスキップ: {type(step_result)}"); continue
        step_num = step_result.get("step", "?"); action = step_result.get("action", "N/A"); status = step_result.get("status", "N/A"); memo = step_result.get("memo", "")
        print(f"Step {step_num}: {action} ({status}) {f'- {memo}' if memo else ''}")
        if (action == "get_all_attributes" and step_result.get("attribute") == "mail" and status == "success"):
            page_emails = step_result.get("extracted_emails", [])
            if page_emails:
                print(f"  -> 抽出されたメールアドレス候補 (ドメインユニーク): {len(page_emails)} 件")
                added_count = 0
                for email in page_emails:
                    if isinstance(email, str) and '@' in email:
                        try:
                            domain = email.split('@', 1)[1].lower()
                            if domain and domain not in processed_domains: 
                                collected_emails.append(email)
                                processed_domains.add(domain)
                                added_count += 1
                        except IndexError: pass
                if added_count > 0: print(f"     -> うち {added_count} 件を最終リストに追加。")
            else: print("  -> このステップではメールアドレスは見つかりませんでした。")
        elif status == "error":
             message = step_result.get('message', 'No message'); selector = step_result.get('selector', 'N/A')
             print(f"  [エラー] Selector: {selector} - Message: {message}")
             if step_result.get('traceback'): print(f"  [エラー] 詳細なエラー情報はログファイルを確認してください。")

    return collected_emails, all_steps_results

# --- メイン実行関数 (変更なし) ---
async def main():
    # ... (ArgumentParser部分は変更なし) ...
    parser = argparse.ArgumentParser(description="Generate JSON and run Google Search Email Crawler via Web-Runner MCP")
    parser.add_argument("search_term", type=str, help="Google検索キーワード")
    parser.add_argument("--max_pages", type=int, default=3, help="クロール最大ページ数 (デフォルト: 3)")
    parser.add_argument('--headless', action=argparse.BooleanOptionalAction, default=False, help="ヘッドレス実行")
    parser.add_argument("--slowmo", type=int, default=0, help="SlowMo遅延 (ms, デフォルト: 0)")
    parser.add_argument("--output_json", type=Path, default=None, help="生成した実行用JSONを保存するパス (オプション)")
    parser.add_argument("--output_result", type=Path, default=DEFAULT_OUTPUT_FILE, help=f"Web-Runnerの実行結果を保存するパス (デフォルト: {DEFAULT_OUTPUT_FILE})")
    args = parser.parse_args()
    # --- 1. JSON生成 (変更なし) ---
    print("--- 1. 実行用JSONを生成中 ---")
    web_runner_input_json = generate_google_crawl_json(args.search_term, args.max_pages)
    print(f"生成されたアクション数: {len(web_runner_input_json['actions'])}")
    if args.output_json:
        try:
            args.output_json.parent.mkdir(parents=True, exist_ok=True)
            with open(args.output_json, 'w', encoding='utf-8') as f: json.dump(web_runner_input_json, f, indent=2, ensure_ascii=False)
            print(f"実行用JSONを保存しました: {args.output_json}")
        except Exception as e: print(f"[警告] 実行用JSONの保存に失敗しました: {e}")
    # --- 2. Web-Runner実行 (変更なし) ---
    print("\n--- 2. Web-Runner をMCP経由で実行中 ---")
    start_time = time.monotonic()
    success, result_or_error = await execute_web_runner_via_mcp(web_runner_input_json, headless=args.headless, slow_mo=args.slowmo)
    end_time = time.monotonic(); print(f"Web-Runner実行時間: {end_time - start_time:.2f} 秒")
    # --- 3. 結果処理 & 出力 (変更なし) ---
    print("\n--- 3. 実行結果を処理中 ---")
    final_unique_emails, all_steps_results_list = process_results(success, result_or_error)
    print("\n" + "=" * 30)
    print(f"--- 最終結果: ユニークドメインメールアドレス ({len(final_unique_emails)} 件) [配列形式] ---")
    print(json.dumps(sorted(final_unique_emails), indent=2, ensure_ascii=False))
    print("=" * 30)
    if args.output_result and utils:
        print(f"\nWeb-Runnerの全ステップ結果と最終メールリストをファイルに書き込みます: {args.output_result}")
        try:
            output_path = Path(args.output_result); output_path.parent.mkdir(parents=True, exist_ok=True)
            final_summary = {"Final Unique Domain Emails": sorted(final_unique_emails)}
            #with open("output_mail.txt", "a", encoding="utf-8") as f:
            #    f.write('\n'.join(final_unique_emails) + '\n')  # 各要素を改行で結合して書き込む
            utils.write_results_to_file(all_steps_results_list, str(output_path), final_summary_data=final_summary)
            print("結果ファイルの書き込みが完了しました。")
        except Exception as e: print(f"[エラー] 結果ファイルの書き込みに失敗しました: {e}"); traceback.print_exc()
    elif args.output_result and not utils: print(f"[警告] utilsモジュールが見つからないため、結果ファイル '{args.output_result}' への書き込みをスキップします。")

if __name__ == "__main__":
    # ... (実行部分は変更なし) ...
    if sys.platform == "win32": pass
    try: asyncio.run(main())
    except KeyboardInterrupt: print("\n処理が中断されました。")
    except Exception as e: print(f"\n予期せぬエラーが発生しました: {e}"); traceback.print_exc()


---


- フォルダ名: .
- ファイル名: web_runner_mcp_client_core.py
- 内容:
# --- ファイル: web_runner_mcp_client_core.py (stdioエンコーディング修正) ---
import asyncio
import sys,os
import json
from pathlib import Path
import anyio
import platform
import traceback
from typing import Optional, Dict, Any, Tuple, Union, List
import argparse
import io # ★★★ io モジュールをインポート ★★★

# MCP クライアントライブラリ
from mcp import ClientSession, StdioServerParameters, types as mcp_types
from mcp.client.stdio import stdio_client

try:
    import config
    import utils
    DEFAULT_OUTPUT_FILE = Path(config.MCP_CLIENT_OUTPUT_FILE)
except ImportError:
    print("Warning: config.py or utils.py not found. Using default output filename './output/web_runner_mcp.txt'")
    DEFAULT_OUTPUT_FILE = Path("./output/web_runner_mcp.txt")
    utils = None

SERVER_SCRIPT = Path("./web_runner_mcp_server.py")
DEFAULT_SLOW_MO = 0

async def execute_web_runner_via_mcp(
    input_json_data: Dict[str, Any],
    headless: bool = False,
    slow_mo: int = DEFAULT_SLOW_MO
) -> Tuple[bool, Union[str, Dict[str, Any]]]:
    """
    指定されたJSONデータをWeb-Runner MCPサーバーに送信し、実行結果を取得する。
    """
    print("--- Executing Web Runner via MCP ---")
    print(f"Input data (type: {type(input_json_data)}): {str(input_json_data)[:200]}...")
    print(f"Headless: {headless}, SlowMo: {slow_mo}")

    if not SERVER_SCRIPT.exists():
        error_msg = f"Error: Server script not found at {SERVER_SCRIPT}"
        print(error_msg)
        return False, {"error": error_msg}

    tool_arguments = {
        "input_args": {
            "target_url": input_json_data.get("target_url"),
            "actions": input_json_data.get("actions", []),
            "headless": headless,
            "slow_mo": slow_mo,
            "default_timeout_ms": input_json_data.get("default_timeout_ms")
        }
    }
    if not tool_arguments["input_args"]["target_url"] or not tool_arguments["input_args"]["actions"]:
         error_msg = "Error: 'target_url' or 'actions' missing in input_json_data."
         print(error_msg)
         return False, {"error": error_msg}

    print("Preparing server parameters...")
    # --- ▼▼▼ 修正箇所 ▼▼▼ ---
    # 環境変数でPythonの標準入出力エンコーディングをUTF-8に強制する
    server_env = os.environ.copy()
    server_env["PYTHONIOENCODING"] = "utf-8"

    server_params = StdioServerParameters(
        command=sys.executable,
        args=[str(SERVER_SCRIPT), "--transport", "stdio", "--log-level", "INFO"],
        env=server_env # ★★★ 環境変数を渡す ★★★
    )
    # --- ▲▲▲ 修正箇所 ▲▲▲ ---
    print(f"Server command: {sys.executable} {SERVER_SCRIPT} --transport stdio --log-level INFO")
    print(f"Server env: PYTHONIOENCODING=utf-8") # デバッグ用

    session: Optional[ClientSession] = None
    try:
        print("Connecting to server via stdio_client...")
        async with stdio_client(server_params) as streams:
            # ...(以下、変更なし)...
            print("DEBUG: stdio_client context entered.")
            read_stream, write_stream = streams
            print("DEBUG: Got streams from stdio_client.")
            print("Creating ClientSession...")
            async with ClientSession(read_stream, write_stream) as session:
                print("DEBUG: ClientSession context entered.")
                print("Initializing session...")
                await session.initialize() # ← ここで止まっていた
                print("DEBUG: Initialization complete.") # ← ここまで進むはず

                print("Calling 'execute_web_runner' tool...")
                print(f"DEBUG: Calling tool with arguments: {str(tool_arguments)[:500]}...")

                tool_result: mcp_types.CallToolResult = await session.call_tool(
                    name="execute_web_runner",
                    arguments=tool_arguments
                )
                print("DEBUG: Tool call finished.")

                if tool_result.isError:
                    print("--- Tool Execution Error ---")
                    error_content = "Unknown error format received from server."
                    if tool_result.content and isinstance(tool_result.content[0], mcp_types.TextContent):
                        error_content = tool_result.content[0].text
                        print(f"Received error details:\n{error_content}")
                        try:
                           error_data = json.loads(error_content)
                           if "JSON: " in error_content:
                               json_part = error_content.split("JSON: ", 1)[1]
                               try: error_data = json.loads(json_part)
                               except json.JSONDecodeError: pass
                           return False, {"error": "MCP tool execution failed", "details": error_data}
                        except json.JSONDecodeError:
                           return False, {"error": "MCP tool execution failed", "raw_details": error_content}
                    else:
                        print(error_content)
                        return False, {"error": error_content}
                else:
                    print("--- Tool Execution Success ---")
                    if tool_result.content and isinstance(tool_result.content[0], mcp_types.TextContent):
                        result_json_string = tool_result.content[0].text
                        return True, result_json_string
                    else:
                        print("No content received from server.")
                        return False, {"error": "No content received from server"}

    except Exception as e:
        print(f"--- An Exception Occurred During MCP Communication ---")
        error_msg = f"{type(e).__name__}: {e}"
        print(error_msg)
        print("--- Traceback ---")
        traceback.print_exc()
        # UnicodeDecodeError の場合は、より具体的なエラーメッセージを返す
        if isinstance(e, UnicodeDecodeError):
             return False, {"error": f"MCP communication error: Failed to decode server output as UTF-8. Check server-side prints/logs.", "details": error_msg}
        # ExceptionGroup の場合も詳細を含める
        if isinstance(e, ExceptionGroup):
             # ExceptionGroup の中身を展開して表示する方が親切かもしれない
             # simplified_error = {"error": "MCP communication error: ExceptionGroup occurred.", "details": str(e)}
             # return False, simplified_error
             # ここでは元のエラーメッセージをそのまま返す
             return False, {"error": f"MCP communication error: {error_msg}"}

        return False, {"error": f"MCP communication error: {error_msg}"}
    finally:
        print("--- Web Runner via MCP Finished ---")

# --- main 関数 (変更なし) ---
async def main():
    """テスト用のJSONファイルを読み込んでコア関数を呼び出し、結果をファイルに出力"""
    parser = argparse.ArgumentParser(description="Test Web-Runner MCP Client Core")
    parser.add_argument(
        "--jsonfile",
        type=Path,
        default=Path("./json/tdnet.json"), # デフォルトをtdnet.jsonにしてみる
        help="Path to the input JSON file for testing."
    )
    parser.add_argument(
        '--headless',
        action=argparse.BooleanOptionalAction,
        default=False, # デフォルトはブラウザ表示
        help="Run browser in headless mode."
    )
    parser.add_argument(
        "--slowmo",
        type=int,
        default=DEFAULT_SLOW_MO,
        help=f"Slow motion delay in milliseconds (default: {DEFAULT_SLOW_MO})."
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=DEFAULT_OUTPUT_FILE,
        help=f"Path to the output file (default: {DEFAULT_OUTPUT_FILE})."
    )
    args = parser.parse_args()
    test_json_file_path: Path = args.jsonfile
    output_file_path: Path = args.output
    slow_mo_value: int = args.slowmo

    print(f"Loading input JSON from: {test_json_file_path}")
    if not test_json_file_path.exists():
        print(f"Error: Test JSON file not found at {test_json_file_path}")
        return

    try:
        with open(test_json_file_path, 'r', encoding='utf-8') as f:
            test_input = json.load(f)
        print("Input JSON loaded successfully.")
    except Exception as e:
        print(f"Error loading JSON file: {e}")
        return

    success, result_or_error = await execute_web_runner_via_mcp(
        test_input,
        headless=args.headless,
        slow_mo=slow_mo_value
    )

    # ファイル書き込み処理
    print(f"\nWriting result to: {output_file_path}")
    if success and isinstance(result_or_error, str):
        try:
            result_data_list = json.loads(result_or_error)
            if isinstance(result_data_list, list) and utils: # ★★★ utils がインポートできているか確認 ★★★
                 utils.write_results_to_file(result_data_list, str(output_file_path))
            elif not utils:
                 print("Error: Cannot write results because 'utils' module failed to import.")
                 with open(output_file_path, 'w', encoding='utf-8') as f:
                     f.write("--- Execution Succeeded but Result Writing Failed (utils missing) ---\n")
                     f.write(result_or_error)
            else:
                 print("Error: Result JSON from server is not a list.")
                 with open(output_file_path, 'w', encoding='utf-8') as f:
                      f.write("--- Execution Failed ---\nReceived invalid result format (not a list):\n")
                      f.write(result_or_error)
        except json.JSONDecodeError:
            error_msg = f"Error: Received non-JSON success result:\n{result_or_error}"
            print(error_msg)
            with open(output_file_path, 'w', encoding='utf-8') as f:
                 f.write(error_msg)
        except Exception as write_e:
             print(f"Error writing result to file {output_file_path}: {write_e}")
             traceback.print_exc()
    else: # success is False
        print("\n--- Final Result (Error) ---")
        formatted_error = json.dumps(result_or_error, indent=2, ensure_ascii=False)
        print(formatted_error)
        with open(output_file_path, 'w', encoding='utf-8') as f:
            f.write(f"--- Execution Failed ---\n{formatted_error}")


if __name__ == "__main__":
    if platform.system() == "Windows":
        pass

    try:
        anyio.run(main)
    except Exception as e:
        print(f"Error running anyio task: {e}")
        traceback.print_exc()


---


- フォルダ名: .
- ファイル名: web_runner_mcp_client_GUI.py
- 内容:
# --- ファイル: web_runner_mcp_client_GUI.py (コピーボタン追加版) ---

import sys
import os
import json
import asyncio
import platform
import traceback
from pathlib import Path
from typing import Optional, Tuple, List, Dict, Any, Union

# --- GUIライブラリ ---
from PySide6.QtWidgets import (
    QApplication, QMainWindow, QVBoxLayout, QHBoxLayout, QWidget,
    QComboBox, QPushButton, QPlainTextEdit, QLabel, QDialog, QMessageBox,
    QCheckBox, QSpinBox
)
from PySide6.QtCore import (
    Qt, QThread, Signal, Slot, QUrl, QObject
)
# --- ▼▼▼ QClipboard をインポート ▼▼▼ ---
from PySide6.QtGui import QClipboard
# --- ▲▲▲ QClipboard をインポート ▲▲▲ ---
from PySide6.QtWebEngineWidgets import QWebEngineView
from PySide6.QtWebChannel import QWebChannel

# --- 実績のあるコア関数をインポート ---
try:
    from web_runner_mcp_client_core import execute_web_runner_via_mcp
except ImportError:
    print("Error: web_runner_mcp_client_core.py not found or cannot be imported.")
    print("Please ensure web_runner_mcp_client_core.py is in the same directory.")
    sys.exit(1)

# --- utils, config のインポート ---
try:
    import config
    import utils
    # --- ▼▼▼ configからファイルパスを取得 ▼▼▼ ---
    DEFAULT_OUTPUT_FILE = Path(config.MCP_CLIENT_OUTPUT_FILE)
    # --- ▲▲▲ configからファイルパスを取得 ▲▲▲ ---
except ImportError:
    print("Warning: config.py or utils.py not found. Using default output filename './output/web_runner_mcp.txt'")
    DEFAULT_OUTPUT_FILE = Path("./output/web_runner_mcp.txt")
    utils = None

# --- 定数 ---
JSON_FOLDER = Path("./json")
GENERATOR_HTML = Path("./json_generator.html")

# --- MCP通信を行うワーカースレッド (変更なし) ---
class McpWorker(QThread):
    result_ready = Signal(str)
    error_occurred = Signal(object)
    status_update = Signal(str)

    def __init__(self, json_input: Dict[str, Any], headless: bool, slow_mo: int):
        super().__init__()
        self.json_input = json_input
        self.headless = headless
        self.slow_mo = slow_mo
        self._is_running = True

    def run(self):
        print("DEBUG: McpWorker.run started")
        self.status_update.emit("MCPタスク実行中...")
        success = False
        result_or_error: Union[str, Dict[str, Any]] = {"error": "Worker execution failed unexpectedly."}
        try:
            import anyio
            success, result_or_error = anyio.run(
                execute_web_runner_via_mcp,
                self.json_input,
                self.headless,
                self.slow_mo
            )
            print(f"DEBUG: execute_web_runner_via_mcp finished. Success: {success}")

            if success and isinstance(result_or_error, str):
                self.result_ready.emit(result_or_error)
            elif not success and isinstance(result_or_error, dict):
                self.error_occurred.emit(result_or_error)
            elif not success and isinstance(result_or_error, str):
                 self.error_occurred.emit({"error": "Received string error", "raw_details": result_or_error})
            else:
                 self.error_occurred.emit({"error": "Unexpected result format from core function", "result": str(result_or_error)})
        except Exception as e:
            err_msg = f"MCPワーカー実行エラー: {type(e).__name__}: {e}\n{traceback.format_exc()}"
            print(f"ERROR in McpWorker.run: {err_msg}")
            self.error_occurred.emit({"error": "Exception in McpWorker", "details": err_msg})
        finally:
            self._is_running = False
            print("DEBUG: McpWorker.run finished")

    def stop_worker(self):
        print("DEBUG: Requesting McpWorker to stop (flag set).")
        self._is_running = False


# --- GeneratorDialog クラス (変更なし) ---
class GeneratorDialog(QDialog):
    json_generated = Signal(str)
    class Bridge(QObject):
        receiveJsonSignal = Signal(str)
        @Slot(str)
        def receiveJsonFromHtml(self, jsonString):
            self.receiveJsonSignal.emit(jsonString)
    def __init__(self, html_path: Path, parent=None):
        super().__init__(parent)
        self.setWindowTitle("JSON Generator")
        self.setGeometry(200, 200, 900, 700)
        layout = QVBoxLayout(self)
        self.webview = QWebEngineView()
        layout.addWidget(self.webview)
        self.bridge = self.Bridge(self)
        self.channel = QWebChannel(self.webview.page())
        self.webview.page().setWebChannel(self.channel)
        self.channel.registerObject("pyBridge", self.bridge)
        if html_path.exists():
            file_url = QUrl.fromLocalFile(str(html_path.resolve()))
            script = """
                 <script src="qrc:///qtwebchannel/qwebchannel.js"></script>
                 <script>
                     document.addEventListener('DOMContentLoaded', function() {
                         if (typeof QWebChannel === 'undefined') { console.error('qwebchannel.js did not load'); return; }
                         new QWebChannel(qt.webChannelTransport, function(channel) {
                             window.pyBridge = channel.objects.pyBridge;
                             console.log('Python Bridge (pyBridge) initialized.');
                             const originalGenerateJsonData = window.generateJsonData;
                             window.generateJsonData = function() {
                                 originalGenerateJsonData();
                                 setTimeout(() => {
                                     const jsonElement = document.getElementById('generated-json');
                                     const jsonString = jsonElement ? jsonElement.textContent : null;
                                     if (jsonString && !jsonString.startsWith('JSON') && !jsonString.startsWith('入力エラー')) {
                                         if (window.pyBridge && window.pyBridge.receiveJsonFromHtml) {
                                             window.pyBridge.receiveJsonFromHtml(jsonString);
                                         } else { console.error('Python bridge not available.'); }
                                     } else { console.log('No valid JSON to send.'); }
                                 }, 100);
                             };
                         });
                     });
                 </script>
             """
            self.webview.page().loadFinished.connect(lambda ok: self.webview.page().runJavaScript(script) if ok else None)
            self.webview.setUrl(file_url)
        else:
            error_label = QLabel(f"Error: HTML file not found at\n{html_path}")
            layout.addWidget(error_label)
        self.bridge.receiveJsonSignal.connect(self.on_json_received_from_html)

    @Slot(str)
    def on_json_received_from_html(self, json_string):
        self.json_generated.emit(json_string)
        self.accept()

    def closeEvent(self, event):
        page = self.webview.page()
        if page:
            if hasattr(self, 'channel') and self.channel:
                 self.channel.deregisterObject("pyBridge")
            self.webview.setPage(None)
        super().closeEvent(event)


# --- メインウィンドウ ---
class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Web-Runner MCP Client (Core Utilized)")
        # ウィンドウサイズを少し広げる場合
        self.setGeometry(100, 100, 850, 650)

        self.mcp_worker: Optional[McpWorker] = None
        self.generator_dialog: Optional[GeneratorDialog] = None

        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)

        # --- 上部のファイル選択・実行ボタンなど ---
        top_layout = QHBoxLayout()
        self.json_selector = QComboBox()
        self.refresh_button = QPushButton("🔄 更新")
        self.generator_button = QPushButton("JSONジェネレーター")
        self.run_button = QPushButton("実行 ▶")
        top_layout.addWidget(QLabel("実行するJSON:"))
        top_layout.addWidget(self.json_selector, 1)
        top_layout.addWidget(self.refresh_button)
        top_layout.addWidget(self.generator_button)
        top_layout.addWidget(self.run_button)
        main_layout.addLayout(top_layout)

        # --- オプション設定のレイアウト ---
        options_layout = QHBoxLayout()
        self.headless_checkbox = QCheckBox("ヘッドレスモードで実行")
        self.headless_checkbox.setChecked(False)
        self.headless_checkbox.setToolTip("チェックするとブラウザ画面を表示せずにバックグラウンドで実行します。")
        options_layout.addWidget(self.headless_checkbox)

        options_layout.addWidget(QLabel("SlowMo (ms):"))
        self.slowmo_spinbox = QSpinBox()
        self.slowmo_spinbox.setRange(0, 30000)
        self.slowmo_spinbox.setValue(0)
        self.slowmo_spinbox.setSingleStep(100)
        self.slowmo_spinbox.setToolTip("各Playwright操作間の遅延時間(ミリ秒)。デバッグ時に便利です。")
        options_layout.addWidget(self.slowmo_spinbox)

        # --- ▼▼▼ コピーボタン追加 ▼▼▼ ---
        # ファイル名をボタンテキストに表示 (パスが長い場合は調整が必要かも)
        copy_button_text = f"コピー ({os.path.join('output', DEFAULT_OUTPUT_FILE.name)})" # 例: output/ファイル名
        self.copy_button = QPushButton(copy_button_text)
        self.copy_button.setToolTip(f"結果ファイル ({DEFAULT_OUTPUT_FILE}) の内容をクリップボードにコピーします。")
        options_layout.addWidget(self.copy_button)
        # --- ▲▲▲ コピーボタン追加 ▲▲▲ ---

        options_layout.addStretch() # ボタンの後にスペーサーを追加
        main_layout.addLayout(options_layout)

        # --- 結果表示エリア ---
        self.result_display = QPlainTextEdit()
        self.result_display.setReadOnly(True)
        self.result_display.setPlaceholderText("ここに実行結果が表示されます...")
        main_layout.addWidget(self.result_display, 1) # 縦方向に伸縮

        # --- ステータスラベル ---
        self.status_label = QLabel("アイドル")
        main_layout.addWidget(self.status_label)

        # --- シグナルとスロットの接続 ---
        self.refresh_button.clicked.connect(self.populate_json_files)
        self.generator_button.clicked.connect(self.open_generator)
        self.run_button.clicked.connect(self.run_mcp)
        # --- ▼▼▼ コピーボタンのシグナル接続 ▼▼▼ ---
        self.copy_button.clicked.connect(self.copy_output_to_clipboard)
        # --- ▲▲▲ コピーボタンのシグナル接続 ▲▲▲ ---

        # --- 初期設定 ---
        JSON_FOLDER.mkdir(exist_ok=True)
        # output ディレクトリもなければ作成
        DEFAULT_OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.populate_json_files()
        self.run_button.setStyleSheet("background-color: #28a745; color: white;")

    def populate_json_files(self):
        # ... (変更なし) ...
        self.json_selector.clear()
        try:
            json_files = sorted([f.name for f in JSON_FOLDER.glob("*.json") if f.is_file()])
            if json_files:
                self.json_selector.addItems(json_files)
                self.status_label.setText(f"{len(json_files)}個のJSONファイルを検出")
                self.run_button.setEnabled(True)
            else:
                self.json_selector.addItem("JSONファイルが見つかりません")
                self.status_label.setText(f"'{JSON_FOLDER}'フォルダにJSONファイルがありません")
                self.run_button.setEnabled(False)
        except Exception as e:
            self.show_error_message(f"JSONファイルの読み込みエラー: {e}")
            self.run_button.setEnabled(False)

    def open_generator(self):
        # ... (変更なし) ...
         if not GENERATOR_HTML.exists():
              self.show_error_message(f"エラー: {GENERATOR_HTML} が見つかりません。")
              return
         if self.generator_dialog is None or not self.generator_dialog.isVisible():
             self.generator_dialog = GeneratorDialog(GENERATOR_HTML, self)
             self.generator_dialog.json_generated.connect(self.paste_generated_json)
             self.generator_dialog.show()
         else:
             self.generator_dialog.raise_()
             self.generator_dialog.activateWindow()

    @Slot(str)
    def paste_generated_json(self, json_string):
        # ... (変更なし) ...
        self.result_display.setPlaceholderText("JSONジェネレーターからJSONが入力されました。\n内容を確認し、必要であればファイルに保存して選択、または直接実行してください。")
        try:
             parsed_json = json.loads(json_string)
             formatted_json = json.dumps(parsed_json, indent=2, ensure_ascii=False)
             self.result_display.setPlainText(formatted_json)
             self.status_label.setText("JSONジェネレーターからJSONを取得しました")
        except json.JSONDecodeError:
              self.show_error_message("ジェネレーターから無効なJSONを受け取りました。")
              self.result_display.setPlainText(json_string)

    def run_mcp(self, json_data: Optional[Dict[str, Any]] = None):
        # ... (変更なし) ...
        if self.mcp_worker and self.mcp_worker.isRunning():
            self.show_error_message("現在、別のタスクを実行中です。")
            return

        input_source = ""
        selected_json_input = None
        if json_data:
            selected_json_input = json_data
            input_source = "ジェネレーターからのJSON"
            self.result_display.clear()
            self.result_display.setPlaceholderText("ジェネレーターからのJSONで実行中...")
        else:
            selected_file = self.json_selector.currentText()
            if not selected_file or selected_file == "JSONファイルが見つかりません":
                self.show_error_message("実行するJSONファイルを選択してください。")
                return
            json_path = JSON_FOLDER / selected_file
            if not json_path.exists():
                 self.show_error_message(f"エラー: 選択されたファイル '{selected_file}' が見つかりません。")
                 self.populate_json_files()
                 return
            input_source = f"ファイル '{selected_file}'"
            self.result_display.clear()
            self.result_display.setPlaceholderText(f"'{selected_file}' を実行中...")
            try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    selected_json_input = json.load(f)
            except Exception as e:
                self.show_error_message(f"JSONファイルの読み込み/パースエラー ({selected_file}): {e}")
                self.status_label.setText("エラー")
                return

        self.status_label.setText(f"{input_source} で実行開始...")
        self.run_button.setEnabled(False)
        self.refresh_button.setEnabled(False)
        self.generator_button.setEnabled(False)
        self.headless_checkbox.setEnabled(False)
        self.slowmo_spinbox.setEnabled(False)
        self.copy_button.setEnabled(False) # コピーボタンも実行中は無効化

        headless_mode = self.headless_checkbox.isChecked()
        slow_mo_value = self.slowmo_spinbox.value()

        self.mcp_worker = McpWorker(selected_json_input, headless_mode, slow_mo_value)
        self.mcp_worker.result_ready.connect(self.display_result)
        self.mcp_worker.error_occurred.connect(self.display_error)
        self.mcp_worker.status_update.connect(self.update_status)
        self.mcp_worker.finished.connect(self.task_finished)
        self.mcp_worker.start()

    # --- ▼▼▼ コピー処理用スロット関数 ▼▼▼ ---
    @Slot()
    def copy_output_to_clipboard(self):
        """結果ファイルの内容をクリップボードにコピーする。"""
        output_filepath = DEFAULT_OUTPUT_FILE
        # output ディレクトリが存在しない場合は作成を試みる
        try:
            output_filepath.parent.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            print(f"Warning: Could not create output directory {output_filepath.parent}: {e}")

        if not output_filepath.exists():
            self.show_error_message(f"エラー: 結果ファイルが見つかりません。\nパス: {output_filepath}")
            self.status_label.setText("コピー失敗: ファイルなし")
            return

        try:
            with open(output_filepath, 'r', encoding='utf-8') as f:
                file_content = f.read()

            clipboard = QApplication.instance().clipboard()
            if clipboard is None:
                self.show_error_message("エラー: クリップボードにアクセスできません。")
                self.status_label.setText("コピー失敗: クリップボードエラー")
                return

            clipboard.setText(file_content)
            self.status_label.setText(f"'{output_filepath.name}' の内容をクリップボードにコピーしました。")
            # 必要であれば情報メッセージを表示
            # QMessageBox.information(self, "コピー完了", f"'{output_filepath.name}' の内容をクリップボードにコピーしました。")

        except IOError as e:
            self.show_error_message(f"エラー: 結果ファイルの読み込みに失敗しました。\nエラー: {e}")
            self.status_label.setText("コピー失敗: 読み込みエラー")
        except Exception as e:
            self.show_error_message(f"予期せぬエラーが発生しました。\nエラー: {e}")
            self.status_label.setText("コピー失敗: 不明なエラー")
            traceback.print_exc() # デバッグ用にトレースバックを出力
    # --- ▲▲▲ コピー処理用スロット関数 ▲▲▲ ---


    @Slot(str)
    def display_result(self, result_json_string: str):
        # ... (変更なし) ...
        display_text = ""
        result_data_list_for_file = None
        try:
             result_data_list = json.loads(result_json_string)
             if not isinstance(result_data_list, list):
                 raise TypeError("Result data is not a list.")
             result_data_list_for_file = result_data_list

             display_text += "--- Web Runner Execution Result ---\n\n"
             display_text += f"Overall Status: Success\n\n"

             for i, step_result in enumerate(result_data_list):
                step_num = step_result.get('step', i + 1)
                action_type = step_result.get('action', 'Unknown')
                status = step_result.get('status', 'Unknown')

                display_text += f"--- Step {step_num}: {action_type} ({status}) ---\n"

                if status == "success":
                    details_to_write = {k: v for k, v in step_result.items() if k not in ['step', 'status', 'action']}
                    if 'selector' in details_to_write:
                        display_text += f"Selector: {details_to_write.pop('selector')}\n"
                    if action_type == 'get_all_attributes':
                        attr_name = details_to_write.pop('attribute', 'N/A')
                        if 'url_list' in details_to_write: # 'url_list' キーをチェック
                            url_list = details_to_write.pop('url_list', []) # 'url_list' を取得
                            if url_list:
                                display_text += "Result (URL List):\n" + '\n'.join(f"- {str(item)}" for item in url_list if item is not None) + "\n"
                        elif 'attribute_list' in details_to_write:
                             attr_list = details_to_write.pop('attribute_list', [])
                             if attr_list:
                                 display_text += f"Result (Attribute List for '{attr_name}'):\n" + '\n'.join(f"- {str(item)}" for item in attr_list if item is not None) + "\n"
                        if 'pdf_texts' in details_to_write:
                             pdf_texts = details_to_write.pop('pdf_texts', [])
                             valid_pdf_texts = [t for t in pdf_texts if t and isinstance(t, str)]
                             if valid_pdf_texts:
                                 display_text += "Extracted PDF Texts:\n" + '\n\n--- Next PDF Text ---\n\n'.join(valid_pdf_texts) + '\n'
                        if 'scraped_texts' in details_to_write:
                             scraped_texts = details_to_write.pop('scraped_texts', [])
                             if scraped_texts:
                                 display_text += "Scraped Page Texts:\n"
                                 display_text += '\n\n--- Next Page Text ---\n\n'.join(str(t) if t is not None else '(No text or Error)' for t in scraped_texts) + '\n'
                    elif action_type == 'get_all_text_contents':
                        text_list_result = details_to_write.pop('text_list', [])
                        if isinstance(text_list_result, list):
                            valid_texts = [str(text).strip() for text in text_list_result if text is not None and str(text).strip()]
                            if valid_texts:
                                display_text += "Result Text List:\n" + '\n'.join(f"- {text}" for text in valid_texts) + "\n"
                    elif action_type in ['get_text_content', 'get_inner_text'] and 'text' in details_to_write:
                        display_text += f"Result Text:\n{details_to_write.pop('text', '')}\n"
                    elif action_type == 'get_inner_html' and 'html' in details_to_write:
                        display_text += f"Result HTML:\n{details_to_write.pop('html', '')}\n"
                    elif action_type == 'get_attribute':
                        attr_name = details_to_write.pop('attribute', ''); attr_value = details_to_write.pop('value', None)
                        display_text += f"Result Attribute ('{attr_name}'): {attr_value}\n"
                        if 'pdf_text' in details_to_write:
                            display_text += f"Extracted PDF Text:\n{details_to_write.pop('pdf_text', '')}\n"
                    if details_to_write:
                        display_text += "Other Details:\n"
                        for key, val in details_to_write.items():
                            display_text += f"  {key}: {val}\n"
                elif status == "error":
                    if step_result.get('selector'): display_text += f"Selector: {step_result.get('selector')}\n"
                    display_text += f"Message: {step_result.get('message')}\n"
                    if step_result.get('full_error'): display_text += f"Details: {step_result.get('full_error')}\n"
                    if step_result.get('error_screenshot'): display_text += f"Screenshot: {step_result.get('error_screenshot')}\n"
                else:
                    display_text += f"Message: {step_result.get('message', 'No details')}\n"
                display_text += "\n"

             self.result_display.setPlainText(display_text)
             self.status_label.setText("実行成功")

             if utils and result_data_list_for_file:
                 try:
                     utils.write_results_to_file(result_data_list_for_file, str(DEFAULT_OUTPUT_FILE))
                     print(f"Result also written to {DEFAULT_OUTPUT_FILE}")
                 except Exception as write_e:
                      print(f"Error writing results to file: {write_e}")

        except (json.JSONDecodeError, TypeError) as e:
             error_msg = f"サーバーからの応答の処理中にエラー ({type(e).__name__}):\n{result_json_string}"
             self.result_display.setPlainText(error_msg)
             self.status_label.setText("警告: 不正な応答")
             print(error_msg)

    @Slot(object)
    def display_error(self, error_info: Union[str, Dict[str, Any]]):
        # ... (変更なし) ...
        error_message = "不明なエラー"
        if isinstance(error_info, dict):
            try: error_message = json.dumps(error_info, indent=2, ensure_ascii=False)
            except Exception: error_message = str(error_info)
        elif isinstance(error_info, str):
            error_message = error_info
        self.result_display.setPlainText(f"エラーが発生しました:\n\n{error_message}")
        self.status_label.setText("エラー発生")
        # エラー時にもファイルに書き込み試行
        try:
            with open(DEFAULT_OUTPUT_FILE, 'w', encoding='utf-8') as f:
                 f.write(f"--- Execution Failed ---\n{error_message}")
            print(f"Error details written to {DEFAULT_OUTPUT_FILE}")
        except Exception as write_e:
            print(f"Error writing error details to file: {write_e}")
        # エラーメッセージボックス表示は削除（冗長なため）
        # self.show_error_message(error_message)


    @Slot(str)
    def update_status(self, status: str):
        # ... (変更なし) ...
        self.status_label.setText(status)

    @Slot()
    def task_finished(self):
        # ... (変更なし) ...
        print("DEBUG: task_finished slot called.")
        self.run_button.setEnabled(True)
        self.refresh_button.setEnabled(True)
        self.generator_button.setEnabled(True)
        self.headless_checkbox.setEnabled(True)
        self.slowmo_spinbox.setEnabled(True)
        self.copy_button.setEnabled(True) # コピーボタンも再度有効化
        if not self.status_label.text().startswith("エラー"):
            self.status_label.setText("アイドル")
        self.mcp_worker = None

    def show_error_message(self, message: str):
        # ... (変更なし) ...
        QMessageBox.critical(self, "エラー", message)

    def closeEvent(self, event):
        # ... (変更なし) ...
        print("Close event triggered.")
        if self.mcp_worker and self.mcp_worker.isRunning():
            print("Stopping MCP worker thread...")
            self.mcp_worker.stop_worker()
            if not self.mcp_worker.wait(3000):
                 print("Warning: Worker thread did not stop gracefully.")
        if self.generator_dialog and self.generator_dialog.isVisible():
            self.generator_dialog.close()
        print("Exiting client application.")
        event.accept()

# --- アプリケーション実行 ---
if __name__ == "__main__":
    # WindowsでのAnyIOポリシー設定 (必要に応じて)
    # if platform.system() == "Windows":
    #     asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec())


---


- フォルダ名: .
- ファイル名: web_runner_mcp_server.py
- 内容:
# --- ファイル: web_runner_mcp_server.py (修正版) ---

import json
import logging # logging をインポート
import traceback # 詳細なエラー出力用

# MCP SDK と Pydantic をインポート
from mcp.server.fastmcp import Context, FastMCP
from mcp.server.fastmcp.exceptions import ToolError
from mcp.server.fastmcp.utilities.logging import configure_logging # MCPのログ設定関数
from pydantic import BaseModel, Field, HttpUrl

# ▼▼▼ typing から List, Dict, Any, Optional をインポート (必要なら) ▼▼▼
from typing import Any, Dict, List, Literal, Union, Optional

# --- ▼▼▼ 修正 ▼▼▼ ---
# 分割した Web-Runner のコア関数と設定をインポート
try:
    import config # 設定値を参照するため
    import utils  # ロギング設定などに使う可能性
    # playwright_handler -> playwright_launcher をインポート
    from playwright_launcher import run_playwright_automation_async # メインの実行関数
except ImportError as import_err:
    logging.critical(f"致命的エラー: Web-Runnerの必須モジュール (config, utils, playwright_launcher) のインポートに失敗しました: {import_err}")
    logging.critical("config.py, utils.py, playwright_launcher.py が同じディレクトリにあるか、PYTHONPATHに含まれているか確認してください。")
    import sys
    sys.exit(1)
# --- ▲▲▲ 修正 ▲▲▲ ---

# --- ロガー取得 ---
logger = logging.getLogger(__name__)

# --- ▼▼▼ ActionStep モデルを修正 ▼▼▼ ---
class ActionStep(BaseModel):
    action: str = Field(..., description="実行するアクション名 (例: 'click', 'input', 'get_text_content')")
    memo: str | None = Field(None, description="アクションに関するメモ (任意)") # memoも追加しておくと便利
    selector: str | None = Field(None, description="従来のCSSセレクター (target_hintsがない場合に使用)")
    # --- ▼▼▼ target_hints フィールドを追加 ▼▼▼ ---
    target_hints: Optional[List[Dict[str, Any]]] = Field(None, description="LLMが生成した要素特定情報の候補リスト")
    # --- ▲▲▲ target_hints フィールドを追加 ▲▲▲ ---
    iframe_selector: str | None = Field(None, description="iframeを対象とする場合のCSSセレクター (switch_to_iframeの場合)")
    value: str | float | int | bool | None = Field(None, description="入力値、待機時間、ファイル名など")
    attribute_name: str | None = Field(None, description="取得する属性名 (get_attribute, get_all_attributesの場合)")
    option_type: Literal['value', 'index', 'label'] | None = Field(None, description="ドロップダウン選択方法 (select_optionの場合)")
    option_value: str | int | None = Field(None, description="選択する値/インデックス/ラベル (select_optionの場合)")
    wait_time_ms: int | None = Field(None, description="このアクション固有の最大待機時間 (ミリ秒)")
# --- ▲▲▲ ActionStep モデルを修正 ▲▲▲ ---

class WebRunnerInput(BaseModel):
    target_url: Union[HttpUrl, str] = Field(..., description="自動化を開始するWebページのURL")
    actions: List[ActionStep] = Field(..., description="実行するアクションステップのリスト", min_length=1)
    headless: bool = Field(True, description="ヘッドレスモードで実行するかどうか")
    slow_mo: int = Field(0, description="各操作間の待機時間 (ミリ秒)", ge=0)
    default_timeout_ms: int | None = Field(None, description=f"デフォルトのアクションタイムアウト(ミリ秒)")



# --- FastMCP サーバーインスタンス作成 (変更なし) ---
mcp = FastMCP(
    name="WebRunnerServer",
    instructions="Webサイトの自動操作とデータ抽出を実行するサーバーです。URLと一連のアクションを指定してください。",
    dependencies=["playwright", "PyMuPDF", "fitz", "playwright-stealth"] # 依存関係にstealth追加
)

# --- MCPツール定義 (修正: インポート元変更) ---
@mcp.tool()
async def execute_web_runner(
    input_args: WebRunnerInput,
    ctx: Context
) -> str:
    """
    指定されたURLとアクションリストに基づいてWebブラウザ自動化タスクを実行し、
    結果をJSON文字列として返します。
    """
    await ctx.info(f"Received task for URL: {input_args.target_url} with {len(input_args.actions)} actions.")
    await ctx.debug(f"Input arguments (raw): {input_args.model_dump()}") # Pydantic v2

    try:
        target_url_str = str(input_args.target_url) # URLを文字列に変換
        # アクションリストを辞書のリストに変換
        actions_list = [step.model_dump(exclude_none=True) for step in input_args.actions]
        # 有効なデフォルトタイムアウトを決定
        effective_default_timeout = input_args.default_timeout_ms if input_args.default_timeout_ms is not None else config.DEFAULT_ACTION_TIMEOUT
        await ctx.info(f"Using effective default timeout: {effective_default_timeout}ms")

        await ctx.debug(f"Calling playwright_launcher.run_playwright_automation_async with:")
        await ctx.debug(f"  target_url='{target_url_str}'")
        await ctx.debug(f"  actions_count={len(actions_list)}")
        await ctx.debug(f"  headless_mode={input_args.headless}")
        await ctx.debug(f"  slow_motion={input_args.slow_mo}")
        await ctx.debug(f"  default_timeout={effective_default_timeout}")

        # --- ▼▼▼ 修正 ▼▼▼ ---
        # playwright_handler -> playwright_launcher のコア関数を呼び出す
        success, results = await run_playwright_automation_async(
            target_url=target_url_str,
            actions=actions_list,
            headless_mode=input_args.headless,
            slow_motion=input_args.slow_mo,
            default_timeout=effective_default_timeout
        )
        # --- ▲▲▲ 修正 ▲▲▲ ---

        # 結果をJSON文字列に変換 (エラー時も含む)
        # ensure_ascii=False で日本語がエスケープされないようにする
        results_json = json.dumps(results, indent=2, ensure_ascii=False)
        await ctx.debug(f"Task finished. Success: {success}. Results JSON (first 500 chars): {results_json[:500]}...")

        if success:
            await ctx.info("Task completed successfully.")
            return results_json
        else:
            # 失敗した場合、ToolErrorを送出するが、そのメッセージに結果JSONを含める
            await ctx.error("Task failed. Returning error information via ToolError.")
            # ToolErrorのメッセージにJSONを含めることで、クライアント側で詳細を確認できるようにする
            raise ToolError(f"Web-Runner task failed. Details in JSON content: {results_json}")

    except ImportError as e:
         # サーバー起動時のインポートエラーは上で処理されるはずだが、念のため
         err_msg = f"Server configuration error: Failed to load core Web-Runner module ({e})"
         await ctx.error(err_msg)
         raise ToolError(err_msg)
    except Exception as e:
        # 予期せぬエラーが発生した場合
        error_traceback = traceback.format_exc()
        await ctx.error(f"Unhandled exception during Web-Runner execution: {type(e).__name__} - {e}")
        await ctx.error(f"Traceback:\n{error_traceback}")
        # クライアントにはエラーが発生したことと、サーバーログを確認するよう促すメッセージを含むエラー情報を返す
        error_result = [{
            "step": "MCP Tool Execution",
            "status": "error",
            "message": f"Unhandled server error occurred: {type(e).__name__}. Please check server logs for details.",
            "error_type": type(e).__name__,
            "raw_error": str(e)
        }]
        error_json = json.dumps(error_result, indent=2, ensure_ascii=False)
        raise ToolError(f"Unhandled server error during execution. Details: {error_json}")

# --- サーバー起動設定 (変更なし) ---
# --- サーバー起動設定 (ロギング修正版) ---
# --- ファイル: web_runner_mcp_server.py (インデント確認・修正案) ---

# ... (ファイル前半の import 文やクラス定義など) ...

# --- サーバー起動設定 (ロギング修正版) ---
if __name__ == "__main__":  # ← インデントレベル 0
    import typer          # ← インデントレベル 1

    cli_app = typer.Typer() # ← インデントレベル 1 であることを確認 ★

    @cli_app.command()    # ← インデントレベル 1 であることを確認 ★
    def main(             # ← インデントレベル 1
        transport: str = typer.Option(
            "stdio", "--transport", "-t",
            help="Transport protocol (stdio or sse)",
        ),
        host: str = typer.Option(
            "127.0.0.1", "--host", help="Host for SSE server"
        ),
        port: int = typer.Option(
            8000, "--port", "-p", help="Port for SSE server"
        ),
        log_level: str = typer.Option(
            "INFO", "--log-level", help="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)"
        )
    ):                    # ← インデントレベル 1
        """Web-Runner MCP Server"""
        # --- main 関数の実装 ---
        # (引数バリデーション)
        transport_lower = transport.lower()
        if transport_lower not in ["stdio", "sse"]:
            print(f"エラー: 無効なトランスポートタイプ '{transport}'。'stdio' または 'sse' を指定してください。", file=sys.stderr)
            raise typer.Exit(code=1)

        log_level_upper = log_level.upper()
        valid_log_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
        if log_level_upper not in valid_log_levels:
            print(f"エラー: 無効なログレベル '{log_level}'。{valid_log_levels} のいずれかを指定してください。", file=sys.stderr)
            raise typer.Exit(code=1)

        # (ロギング設定)
        try:
            print(f"DEBUG [server]: Attempting to set up logging using utils.setup_logging_for_standalone for {config.MCP_SERVER_LOG_FILE}")
            utils.setup_logging_for_standalone(log_file_path=config.MCP_SERVER_LOG_FILE)
            logging.getLogger().setLevel(log_level_upper)
            logger.info(f"MCP Server logging configured via utils. Level: {log_level_upper}. File: {config.MCP_SERVER_LOG_FILE}")
        except Exception as log_setup_err:
            print(f"緊急エラー: サーバーのロギング設定に失敗しました: {log_setup_err}", file=sys.stderr)
            raise typer.Exit(code=1)

        logger.info(f"Web-Runner MCP サーバーを {transport_lower} トランスポートで起動します...")
        if transport_lower == "sse":
             mcp.settings.host = host
             mcp.settings.port = port
             logger.info(f"SSEサーバーが http://{host}:{port} で待機します")
        # MCPサーバーを実行
        mcp.run(transport=transport_lower) # type: ignore
        # --- main 関数の実装ここまで ---

    # Typerアプリケーションを実行
    cli_app()             # ← インデントレベル 1 であることを確認 ★


---


- フォルダ名: .\json
- ファイル名: cw_all_content.json
- 内容:
{
  "target_url": "https://crowdworks.jp/public/jobs/search?category_id=228&order=new&page=1",
  "actions": [
    {
      "memo": "表示待ち",
      "action": "wait_visible",
      "selector": "li[data-v-d4b91500]"
    },
    {
      "memo": "href = url",
      "action": "get_all_attributes",
      "selector": "li a.wB71r",
      "attribute_name": "href"
    },
    {
      "memo": "content = urlへアクセスしてbodyを取得",
      "action": "get_all_attributes",
      "selector": "li a.wB71r",
      "attribute_name": "content"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: cw_url.json
- 内容:
{
  "target_url": "https://crowdworks.jp/public/jobs/search?category_id=228&order=new&page=1",
  "actions": [
    {
      "memo": "表示待ち",
      "action": "wait_visible",
      "selector": "li[data-v-d4b91500]",
      "wait_time_ms": 10000
    },
    {      
      "memo": "href = url",
      "action": "get_all_attributes",
      "selector": "li a.wB71r",
      "wait_time_ms": 5000,
      "attribute_name": "href"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_company2mail.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "memo": "検索ボックスに入力",
      "action": "input",
      "selector": "#APjFqb",
      "value": "東京都　渋谷区　株式会社　お問い合わせ"
    },
    {
      "memo": "検索ボタンをクリック",
      "action": "click",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 5000
    },
    {
      "memo": "mail = 全てのメルアドを取得する。（ドメイン単位でユニークにする）",
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "wait_time_ms": 5000,
      "attribute_name": "mail"
    },
    {
      "memo": "次へボタンをクリック",
      "action": "click",
      "selector": "#pnnext > span.oeN89d",
      "wait_time_ms": 5000
    },
    {
      "memo": "mail = 全てのメルアドを取得する。（ドメイン単位でユニークにする）",
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "wait_time_ms": 5000,
      "attribute_name": "mail"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_domein2company1.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "memo": "検索ボックスに入力",
      "action": "input",
      "selector": "#APjFqb",
      "value": "meisenjp.com　会社概要"
    },
    {
      "memo": "検索ボタンをクリック",
      "action": "click",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 5000
    },
    {
      "memo": "content = urlに全てアクセスしてbodyの内容を取得する",
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "wait_time_ms": 5000,
      "attribute_name": "content"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_domein2company2.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "memo": "検索ボックスに入力",
      "action": "input",
      "selector": "#APjFqb",
      "value": "bil.jp　会社概要"
    },
    {
      "memo": "検索ボックス　クリック",
      "action": "click",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 5000
    },
    {
      "memo": "content = 全てのurlにアクセスしてbodyを取得する",
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "wait_time_ms": 5000,
      "attribute_name": "content"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_inner-text.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "memo": "検索ボックスに入力",
      "action": "input",
      "selector": "textarea#APjFqb",
      "value": "大阪府　株式会社　問い合わせ"
    },
    {
      "memo": "検索　をクリック",
      "action": "click",
      "selector": "input[name=\"btnK\"][value=\"Google 検索\"]",
      "wait_time_ms": 5000
    },
    {
      "memo": "次へ　クリック",
      "action": "click",
      "selector": "#pnnext > span.oeN89d",
      "wait_time_ms": 5000
    },
    {
      "action": "sleep",
      "wait_time_ms": 5000,
      "value": 5
    },
    {
      "memo": "検索結果　クリック",
      "action": "click",
      "selector": "a.zReHs",
      "wait_time_ms": 5000
    },
    {
      "memo": "内容を取得",
      "action": "get_inner_text",
      "selector": "body",
      "wait_time_ms": 5000
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_urls.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "action": "input",
      "memo": "入力",
      "selector": "#APjFqb",
      "wait_time_ms": 3000,
      "value": "bil.jp　会社概要"
    },
    {
      "action": "click",
      "memo": "Google検索ボタン　クリック",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 3000
    },
    {
      "action": "get_all_attributes",
      "memo": "全てのcontent取得",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "wait_time_ms": 3000,
      "attribute_name": "href"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_yahooFinance.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "memo": "入力",
      "action": "input",
      "selector": "#APjFqb",
      "value": "yahoo ファイナンス"
    },
    {
      "memo": "検索ボタン　クリック",
      "action": "click",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 5000
    },
    {
      "memo": "検索結果の１件目　クリック",
      "action": "click",
      "selector": "#rso > div.MjjYud > div > div > div > div > div > div > div > div:nth-child(1) > div:nth-child(2) > div > div > span > a",
      "wait_time_ms": 3000
    },
    {
      "memo": "yahoo ファイナンスの検索ボックスに9501と入力",
      "action": "input",
      "selector": "#search > form > input",
      "value": "9501"
    },
    {
      "memo": "検索をクリック",
      "action": "click",
      "selector": "#search > form > button"
    },
    {
      "memo": "時系列をクリック",
      "action": "click",
      "selector": "#stk_info > li:nth-child(7) > a"
    },
    {
      "action": "get_inner_text",
      "selector": "#root > main > div > div.Column__rMa8 > div.Column__main__XuqD > div:nth-child(3) > section.StocksEtfReitPriceHistory__26aY.StocksEtfReitPriceHistory--price__h40V.StocksContents__stockHistory__2P-X > div > table"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: input.json
- 内容:
{
  "target_url": "https://www.release.tdnet.info/index.html",
  "actions": [
    {
      "action": "click",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "wait_time_ms": 5000
    },
    {
      "action": "select_option",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "wait_time_ms": 5000,
      "option_type": "index",
      "option_value": 7
    },
    {
      "action": "input",
      "selector": "#freewordtxt",
      "value": "不動産"
    },
    {
      "action": "click",
      "selector": "#searchbtn > img"
    },
    {
      "action": "get_all_text_contents",
      "selector": "tr td.title a"
    },    
    {
      "action": "get_all_attributes",
      "selector": ".title a",
      "attribute_name": "href"
    }

  ]
}


---


- フォルダ名: .\json
- ファイル名: pmda_inner-text.json
- 内容:
{
  "target_url": "https://www.pmda.go.jp/PmdaSearch/iyakuSearch/",
  "actions": [
    {
      "memo": "入力",
      "action": "input",
      "selector": "#txtName",
      "value": "パキシル"
    },
    {
      "memo": "検索　クリック",
      "action": "click",
      "selector": "#ContentMainArea > div > div > p:nth-child(2) > span:nth-child(2) > input[type=image]"
    },
    {
      "memo": "TEXT　クリック",
      "action": "click",
      "selector": "#ResultList > tbody > tr.TrColor01 > td:nth-child(4) > div > a:nth-child(2)"
    },
    {
      "memo": "説明文を取得",
      "action": "get_inner_text",
      "selector": "#ResultSet > div:nth-child(2)"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: qiita_text.json
- 内容:
{
  "target_url": "https://qiita.com/",
  "actions": [
    {
      "memo": "一覧の文字情報を取得",
      "action": "get_all_text_contents",
      "selector": "article h2 a"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: tdnet_pdf.json
- 内容:
{
  "target_url": "https://www.release.tdnet.info/index.html",
  "actions": [
    {
      "action": "click",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)"
    },
    {
      "action": "select_option",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "option_type": "index",
      "option_value": 7
    },
    {
      "action": "input",
      "selector": "#freewordtxt",
      "value": "不動産"
    },
    {
      "action": "click",
      "selector": "#searchbtn > img"
    },
    {
      "action": "get_all_attributes",
      "selector": "tr td.title a",
      "attribute_name": "pdf"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: tdnet_text url.json
- 内容:
{
  "target_url": "https://www.release.tdnet.info/index.html",
  "actions": [
    {
      "action": "click",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "wait_time_ms": 5000
    },
    {
      "action": "select_option",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "wait_time_ms": 5000,
      "option_type": "index",
      "option_value": 7
    },
    {
      "action": "input",
      "selector": "#freewordtxt",
      "value": "不動産"
    },
    {
      "action": "click",
      "selector": "#searchbtn > img"
    },
    {
      "action": "get_all_text_contents",
      "selector": "tr td.title a"
    },    
    {
      "action": "get_all_attributes",
      "selector": ".title a",
      "attribute_name": "href"
    }

  ]
}


---


- フォルダ名: .\json
- ファイル名: tdnet_text.json
- 内容:
{
  "target_url": "https://www.release.tdnet.info/index.html",
  "actions": [
    {
      "action": "click",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "wait_time_ms": 5000
    },
    {
      "action": "select_option",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "wait_time_ms": 5000,
      "option_type": "index",
      "option_value": 7
    },
    {
      "action": "input",
      "selector": "#freewordtxt",
      "value": "不動産"
    },
    {
      "action": "click",
      "selector": "#searchbtn > img"
    },
    {
      "action": "get_all_text_contents",
      "selector": "tr td.title a"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: tdnet_url_pdf.json
- 内容:
{
  "target_url": "https://www.release.tdnet.info/index.html",
  "actions": [
    {
      "action": "click",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)"
    },
    {
      "action": "select_option",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "option_type": "index",
      "option_value": 7
    },
    {
      "action": "input",
      "selector": "#freewordtxt",
      "value": "不動産"
    },
    {
      "action": "click",
      "selector": "#searchbtn > img"
    },
    {
      "action": "get_inner_text",
      "selector": "#maintable > tbody > tr:nth-child(1) > td.title > a"
    },
    {
      "action": "get_all_attributes",
      "selector": ".title a",
      "attribute_name": "href"
    },
    {
      "action": "get_all_attributes",
      "selector": "tr td.title a",
      "attribute_name": "pdf"
    }

  ]
}


---


- フォルダ名: .\json
- ファイル名: zip-code-tokyo.json
- 内容:
{
  "target_url": "https://www.post.japanpost.jp/zipcode/",
  "actions": [
    {
      "memo": "表示待ち",
      "action": "wait_visible",
      "selector": "#zipcode > div.wrapper > div.contWrap > div > div > div.inner > div.areaTxt.sp-t30 > ul > li:nth-child(3) > a:nth-child(1)",
      "wait_time_ms": 10000
    },
    {
      "memo": "東京をクリック",
      "action": "click",
      "selector": "#zipcode > div.wrapper > div.contWrap > div > div > div.inner > div.areaTxt.sp-t30 > ul > li:nth-child(3) > a:nth-child(1)",
      "wait_time_ms": 5000
    },
    {
      "memo": "昭島市をクリック",
      "action": "click",
      "selector": "#main-box > div > div:nth-child(9) > table > tbody > tr:nth-child(2) > th > a",
      "wait_time_ms": 5000
    },


    {      
      "memo": "href = url",
      "action": "get_all_text_contents",
      "selector": "table.prefList",
      "wait_time_ms": 5000,
      "attribute_name": "content"

    }
  ]
}


---


- フォルダ名: .\json_generated_by_llm
- ファイル名: chatgpt_lab_get_info.json
- 内容:
{
  "target_url": "https://chatgpt-lab.com/n/nc1a8b4bb4911",
  "actions": [
    {
      "memo": "記事タイトルを取得 (textContent)",
      "action": "get_text_content",
      "target_hints": [
        {
          "type": "text_exact",
          "value": "AIエージェント構築フレームワーク「Mastra」基本的な使い方を徹底解説！",
          "confidence": "high"
        },
        {
          "type": "css_selector_candidate",
          "value": "h1.o-noteContentHeader__title",
          "confidence": "medium"
        }
      ]
    },
    {
      "memo": "記事本文の最初の段落を取得 (innerText)",
      "action": "get_inner_text",
      "target_hints": [
        {
          "type": "nth_child",
          "value": null,
          "common_selector": "div.note-common-styles__textnote-body > p",
          "index": 0,
          "confidence": "high"
        },
        {
          "type": "css_selector_candidate",
          "value": "p[id='291aed98-3da7-4f14-a743-d577542f7e38']",
          "confidence": "medium"
        },
        {
          "type": "css_selector_candidate",
          "value": "div.note-common-styles__textnote-body > p:first-of-type",
          "confidence": "medium"
        }
      ]
    },
    {
      "memo": "記事画像のsrc属性を取得",
      "action": "get_attribute",
      "target_hints": [
        {
          "type": "nth_child",
          "value": null,
          "common_selector": "div[data-note-id] div.o-noteContentText--font_sansserif > *",
          "index": 0,
          "confidence": "high"
        },
        {
          "type": "css_selector_candidate",
          "value": "figure.o-noteEyecatch img.a-image",
          "confidence": "medium"
        },
        {
          "type": "css_selector_candidate",
          "value": "img[src*='rectangle_large_type_2_42babf790237cc623002689480d9c05a.png']",
          "confidence": "low"
        }
      ],
      "attribute_name": "src"
    },
    {
      "memo": "共有ボタンのツールチップを取得 (カスタム属性)",
      "action": "get_attribute",
      "target_hints": [
        {
          "type": "role_and_text",
          "value": "button",
          "name": "シェア",
          "confidence": "high"
        },
        {
          "type": "css_selector_candidate",
          "value": "button[data-tooltip='シェア']",
          "confidence": "medium"
        },
        {
          "type": "css_selector_candidate",
          "value": "#shareButton",
          "confidence": "low"
        }
      ],
      "attribute_name": "data-tooltip"
    }
  ]
}


---


- フォルダ名: .\json_generated_by_llm
- ファイル名: google_search_click_first_and_next.json
- 内容:
{
  "target_url": "https://www.google.co.jp/",
  "actions": [
    {
      "memo": "検索ボックスに入力",
      "action": "input",
      "target_hints": [
        {
          "type": "aria_label",
          "value": "検索",
          "confidence": "high"
        },
        {
          "type": "role_and_text",
          "value": "combobox",
          "name": "検索",
          "confidence": "medium"
        },
        {
          "type": "css_selector_candidate",
          "value": "textarea#APjFqb",
          "confidence": "medium"
        },
        {
          "type": "css_selector_candidate",
          "value": "textarea[name='q']",
          "confidence": "medium"
        },
        {
          "type": "css_selector_candidate",
          "value": "textarea.gLFyf",
          "confidence": "low"
        }
      ],
      "value": "Playwrightによる自動テスト"
    },
    {
      "memo": "Google検索ボタンをクリック",
      "action": "click",
      "target_hints": [
        {
          "type": "nth_child",
          "value": null,
          "common_selector": "div.FPdoLc > center > input.gNO89b, div.UUbT9 > div.lJ9FBc > center > input.gNO89b",
          "index": 0,
          "confidence": "high"
        },
        {
          "type": "role_and_text",
          "value": "button",
          "name": "Google 検索",
          "confidence": "medium"
        },
        {
          "type": "aria_label",
          "value": "Google 検索",
          "confidence": "medium"
        },
        {
          "type": "css_selector_candidate",
          "value": "input[name='btnK'][value='Google 検索']",
          "confidence": "low"
        }
      ],
      "wait_time_ms": 7000
    },
    {
      "memo": "「次へ」リンクをクリック",
      "action": "click",
      "target_hints": [
        {
          "type": "nth_child",
          "value": null,
          "name": null,
          "level": null,
          "common_selector": ".MjjYud > div.ULSxyf > div > div > div > div > div > div > div.g-scrolling-carousel > div > g-right-button",
          "index": 0,
          "confidence": "high"
        },
        {
          "type": "aria_label",
          "value": "次へ",
          "name": null,
          "level": null,
          "common_selector": null,
          "index": null,
          "confidence": "medium"
        },
        {
          "type": "css_selector_candidate",
          "value": "g-right-button[aria-label='次へ']",
          "name": null,
          "level": null,
          "common_selector": null,
          "index": null,
          "confidence": "low"
        }
      ],
      "wait_time_ms": 7000
    },
    {
      "memo": "最初の検索結果リンクをクリック",
      "action": "click",
      "target_hints": [
        {
          "type": "nth_child",
          "value": null,
          "name": null,
          "level": null,
          "common_selector": "div.MjjYud > div.wHYlTd > div.N54PNb > div.kb0PBd > div > div > div.yuRUbf > div.b8lM7 > span > a",
          "index": 0,
          "confidence": "high"
        },
        {
          "type": "css_selector_candidate",
          "value": "div.MjjYud:nth-child(1) a.zReHs",
          "name": null,
          "level": null,
          "common_selector": null,
          "index": null,
          "confidence": "medium"
        },
        {
          "type": "css_selector_candidate",
          "value": "a.zReHs",
          "name": null,
          "level": null,
          "common_selector": null,
          "index": null,
          "confidence": "low"
        }
      ],
      "wait_time_ms": 10000
    }
  ]
}